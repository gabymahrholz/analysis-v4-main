{"title":"Data wrangling II","markdown":{"headingText":"Data wrangling II","headingAttr":{"id":"sec-wrangling2","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n```{r include=FALSE}\nlibrary(webexercises)\n```\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter, you should be able to:\n\n-   apply familiar data wrangling functions to novel datasets\n-   read and interpret error messages\n-   realise there are several ways of getting to the results\n\nIn this chapter, we will pick up where we left off in @sec-wrangling. We will calculate average scores for two of the questionnaires, address an error mode problem, and finally, join all data objects together. This will finalise our data for the upcoming data visualization sections (@sec-dataviz and @sec-dataviz2).\n\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n## Activity 1: Setup\n\n* Go to the project folder we have been using in the last two weeks and double-click on the project icon to **open the project** in RStudio\n* Either **Create a new `.Rmd` file** for chapter 3 and save it to your project folder or continue the one from last week. See @sec-rmd if you need some guidance.\n\n\n\n## Activity 2: Load in the libraries and read in the data\n\nToday, we will be using `tidyverse` along with the two csv files created at the end of the last chapter: `data_prp_for_ch3.csv` and `qrp_t1.csv`. If you need to download them again for any reason, click on the following links: [data_prp_for_ch3.csv](data/data_prp_for_ch3.csv \"download\") and [qrp_t1.csv](data/qrp_t1.csv \"download\").\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hint\n\n```{r eval=FALSE}\nlibrary(???)\ndata_prp <- read_csv(\"???\")\nqrp_t1 <- read_csv(\"???\")\n```\n\n```{r include=FALSE, message=TRUE}\n## I basically have to have 2 code chunks since I tell them to put the data files next to the project, and mine are in a separate folder called data - unless I'll turn this into a fixed path\nlibrary(tidyverse)\ndata_prp <- read_csv(\"data/prp_data_reduced.csv\")\nqrp_t1 <- read_csv(\"data/qrp_t1.csv\")\n```\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n```{r eval=FALSE}\nlibrary(tidyverse)\ndata_prp <- read_csv(\"prp_data_reduced.csv\")\nqrp_t1 <- read_csv(\"qrp_t1.csv\")\n```\n\n:::\n\nIf you need a quick reminder what the dataset was about, have a look at the abstract in @sec-download_data_ch1. We also addressed the changes we made to the dataset there.\n\nAnd remember to have a quick `glimpse()` at your data.\n\n\n\n## Activity 3: Confidence in understanding Open Science practices {#sec-wrangling2_act3}\n\n#### The main goal is to compute the mean Understanding score per participant. {.unnumbered}\n\nThe mean Understanding score for time point 2 has already been calculated (in the `Time2_Understanding_OS` column), but we still need to compute it for time point 1.\n\nLooking at the Understanding data at time point 1, you determine that\n\n* individual item columns are `r mcq(c(x = \"numeric\", answer = \"character\"))`, and\n* according to the codebook, there are `r mcq(c(answer = \"no\", x = \"some\"))` reverse-coded items in this questionnaire.\n\nThe steps are quite similar to those for QRP, but we need to add an extra step: converting the character labels into numbers.\n\nAgain, let's do this step by step:\n\n* **Step 1**: Select the relevant columns `Code`, and every Understanding column from time point 1 (e.g., from `Understanding_OS_1_Time1` to `Understanding_OS_12_Time1`) and store them in an object called `understanding_t1`\n* **Step 2**: Pivot the data from wide format to long format using `pivot_longer()` so we can recode the labels into values (step 3) and calculate the average score (in step 4) more easily\n* **Step 3**: Recode the values \"Not at all confident\" as 1 and \"Entirely confident\" as 7. All other values are already numbers. We can use functions `mutate()` in combination with `case_match()` for that\n* **Step 4**: Calculate the average Understanding Open Science score (`Time1_Understanding_OS`) per participant using `group_by()` and `summarise()`\n\n#### Steps 1 and 2: Select and pivot {.unnumbered}\n\nHow about you try the first 2 steps yourself using the code from Chapter 2 Activity 4 (@sec-ch2_act4) as a template?\n\n```{r understanding, eval=FALSE}\nunderstanding_t1 <- data_prp %>% \n  select(???) %>% # Step 1\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\") # Step 2\n```\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for steps 1 and 2\n\n```{r}\nunderstanding_t1 <- data_prp %>% \n  # Step 1\n  select(Code, Understanding_OS_1_Time1:Understanding_OS_12_Time1) %>% \n  # Step 2 - I picked different column labels this time for some variety\n  pivot_longer(cols = Understanding_OS_1_Time1:Understanding_OS_12_Time1, names_to = \"Understanding_Qs\", values_to = \"Responses\") \n```\n\n:::\n\n#### Step 3: recoding the values {.unnumbered}\n\nOK, we now want to recode the values in the `Responses` column (or whatever name you picked for your column that has some of the numbers in it) so that \"Not at all confident\" = 1 and \"Entirely confident\" = 7. We want to keep all other values as they are (2-6 look already quite \"numeric\").\n\nLet's create a new column `Responses_corrected` that stores the new values with `mutate()`. Then we can combine that with the `case_match()` function.\n\n* The first argument in `case_match()` is the column name of the variable you want to recode.\n* Then you can start recoding the values in the way of `CurrentValue ~ NewValue` (~ is a tilde). Make sure you use the `~` and not `=`!\n* Lastly, the `.default` argument tells R what to do with values that are neither \"Not at all confident\" nor \"Entirely confident\". Here, we want to replace them with the original value of the `Responses` column. In other datasets, you may want to set the default to `NA` for missing values, a character string or a number, and `case_match()` is happy to oblige.\n\n```{r error=TRUE}\nunderstanding_t1 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = Responses # all other values taken from column Responses\n  ))\n```\n\n::: {.callout-important collapse=\"true\"}\n\n## Error!!! Can you explain what is happening here?\n\nHave a look at the error message. It's pretty helpful this time. It says `Can't combine ..1 (right) <double> and .default <character>.` It means that the replacement values are expected to be data type character since the original column type was type character.\n\n:::\n\n**So how do we fix this?** Actually, there are several ways this could be done. Click on the tabs below to check out 3 possible solutions.\n\n::: {.panel-tabset group=\"layers\"}\n\n## Fix option 1\n\nOne option is to modify the `.default` argument `Responses` so that the values are copied over from the original column but as a number rather than the original character value. The function `as.numeric()` does the conversion.\n\n```{r warning=FALSE}\nunderstanding_t1_step3_v1 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  ))\n```\n\n## Fix option 2\n\nChange the numeric values on the right side of the `~` to character. Then in a second step, we would need to turn the character column into a numeric type. Again, we have several options to do so. We could either use the `parse_number()` function we encountered earlier during the demographics wrangling or the `as.numeric()` function.\n\n* V1: `Responses_corrected = parse_number(Responses_corrected)`\n* V2: `Responses_corrected = as.numeric(Responses_corrected)`\n\nJust pay attention that you are still working *within* the `mutate()` function.\n\n```{r}\nunderstanding_t1_step3_v2 <- understanding_t1 %>% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ \"1\",\n                                          \"Entirely confident\" ~ \"7\",\n                                          .default = Responses # all other values taken from column Responses (character)\n  ),\n  Responses_corrected = parse_number(Responses_corrected)) # turning Responses_corrected into a numeric column\n```\n\n\n## Fix option 3\n\nIf you recode all the labels into numbers (e.g., \"2\" into 2, \"3\" into 3, etc.) from the start, you wonâ€™t need to perform any additional conversions later.\n\n```{r}\nunderstanding_t1_step3_v2 <- understanding_t1 %>% \n  mutate(Responses_recoded = case_match(Responses, # column of the values to recode\n                                        \"Not at all confident\" ~ 1, # recode all of them\n                                        \"2\" ~ 2,\n                                        \"3\" ~ 3,\n                                        \"4\" ~ 4,\n                                        \"5\" ~ 5,\n                                        \"6\" ~ 6,\n                                        \"Entirely confident\" ~ 7))\n```\n\n:::\n\n::: {.callout-note icon=\"false\"}\n\n## Your Turn\n\nChoose the option that works best for you to **modify the code of `understanding_t1`** above that didn't work/ gave you an error message. Once you do that, you should be able to calculate the **mean Understanding Score per participant**. Store the average scores in a variable called `Time1_Understanding_OS`. If you need help, refer to the hint below or use Chapter 2 Activity 4 (@sec-ch2_act4) as guidance.\n\n::: {.callout-caution icon=\"false\" collapse=\"true\"}\n\n## One solution for Steps 3 and 4\n\n```{r warning=FALSE}\nunderstanding_t1 <- understanding_t1 %>% \n  # Step 3\n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  )) %>% \n  # Step 4: calculating averages per participant\n  group_by(Code) %>%\n  summarise(Time1_Understanding_OS = mean(Responses_corrected)) %>%\n  ungroup()\n\n```\n\n:::\n\n:::\n\nOf course, this could have been written up as a single pipe.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Single pipe of activity 3\n\n```{r message=FALSE, warning=FALSE}\nunderstanding_t1 <- data_prp %>% \n  # Step 1\n  select(Code, Understanding_OS_1_Time1:Understanding_OS_12_Time1) %>% \n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Understanding_Qs\", values_to = \"Responses\") %>% \n  # Step 3\n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  )) %>% \n  # Step 4\n  group_by(Code) %>%\n  summarise(Time1_Understanding_OS = mean(Responses_corrected)) %>%\n  ungroup()\n```\n\n:::\n\n## Activity 4: Survey of Attitudes Toward Statistics (SATS-28) {#sec-wrangling2_act4}\n\n#### The main goal is to compute the mean SATS-28 score for each of the 4 subscales per participant for time point 1. {.unnumbered}\n\nLooking at the SATS data at time point 1, you determine that\n\n* individual item columns are `r mcq(c(answer = \"numeric\", x = \"character\"))`, and\n* according to the codebook, there are `r mcq(c(x = \"no\", answer = \"some\"))` reverse-coded items in this questionnaire.\n* Additionally, we are looking to compute the means for the 4 different subscales of the SAT-28 which are `r fitb(\"Affect\",ignore_case = TRUE)`, `r fitb(\"Cognitive Competence\",ignore_case = TRUE)`, `r fitb(\"Value\",ignore_case = TRUE)`, and `r fitb(\"Difficulty\",ignore_case = TRUE)`.\n\nThis scenario is slightly more tricky than the previous ones due to the reverse-coding and the 4 subscales. So, let's tackle this step by step again:\n\n* **Step 1**: Select the relevant columns `Code`, and every SATS28 column from time point 1 (e.g., from `SATS28_1_Affect_Time1` to `SATS28_28_Difficulty_Time1`) and store them in an object called `sats_t1`\n* **Step 2**: Pivot the data from wide format to long format using `pivot_longer()` so we can recode the labels into values (step 3) and calculate the average score (in step 4) more easily\n* **Step 3**: We need to know which items belong to which subscale - fortunately, we have that information in the variable name and can use the `separate()` function to access it.\n* **Step 4**: We need to know which items are reverse-coded and then reverse-score them - unfortunately, the info is only in the codebook and we need to find a work-around. `case_when()` can help identify and re-score the reverse-coded items.\n* **Step 5**: Calculate the average SATS score per participant and subscale using `group_by()` and `summarise()`\n* **Step 6**: use `pivot_wider()` to spread out the dataframe into wide format and `rename()` to tidy up the column names\n\n#### Steps 1 and 2: select and pivot {.unnumbered}\n\nThe selecting and pivoting are exactly the same way as we already practiced in the other 2 questionnaires. Apply them here to this questionnaire.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hint\n\n```{r SATS28, eval=FALSE}\nsats_t1 <- data_prp %>% \n  select(???) %>% # Step 1\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\") # Step 2\n```\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for steps 1 and 2\n\n```{r}\nsats_t1 <- data_prp %>% \n  select(Code, SATS28_1_Affect_Time1:SATS28_28_Difficulty_Time1) %>% # Step 1\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Response\") # Step 2\n```\n\n:::\n\n:::\n\n#### Step 3: separate Subscale information {.unnumbered}\n\nIf you look at the `Items` column more closely, you can see that there is information on the `Questionnaire`, the `Item_number`, the `Subscale`, and the `Timepoint` the data was collected at.\n\nWe can separate the information into separate columns using the `separate()` function. The function's first argument is the column to separate, then define `into` which columns you want the original column to split up, and lastly, define the separator `sep` (here an underscore). For our example, we would write:\n\n* V1: `separate(Items, into = c(\"SATS\", \"Item_number\", \"Subscale\", \"Time\"), sep = \"_\")`\n\nHowever, we don't need all of those columns, so we could just drop the ones we are not interested in by replacing them with `NA`.\n\n* V2: `separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\")`\n\nWe might also add an extra argument of `convert = TRUE` to have numeric columns (i.e., `Item_number`) converted to numeric as opposed to keeping them as characters. Saves us typing a few quotation marks later in Step 4.\n\n```{r}\nsats_t1 <- sats_t1 %>% \n  # Step 3\n  separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\", convert = TRUE)\n\n```\n\n#### Step 4: identifying reverse-coded items and then correct them {.unnumbered}\n\nWe can use `case_when()` within the `mutate()` function here to create a new column `FW_RV` that stores information on whether the item is a reverse-coded item or not.\n\n`case_when()` works similarly to `case_match()`, however `case_match()` only allows us to \"recode\" values (i.e., replace one value with another), whereas `case_when()` is more flexible. It allows us to use **conditional statements** on the left side of the tilde which is useful when you want to change only *some* of the data based on specific conditions.\n\nLooking at the codebook, it seems that items 2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, and 28 are reverse-coded. The rest are forward-coded.\n\nWe want to tell R now, that\n\n* **if** the `Item_number` is any of those numbers listed above, R should write \"Reverse\" into the new column `FW_RV` we are creating. Since we have a few possible matches for `Item_number`, we need the Boolean expression `%in%` rather than `==`.\n* **if** `Item_number` is none of those numbers, then we would like the word \"Forward\" in the `FW_RV` column to appear. We can achieve that by specifying a `.default` argument again, but this time we want a \"word\" rather than a value from another column.\n\n```{r}\nsats_t1 <- sats_t1 %>% \n  mutate(FW_RV = case_when(\n    Item_number %in% c(2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28) ~ \"Reverse\",\n    .default = \"Forward\"\n  ))\n```\n\nMoving on to correcting the scores: Once again, we can use `case_when ()` within the `mutate()` function to create another **conditional statement**. This time, the condition is:\n\n* **if** `FW_RV` column has a value of \"Reverse\" then we would like to turn all 1 into 7, 2 into 6, etc.\n* **if** `FW_RV` column has a value of \"Forward\" then we would like to keep the score from the `Response` column\n\nThere is a quick way and a not-so-quick way to achieve the actual **reverse-coding**.\n\n* **Option 1 (quick)**: The easiest way to reverse-code scores is to take the maximum value of the scale, add 1 unit, and subtract the original value. For example, on a 5-point Likert scale, it would be 6 minus the original rating; for a 7-point Likert scale, 8 minus the original rating, etc. (see *Option 1* tab).\n* **Option 2 (not so quick)**: This involves using two conditional statements (see *Option 2* tab).\n\nUse the one you find more intuitive.\n\n::: panel-tabset\n\n## Option 1\n\nHere we are using a Boolean expression to check if the string \"Reverse\" is present in the `FW_RV` column. If this condition is `TRUE`, the value in the new column we're creating, `Scores_corrected`, will be calculated as 8 minus the value from the Response column. If the condition is FALSE (handled by the .default argument), the original values from the `Response` column will be retained.\n\n```{r}\nsats_t1 <- sats_t1 %>% \n  mutate(Scores_corrected = case_when(\n    FW_RV == \"Reverse\" ~ 8-Response,\n    .default = Response\n  ))\n```\n\n## Option 2\n\nAs stated above, the longer approach involves using two conditional statements. The first condition checks if the value in the `FW_RV` column is \"Reverse\", while the second condition checks if the value in the `Response` column equals a specific number. **When both conditions are met**, the corresponding value on the right side of the tilde is placed in the newly created `Scores_corrected_v2` column.\n\nFor example, line 3 would read: if the value in the `FW_RV` column is \"Reverse\" **AND** the value in the `Response` column is 1, then assign a value of 7 to the `Scores_corrected_v2` column.\n\n```{r}\nsats_t1 <- sats_t1 %>% \n  mutate(Scores_corrected_v2 = case_when(\n    FW_RV == \"Reverse\" & Response == 1 ~ 7,\n    FW_RV == \"Reverse\" & Response == 2 ~ 6,\n    FW_RV == \"Reverse\" & Response == 3 ~ 5,\n    # no need to recode 4 as 4\n    FW_RV == \"Reverse\" & Response == 5 ~ 3,\n    FW_RV == \"Reverse\" & Response == 6 ~ 2,\n    FW_RV == \"Reverse\" & Response == 7 ~ 1,\n    .default = Response\n  ))\n```\n\nAs you can see now in `sats_t1`, both columns `Scores_corrected` and `Scores_corrected_v2` are identical.\n\n:::\n\nOne way to **check whether our reverse-coding worked** is by examining the `distinct` values in the original `Response` column and comparing them with the `Scores_corrected`. We should also retain the `FW_RV` column to observe how the reverse-coding applied.\n\nTo see the patterns more clearly, we can use `arrange()` to sort the values in a meaningful order. Remember, the default sorting order is ascending, so if you want to sort values in descending order, youâ€™ll need to wrap your variable in the `desc()` function.\n\n```{r}\ncheck_coding <- sats_t1 %>% \n  distinct(FW_RV, Response, Scores_corrected) %>% \n  arrange(desc(FW_RV), Response)\n```\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Show `check_coding` output\n\n```{r}\ncheck_coding\n```\n\n:::\n\n#### Step 5 {.unnumbered}\n\nNow that we know everything worked out as intended, we can calculate the mean scores of each subscale for each participant in `sats_t1`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hint\n\n```{r eval=FALSE}\nsats_t1 <- sats_t1 %>% \n  group_by(???, ???) %>% \n  summarise(mean_score = ???(???)) %>% \n  ungroup()\n```\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n```{r}\nsats_t1 <- sats_t1 %>% \n  group_by(Code, Subscale) %>% \n  summarise(mean_score = mean(Scores_corrected)) %>% \n  ungroup()\n```\n\n:::\n\n:::\n\n#### Step 6 {.unnumbered}\n\nThe final step is to transform the data back into wide format, ensuring that each subscale has its own column. This will make it easier to join the data objects later on. In `pivot_wider()`, the first argument, `names_from`, specifies the column you want to use for your new column headings. The second argument, `values_from`, tells R which column should provide the cell values.\n\nWe should also **rename the column names** to match those in the codebook. Conveniently, we can use a function called `rename()` that works exactly like `select()` (following the pattern `new_name = old_name`), but it keeps all other column names the same rather than reducing the number of columns.\n\n```{r}\nsats_t1 <- sats_t1 %>% \n  pivot_wider(names_from = Subscale, values_from = mean_score) %>% \n  rename(SATS28_Affect_Time1_mean = Affect,\n         SATS28_CognitiveCompetence_Time1_mean = CognitiveCompetence,\n         SATS28_Value_Time1_mean = Value,\n         SATS28_Difficulty_Time1_mean = Difficulty)\n```\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Show final `sats_t1` output\n\n```{r}\nhead(sats_t1, n = 5)\n```\n\n:::\n\nAgain, this could have been written up as a single pipe.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Single pipe of activity 4\n\n```{r message=FALSE}\nsats_t1 <- data_prp %>% \n  # Step 1\n  select(Code, SATS28_1_Affect_Time1:SATS28_28_Difficulty_Time1) %>% \n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Response\") %>% \n  # Step 3\n  separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\", convert = TRUE) %>% \n  # step 4\n  mutate(FW_RV = case_when(\n    Item_number %in% c(2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28) ~ \"Reverse\",\n    .default = \"Forward\"\n  ),\n    Scores_corrected = case_when(\n      FW_RV == \"Reverse\" ~ 8-Response,\n      .default = Response\n  )) %>% \n  # step 5\n  group_by(Code, Subscale) %>% \n  summarise(mean_score = mean(Scores_corrected)) %>% \n  ungroup() %>% \n  # step 6\n  pivot_wider(names_from = Subscale, values_from = mean_score) %>% \n  rename(SATS28_Affect_Time1_mean = Affect,\n         SATS28_CognitiveCompetence_Time1_mean = CognitiveCompetence,\n         SATS28_Value_Time1_mean = Value,\n         SATS28_Difficulty_Time1_mean = Difficulty)\n```\n\n:::\n\n\n\n## Activity 5 (Error Mode): Perceptions of supervisory support\n\n#### The main goal is to compute the mean score for perceived supervisory support per participant. {.unnumbered}\n\nLooking at the supervisory support data, you determine that\n\n* individual item columns are `r mcq(c(answer = \"numeric\", x = \"character\"))`, and\n* according to the codebook, there are `r mcq(c(x = \"no\", answer = \"some\"))` reverse-coded items in this questionnaire.\n\nI have outlined my steps as follows:\n\n* **Step 1**: Reverse-code the single column first because that's less hassle than having to do that with conditional statements (`Supervisor_15_R`). `mutate()` is my friend.\n* **Step 2**: I want to filter out everyone who failed the attention check in `Supervisor_7`. I can do this with a Boolean expression within the `filter()` function. The correct response was \"completely disagree\" which is 1.\n* **Step 3**: Select their id from time point 2 and all the columns that start with the word \"super\", apart from `Supervisor_7` and the original `Supervisor_15_R` column\n* **Step 4**: pivot into long format so I can calculate the averages better\n* **Step 5**: calculate the average scores per participant\n\nI've started coding but there are some errors in my code. Help me find and fix all of them. Try to go through the code line by line and read the error messages.\n\n```{r super_error, eval=FALSE}\nsuper <- data_ppr %>% \n  mutate(Supervisor_15 = 9-supervisor_15_R) %>% \n  filter(Supervisor_7 = 1) %>% \n  select(Code, starts_with(\"Super\"), -Supervisor_7, -Supervisor_15_R) \npivot_wider(cols = -Code, names_to = \"Item\", values_to = \"Response\") %>% \n  group_by(Time2_Code) %>% \n  summarise(Mean_Supervisor_Support = mean(Score_corrected, na.rm = TRUE)) %>% \n  ungroup()\n\n```\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## How many mistakes am I supposed to find?\n\nThere are 8 mistakes in the code.\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Reveal solution\n\nDid you spot all 8 mistakes? Let's go through them line by line.\n\n```{r super_correct}\nsuper <- data_prp %>% # spelling mistake in data object\n  mutate(Supervisor_15 = 8-Supervisor_15_R) %>% # semantic error: 8 minus response for a 7-point scale and supervisor_15_R needs a capital S\n  filter(Supervisor_7 == 1) %>% # needs a Boolean expression == instead of =\n  select(Code, starts_with(\"Super\"), -Supervisor_7, -Supervisor_15_R) %>% # no pipe at the end, the rest is actually legit\n  pivot_longer(cols = -Code, names_to = \"Item\", values_to = \"Response\") %>% # pivot_longer instead of pivot_wider\n  group_by(Code) %>% # Code rather than Time2_Code - the reduced dataset does not contain Time2_Code\n  summarise(Mean_Supervisor_Support = mean(Response, na.rm = TRUE)) %>% # Score_corrected doesn't exist; needs to be Response\n  ungroup()\n```\n\n* Note that the **semantic error** in line 2 will not give you an error message.\n* Were you thrown off by the `starts_with(\"Super\")` expression in line 4? `starts_with()` and `ends_with()` are great alternatives to selecting columns via `:` But, using `select(Code, Supervisor_1:Supervisor_6, Supervisor_8:Supervisor_14)` would have given us the same result. *[I admit, that one was perhaps a bit mean]*\n\n:::\n\n## Activity 6: Join everything together with `???_join()`\n\nTime to join all the relevant data files into a single dataframe, which will be used in the next chapters on data visualization. There are four ways to join data: `inner_join()`, `left_join()`, `right_join()`, and `full_join()`. Each function behaves differently in terms of what information is retained from the two data objects. Here is a quick overview:\n\n::: {.callout-note icon=\"false\"}\n\n## Info on mutating joins\n\nYou have 4 types of join functions you could make use of. Click on the panels to know more\n\n::: panel-tabset\n\nA mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.\n\n## `inner_join()`\n\n`inner_join()` returns only the rows where the values in the column specified in the `by =` statement match in both tables.\n\n![inner_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/inner-join.gif)\n\n## `left_join()`\n\n`left_join()` retains the complete first (left) table and adds values from the second (right) table that have matching values in the column specified in the `by =` statement. Rows in the left table with no match in the right table will have missing values (`NA`) in the new columns.\n\n![left_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/left-join.gif)\n\n## `right_join()`\n\n`right_join()` retains the complete second (right) table and adds values from the first (left) table that have matching values in the column specified in the `by =` statement. Rows in the right table with no match in the left table will have missing values (`NA`) in the new columns.\n\n![right_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/right-join.gif)\n\n## `full_join()`\n\n`full_join()` returns all rows and all columns from both tables. `NA` values fill unmatched rows.\n\n![full_join(): gif by [Garrick Aden-Buie](https://www.garrickadenbuie.com/project/tidyexplain/){target=\"_blank\"}](images/full-join.gif)\n\n:::\n\n:::\n\nFrom our original `data_prp`, we need to select demographics data and all summarised questionnaire data from time point 2. Next, we will join this with all other aggregated datasets from time point 1 which are currently stored in separate data objects in the `Global Environment`.\n\nWhile you may be familiar with `inner_join()` from last year, for this task, we want to retain all data from all the data objects. Therefore, we will use `full_join()`. Keep in mind, you can only join two data objects at a time, so the upcoming code chunk will involve a fair bit of piping and joining.\n\nNote: Since I (Gaby) like my columns arranged in a meaningful way, I will use `select()` at the end to order them better.\n\n```{r eval=FALSE}\ndata_prp_final <- data_prp %>% \n  select(Code:Plan_prereg, Pre_reg_group:Time2_Understanding_OS) %>% \n  full_join(qrp_t1) %>% \n  full_join(understanding_t1) %>% \n  full_join(sats_t1) %>% \n  full_join(super) %>% \n  select(Code:Plan_prereg, Pre_reg_group, SATS28_Affect_Time1_mean, SATS28_CognitiveCompetence_Time1_mean, SATS28_Value_Time1_mean, SATS28_Difficulty_Time1_mean, QRPs_Acceptance_Time1_mean, Time1_Understanding_OS, Other_OS_behav_2:Time2_Understanding_OS, Mean_Supervisor_Support)\n```\n\n\n::: {.callout-important icon=\"false\"}\n## No `by` argument in the code above? \n\nNote how I didn't include a `by` argument in the code above. If you leave `by =` out, R will join the 2 data objects by **ALL** columns that have the same name.\n\n**Special case 1: matching column names but different values**\n\nIf you want more control, you should include the `by` argument; for example, if both data objects include a column `age` but data was recorded at 2 different time points. In that case, the information from both `age` columns should be retained and the `by` argument would not include `age`.\n\n**Special case 2: different column names but matching values**\n\nAnother special case presents when both data objects contain identical information but the variable names don't match. Let's say, both data objects contain gender information, but in one data object the variable is named `gender` and in the other one `gender_label`. In that case, your `by` argument needs to be modified as: `by = join_by(gender == gender_label)`.\n\nMore info on joins can be found [https://www.tidyverse.org/blog/2023/01/dplyr-1-1-0-joins/](https://www.tidyverse.org/blog/2023/01/dplyr-1-1-0-joins/){target=\"_blank\"}\n:::\n\nAnd this is basically the dataset we need for @sec-dataviz and @sec-dataviz2.\n\n\n\n## Activity 7: Knit and export\n\nKnit the `.Rmd` file to ensure everything runs as expected. Once it does, export the data object `data_prp_final` as a csv for use in the @sec-dataviz. Name it something meaningful, something like `data_prp_for_ch4.csv`.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n```{r eval=FALSE}\nwrite_csv(data_prp_final, \"data_prp_for_ch4.csv\")\n```\n\n:::\n\n\n\n\n## [Test your knowledge and challenge yourself]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n### Knowledge check {.unnumbered}\n\n\n#### Question 1 {.unnumbered}\n\nWhen using `mutate()`, which additional function could you use to recode an existing variable? `r mcq(c(x = \"arrange()\", x = \"filter()\", answer = \"case_match()\", x = \"case_when()\"))`\n\n\n#### Question 2 {.unnumbered}\n\nWhen using `mutate()`, which additional function could you use to create a new variable based on one or multiple conditional statements? `r mcq(c(x = \"arrange()\", x = \"filter()\", x = \"case_match()\", answer = \"case_when()\"))`\n\n\n#### Question 3 {.unnumbered}\n\nWhich of the following functions would you use if you wanted to join two data sets by their shared identifier? `r mcq(c(answer = \"inner_join()\", x = \"left_join()\", x = \"right_join()\", x = \"full_join()\"))`\n\n\n#### Question 4 {.unnumbered}\n\nYour data object contains a column `Score` with numbers, but they have been read in incorrectly as a character datatype. Which of the following functions would *not* work for fixing this issue? `r mcq(c(x = \"parse_number()\", answer = \"factor(Score)\", x = \"mutate(Score = as.numeric(Score))\", x = \"as.numeric()\"))`\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\n* `parse_number()` from the `readr` package extracts numeric values from strings, so this would work.\n* `factor(Score)`: This would *not* work as expected because it converts the column into a factor, not a numeric datatype, leading to incorrect results if numeric operations are needed.\n* `mutate(Score = as.numeric(Score))`: This would work too because `mutate()` can be used in combination with `as.numeric()` to create a new numeric column or override the existing character column.\n* `as.numeric()`: This would also work to convert a character column to numeric. Without mutate, you could use it in a BaseR way, e.g., `data$Score <- as.numeric(data$Score)` (*shudder, BaseR!!! But effective*)\n\n:::\n\n\n\n### Challenge yourself {.unnumbered}\n\n```{r reading in data for me, echo=FALSE, message=FALSE}\nlibrary(tidyverse)\n\ndog_data_raw <- read_csv(\"data/dog_data_raw.csv\")\n```\n\nIf you want to **challenge yourself** and further apply the skills from Chapter 3, you could wrangle the data from `dog_data_raw` ([lab data](data/data_pair_coding.zip \"download\")) for one of the other questionnaires. There are plenty of options to choose from:\n\n::: {.callout-tip collapse=\"true\" icon=\"false\"}\n\n## Difficulty level: easy\n\n* recode column `Live_Pets` so the values read yes and no rather than 1 and 2\n* recode `Year_of_Study` so they have the labels from the codebook rather than the numbers\n* reverse-code the `Homesickness` scale for `_pre` and `_post`\n* renaming the columns of the other one-item scales as `Stress_pre`, `Stress_post`, `Engagement_pre` and `Engagement_post`\n\nAny of these tasks should be doable in one step. No need to select or pivot anything. You could just modify `dog_data_raw`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n* For the **recoding tasks**, you need to work out which function to use to recode one value as another - just plain replacing, no conditional statements\n* The **reverse-coding** might sound daunting to do in one step, but it is only a single value that needs to be recoded. Take some inspiration from Activity 5 (error mode).\n* For the **renaming tasks**, check how you would change column names without reducing the number of columns overall\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for **Challenge yourself - easy**\n\n```{r eval=FALSE}\n## Live_Pets\ndog_data_raw <- dog_data_raw %>%\n  mutate(Live_Pets = case_match(Live_Pets,\n                                1 ~ \"yes\",\n                                2 ~ \"no\"))\n```\n\n```{r eval=FALSE}\n## Year of Study\ndog_data_raw <- dog_data_raw %>%\n  mutate(Year_of_Study = case_match(Year_of_Study,\n                                    1 ~ \"First\",\n                                    2 ~ \"Second\",\n                                    3 ~ \"Third\",\n                                    4 ~ \"Fourth\",\n                                    5 ~ \"Fifth or above\"))\n```\n\n```{r eval=FALSE}\n## Reverse-coding of homesickness pre and post. It's a 5-point scale, hence you'd calculate 6-the original response column\ndog_data_raw <- dog_data_raw %>% \n  mutate(Homesick_pre = 6-HO1_1,\n         Homesick_post = 6-HO2_1)\n```\n\n```{r eval=FALSE}\n## Renaming of Stress and Engagement\ndog_data_raw <- dog_data_raw %>% \n  rename(Stress_pre = S1_1, Stress_post = S2_1, Engagement_pre = HO1_2, Engagement_post = HO2_2)\n```\n:::\n:::\n\n::: {.callout-warning collapse=\"true\" icon=\"false\"}\n\n## Difficulty level: medium\n\n* reverse-code the Social connectedness scale (pre-intervention) and compute a mean score per participant\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\nThis task would take 4 steps to complete. These are the exact same steps we applied to `Loneliness_pre` in the lab activity. You would just need to figure out which items are related to the Social connectedness scale (pre-intervention) and which ones of those are reverse-coded. The codebook has all the answers.\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for **Challenge yourself - medium**\n\n```{r eval=FALSE}\n## SCS pre\nscs_pre <- dog_data_raw %>% \n  select(RID, starts_with(\"SC1\")) %>% \n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %>% \n  mutate(Score_corrected = case_when(\n    Names %in% c(\"SC1_3\", \"SC1_6\", \"SC1_7\", \"SC1_9\", \"SC1_11\", \"SC1_13\", \"SC1_15\", \"SC1_17\", \"SC1_18\", \"SC1_20\") ~ 7-Response,\n    .default = Response\n    )) %>% \n  group_by(RID) %>% \n  summarise(SCS_pre = mean(Score_corrected, na.rm = TRUE)) %>% \n  ungroup()\n\n```\n:::\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Difficulty level: hard\n\n* reverse-code the Loneliness scale (post-intervention) and compute a mean score per participant\n* reverse-code the Social connectedness scale (post-intervention) and compute a mean score per participant\n\nBoth activities are similar to Activity 3 from the individual walkthrough and would take about 5 steps to complete. **Start by mapping out the steps**.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n* **Step 1**: Select all relevant columns, such as participant ID and all the items that belong to the questionnaire that participants completed after the intervention\n* **Step 2**: Pivot the data from wide format to long format so we can reverse-score and calculate the average score more easily\n* **Step 3**: Recode the initial responses so that the new column has numbers instead of labels\n* **Step 4**: Reverse-score the items that are labelled as \"Reverse\" in the codebook and then reverse-score them\n* **Step 5**: Group by and summarise to calculate the mean Score\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for **Challenge yourself - hard**\n\n```{r eval=FALSE}\n## loneliness post\nlonely_post <- dog_data_raw %>% \n  # Step 1\n  select(RID, starts_with(\"L2\")) %>% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %>% \n  # Step 3\n  mutate(Score = case_match(Response,\n                            \"never\" ~ 1,\n                            \"rarely\" ~ 2,\n                            \"sometimes\" ~ 3,\n                            \"often\" ~ 4,\n                            .default = NA\n  ),\n  # Step 4 - we are still in the same mutate function (count the brackets)\n        Score_corrected = case_when(\n          Names %in% c(\"L2_1\", \"L2_5\", \"L2_6\", \"L2_9\", \"L2_10\", \"L2_15\", \"L2_16\", \"L2_19\", \"L2_20\") ~ 5-Score,\n          .default = Score\n  )) %>% \n  # Step 5\n  group_by(RID) %>% \n  summarise(Loneliness_post = mean(Score_corrected, na.rm = TRUE)) %>% \n  ungroup()\n\n```\n\n```{r eval=FALSE}\n## SCS post\nscs_post <- dog_data_raw %>% \n  # Step 1\n  select(RID, starts_with(\"SC2\")) %>% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %>% \n  # Step 3\n  mutate(Response = case_match(Response,\n                               \"strongly disagree\" ~ \"1\",\n                               \"strongly agree\" ~ \"6\",\n                               .default = Response),\n         Response = parse_number(Response),\n  # Step 4 - we are still in the same mutate function (count the brackets)\n         Score_corrected = case_when(\n           Names %in% c(\"SC2_3\", \"SC2_6\", \"SC2_7\", \"SC2_9\", \"SC2_11\", \"SC2_13\", \"SC2_15\", \"SC2_17\", \"SC2_18\", \"SC2_20\") ~ 7-Response,\n           .default = Response\n         )) %>% \n  # Step 5\n  group_by(RID) %>% \n  summarise(SCS_post = mean(Score_corrected, na.rm = TRUE)) %>% \n  ungroup()\n```\n:::\n:::\n\n::: {.callout-important collapse=\"true\" icon=\"false\"}\n\n## Difficulty level: extra hard\n\n* PANAS: positive and negative affect of pre- and post-intervention in a single pipe rather than in 4 different data objects (see last week's)\n\nThis task would take about 7 steps to get it from\n\n```{r echo=FALSE}\nPANAS <- dog_data_raw %>% \n  select(RID, starts_with(\"PN\"))\n\nhead(PANAS, n = 5)\n```\n\nto\n\n```{r echo=FALSE, message=FALSE}\nPANAS <- dog_data_raw %>% \n  # Step 1\n  select(RID, starts_with(\"PN\")) %>% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %>% \n  # Step 3\n  separate(Items, into = c(\"Stage\", \"Item_number\"), sep = \"_\", convert = TRUE) %>% \n  # Step 4 recode Stage\n  mutate(Stage = case_match(Stage,\n                            \"PN1\" ~ \"pre\",\n                            \"PN2\" ~ \"post\")) %>% \n  # Step 5 identify subscales by item number\n  mutate(Subscales = case_when(\n    Item_number %in% c(3, 5, 7, 8, 10) ~ \"PANAS_PA\",\n    .default = \"PANAS_NA\"\n  )) %>% \n  # Step 6 \n  group_by(RID, Stage, Subscales) %>% \n  summarise(Score = mean(Scores)) %>% \n  ungroup() %>% \n  # Step 7 - to make the data look like the data in `dog_data_clean_long.csv`\n  pivot_wider(names_from = Subscales, values_from = Score)\n\nhead(PANAS, n = 5)\n```\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n**Start by mapping out the steps**\n\n* **Step 1**: select all relevant columns, such as participant ID and all the items that belong to PANAs scale (pos, neg, pre, and post)\n* **Step 2**: pivot the data from wide format to long format. You want to do that for ALL columns that are not the participant id. The data object should have 3 columns and 5680 observations, i.e. each participant has 20 rows.\n* **Step 3**: All of the items will have the structure `PN1_1`. Use separate to split the information across 2 columns. First column has information about the `Stage`, second column should turn into an `Item_number` and it should convert into a numeric column in the process to save you typing quotation marks in Step 5.\\\n* **Step 4**: recode the `Stage` column you just created so that everything that starts with PN1 relates to \"pre\" and PN2 as post.\n* **Step 5**: identify the subscales positive affect (PA) and negative affect (NA) by item number and recode them. This requires a conditional statement.\n* **Step 6**: group by and summarise to calculate the mean Score\n* **Step 7**: pivot, so that you have the 2 PANAS subscales presented in separate columns (see table above). You might need an extra step if the columns aren't labelled exactly as shown in the table above.\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for **Challenge yourself - extra hard**\n\n```{r eval=FALSE}\nPANAS <- dog_data_raw %>% \n  # Step 1\n  select(RID, starts_with(\"PN\")) %>% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %>% \n  # Step 3\n  separate(Items, into = c(\"Stage\", \"Item_number\"), sep = \"_\", convert = TRUE) %>% \n  # Step 4 recode Stage\n  mutate(Stage = case_match(Stage,\n                            \"PN1\" ~ \"pre\",\n                            \"PN2\" ~ \"post\")) %>% \n  # Step 5 identify subscales by item number\n  mutate(Subscales = case_when(\n    Item_number %in% c(3, 5, 7, 8, 10) ~ \"PANAS_PA\",\n    .default = \"PANAS_NA\"\n  )) %>% \n  # Step 6 \n  group_by(RID, Stage, Subscales) %>% \n  summarise(Score = mean(Scores)) %>% \n  ungroup() %>% \n  # Step 7 - to make the data look like the data in `dog_data_clean_long.csv`\n  pivot_wider(names_from = Subscales, values_from = Score)\n```\n:::\n:::\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"kable","error":false,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"wrap","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["https://use.fontawesome.com/releases/v5.13.0/css/all.css","include/booktem.css","include/webex.css","include/glossary.css","include/style.css","include/custom.scss","include/styles.css"],"highlight-style":"a11y","include-after-body":["include/webex.js","include/script.js"],"output-file":"03-wrangling2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.5.57","lightbox":true,"bibliography":["include/references.bib"],"csl":"include/apa.csl","minimal":true,"theme":{"light":["flatly","include/light.scss"],"dark":["darkly","include/dark.scss"]},"code-annotations":false,"anchor-sections":false,"code-copy":"hover","mainfont":"","monofont":""},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}