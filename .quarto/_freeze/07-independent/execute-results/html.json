{
  "hash": "666b549d129a84e090fb7cdfc8774e3a",
  "result": {
    "markdown": "# Two-sample t-test {#sec-independent}\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nIn this chapter, we will focus on two-sample t-tests, also known as between-groups, between-subjects, or independent-samples t-tests. By the end of this chapter, you should be able to:\n\n- Compute a two-sample t-test and effectively report the results.\n- Understand when to use a non-parametric equivalent of the two-sample t-test, compute it, and report the results.\n\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n## Activity 1: Setup & download the data\n\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\n* **Create a new project** and name it something meaningful (e.g., \"2A_chapter7\", or \"07_independent_ttest\"). See @sec-project if you need some guidance.\n* **Create a new `.Rmd` file** and save it to your project folder. See @sec-rmd if you get stuck. \n* Delete everything after the setup code chunk (e.g., line 12 and below)\n* **Download the reduced version of a new dataset** here: [data_ch7.zip](data/data_ch7.zip \"download\"). The zip folder includes the following files:\n  * CodebookSimonTask.xlsx: A codebook with detailed variable descriptions\n  * DemoSimonTask.csv: A CSV file containing demographic information\n  * MeanSimonTask.csv: A CSV file with the mean response times\n  * Sup_Mats_Simon_Task.docx: A Word document with Supplementary Materials providing additional details about the task\n  * RawDataSimonTask.csv: The raw data file, allowing you to explore what experimental data looks like prior to pre-processing.\n* Extract the data files from the zip folder and place them in your project folder. If you need help, see @sec-download_data_ch1.\n\n\n**Citation**\n\n> Zwaan, R. A., Pecher, D., Paolacci, G., Bouwmeester, S., Verkoeijen, P., Dijkstra, K., & Zeelenberg, R. (2018). Participant nonnaiveté and the reproducibility of cognitive psychology. *Psychonomic Bulletin & Review, 25*, 1968-1972. [https://doi.org/10.3758/s13423-017-1348-y](https://doi.org/10.3758/s13423-017-1348-y){target=\"_blank\"}\n\nThe data and supplementary materials are available on OSF: [https://osf.io/ghv6m/](https://osf.io/ghv6m/){target=\"_blank\"}\n\n**Abstract**\n\n> Many argue that there is a reproducibility crisis in psychology. We investigated nine well-known effects from the cognitive psychology literature—three each from the domains of perception/action, memory, and language, respectively—and found that they are highly reproducible. Not only can they be reproduced in online environments, but they also can be reproduced with nonnaïve participants with no reduction of effect size. Apparently, some cognitive tasks are so constraining that they encapsulate behavior from external influences, such as testing situation and prior recent experience with the experiment to yield highly robust effects.\n\n\n\n**Changes made to the dataset**\n\n* The dataset, demographic information, and Supplementary Materials have been reduced to include only information related to the Simon Task. The full dataset, which includes the other eight tasks, is available on OSF.\n* No other changes were made.\n\n\n## Activity 2: Library and data for today\n\nToday, we’ll be using the following packages: `rstatix`, `tidyverse`, `car`, `lsr`, and `pwr`. You may need to install the packages before using them (see @sec-install_packages if you need some help). Make sure that `rstatix` is loaded in before `tidyverse` to avoid masking certain functions that we will need later.\n\nWe will also read in the data from `MeansSimonTask.csv`  and the demographic information from `DemoSimonTask.csv`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load in the packages\n???\n\n# read in the data\nzwaan_data <- ???\nzwaan_demo <- ???\n```\n:::\n\n\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load in the packages\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(car)\nlibrary(lsr)\nlibrary(pwr)\n\n# read in the data\nzwaan_data <- read_csv(\"MeansSimonTask.csv\")\nzwaan_demo <- read_csv(\"DemoSimonTask.csv\")\n```\n:::\n\n\n:::\n\n## Activity 3: Familiarise yourself with the data\n\nAs usual, take some time to familiarise yourself with the data before starting on the between-subjects t-test. Also, more importantly, have a look at the Supplementary Materials in which the Simon effect is explained in more depth.\n\nIn general, **the Simon effect** refers to the phenomenon where participants respond faster when the stimulus appears on the same side of the screen as the button they need to press (i.e., a congruent condition). Conversely, response times are slower when the stimulus appears on the opposite side of the screen from the required button (i.e., an incongruent condition).\n\nIn this experiment, all participants completed two sessions of trials. However, they were divided into two groups based on the stimuli they received:\n\n* **Same Stimuli Group**: Half of the participants received the same set of stimuli in both sessions.\n* **Different Stimuli Group**: The other half received a different set of stimuli in session 2 compared to session 1.\n\n### Potential research questions and hypotheses\n\n* **Potential research question**: “Is there a significant difference in the Simon effect between participants who received the same stimuli in both sessions compared to those who received different stimuli?”\n* **Null Hypothesis (H~0~)**: \"There is no significant difference in the Simon effect between participants who received the same stimuli in both sessions and those who received different stimuli.\"\n* **Alternative Hypothesis (H~1~)**: \"There is a significant difference in the Simon effect between participants who received the same stimuli in both sessions and those who received different stimuli.\"\n\n\n\n## Activity 4: Preparing the dataframe\n\nThe data is already in a very good shape, however, we need to perform some data wrangling to compute the Simon effect.\n\n\n**Steps to calculate the Simon effect:**\n\n1. For each participant, **compute the mean response time (RT)** for congruent trials and the mean RT for incongruent trials\n2. Subtract the mean RT of congruent trials from the mean RT of incongruent trials to **calculate the Simon effect**\n\nTo streamline analysis, we should join this output with the demographics data to have all relevant information in one place.\n\nBasically, we want to create a tibble that has the following content. *[Note that I re-arranged the columns and re-labelled some of them in a final step, so your column names and/or order might be slightly different, but content should match.]*\n\n\n::: {.cell}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|participant |gender | age|education          |similarity | congruent| incongruent| simon_effect|\n|:-----------|:------|---:|:------------------|:----------|---------:|-----------:|------------:|\n|T1          |Female |  50|High school        |same       |  475.0032|    508.2835|     33.28029|\n|T10         |Male   |  45|Associate's degree |same       |  420.1515|    401.5800|    -18.57148|\n|T109        |Male   |  33|Bachelor's degree  |same       |  339.5343|    375.7152|     36.18085|\n|T11         |Female |  71|High school        |same       |  516.9722|    542.3111|     25.33889|\n|T111        |Female |  34|High school        |same       |  373.5778|    394.0665|     20.48874|\n\n</div>\n:::\n:::\n\n\nObviously, there are various ways to achieve this, so feel free to explore and come up with your own approach. However, we will provide step-by-step instructions for one of those ways that will get you the desired output.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n* **Step 1**: Convert the data from wide format to long format, so that all RT values are consolidated into a single column. This transformation will result in each participant having four rows.\n* **Step 2**: There should be a column now that contained the previous column headings with information on session number and congruency. Separate this information into 2 separate columns (i.e., session number and congruency).\n* **Step 3**: Compute the mean RT values for each combination of `participant`, `similarity`, and `congruency`\n* **Step 4**: Pivot the data back to wide format so that the mean RT values for congruent and incongruent trials are placed in two separate columns.\n* **Step 5**: Add a new column called the `simon_effect` that calculates the Simon effect by subtracting the mean RT for congruent trials from the mean RT for incongruent trials.\n* **Step 6**: Merge this processed dataset with the demographics data to ensure all relevant information is in one table.\n* **Step 7**: Feel free to rearrange the order of columns and/or rename them to match your output with ours (not strictly necessary tbh)\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution to the steps outlined above\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimon_effect <- zwaan_data %>% \n  pivot_longer(cols = session1_congruent:session2_incongruent, names_to = \"col_headings\", values_to = \"RT\") %>% \n  separate(col_headings, into = c(\"Session_number\", \"congruency\"), sep = \"_\") %>% \n  group_by(participant, similarity, congruency) %>% \n  summarise(mean_RT = mean(RT)) %>% \n  ungroup() %>% \n  pivot_wider(names_from = congruency, values_from = mean_RT) %>% \n  mutate(simon_effect = incongruent - congruent) %>% \n  full_join(zwaan_demo, by = join_by(participant == twosubjectnumber)) %>% \n  select(participant, gender = gender_response, age = age_response, education = education_response, similarity:simon_effect)\n```\n:::\n\n\n:::\n\n:::\n\n\n## Activity 5: Compute descriptives\n\nNext, we want to compute number of participants (**n**), **means** and **standard deviations** for each group (i.e., `same` and `different`) of our variable of interest (i.e., `simon_effect`).\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescriptives <- simon_effect %>% \n  group_by(similarity) %>% \n  summarise(n = n(),\n            mean_RT = mean(simon_effect),\n            sd_RT = sd(simon_effect)) %>% \n  ungroup()\n\ndescriptives\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|similarity |  n|  mean_RT|    sd_RT|\n|:----------|--:|--------:|--------:|\n|different  | 80| 32.85726| 20.79313|\n|same       | 80| 35.99415| 22.39601|\n\n</div>\n:::\n:::\n\n\n:::\n\n\n## Activity 6: Create an appropriate plot\n\nWhich plot would you choose to represent the data appropriately? Create a plot that effectively visualises the data, and then compare it with the solution provided below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.4, alpha = 0.8) +\n  scale_fill_viridis_d(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"Similarity\", y = \"Simon effect\")\n```\n\n::: {.cell-output-display}\n![](07-independent_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n:::\n\n## Activity 7: Check assumptions\n\n#### Assumption 1: Continuous DV {.unnumbered}\n\nThe dependent variable must be measured at interval or ratio level. We can confirm that by looking at `simon_effect`. \n\n\n#### Assumption 2: Data are independent {.unnumbered}\n\nThere should be no relationship between the observations. Scores in one condition or observation should not influence scores in another. We assume this assumption holds for our data.\n\n\n#### Assumption 3: Homoscedasticity (homogeneity of variance) {.unnumbered}\n\nThis assumption requires the variances between the two groups to be similar (i.e., homoscedasticity). If the variances between the 2 groups are dissimilar/unequal, we have heteroscedasticity.\n\nWe can test this using a **Levene’s Test for Equality of Variance** which is available in the package `car`. The first argument specifies the formula in the format `DV ~ IV`. Here:\n\n* The dependent variable (DV) is `simon_effect` (continuous)\n* The independent variable (IV) is `similarity` (the grouping variable)\n\nTo perform the test, separate the variables with a tilde (`~`), and specify the dataset using the `data` argument:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleveneTest(simon_effect ~ similarity, data = simon_effect)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n```\n:::\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|      |  Df|   F value|    Pr(>F)|\n|:-----|---:|---------:|---------:|\n|group |   1| 0.7263221| 0.3953679|\n|      | 158|        NA|        NA|\n\n</div>\n:::\n:::\n\n\nThe warning message tells us that the grouping variable was converted into a factor. Oops, I guess we forgot to convert `similarity` into a factor during data wrangling.\n\nThe test output shows a **p-value greater than .05**. This indicates that we do not have enough evidence to reject the null hypothesis. Therefore, the variances across the two groups can be assumed equal.\n\nYou would report this result in APA style: A Levene's test of homogeneity of variances was used to compare the variances of the same and the different groups. The test indicated that the variances were homogeneous, $F(1,158) = 0.73, p = .395$.\n\n::: {.callout-important}\n\nThe t-test we are conducting is a Welch t-test by default. The Welch t-test provides similar results to a Student’s t-test when variances are equal but is preferred when variances are unequal.\n\nThis means that even if Levene’s test returns a significant p-value, indicating that the variances between the groups are unequal, the Welch t-test remains appropriate and valid for analysis.\n\n:::\n\n\n\n#### Assumption 4: DV should be approximately normally distributed {.unnumbered}\n\nIt’s important to note that this assumption requires the **dependent variable to be normally distributed within each group**.\n\nWe can either use our eyeballs again on the violin-boxplot we created earlier (or use a qqplot, density plot, or histogram instead), OR compute a statistic like the Shapiro-Wilk's test we already mentioned previously for the one-sample t-test. However, keep in mind that with large sample sizes (approximately 80 participants per group), this test may flag minor deviations from normality as significant, even if the data is reasonably normal.\n\n\nVisual inspection suggests that both groups are approximately normally distributed. The **\"same\" group** appears slightly more normally distributed than the **\"different\" group**, which has a small peak in the lower tail. Despite this, both distributions seem normal enough for practical purposes with real-world data.\n\n::: {.callout-tip} \n\n## Tip: Visual inspection\n\nIf you want to use a histogram, density plot or qqplot (the ones created with the `ggplot2` and `qqplotr` packages), you can simply add a `facet_wrap()` function to display the plots separately for each group. \n\nIf you are using the Q-Q plot function from the `car` package, you will need to create separate data objects filtered for each group before generating Q-Q plots for the groups individually.\n\n:::\n\n::: {.callout-note icon=\"false\"} \n\n## Task: Compute Shapiro-Wilk's test\n\nAs mentioned above, the function for the **Shapiro-Wilk's test** does not allow for a formula. This means you will need to create separate data objects for the two groups first. Consider this a good opportunity to practice using the `filter()` function.\n\n**Step-by-step instructions**: \n\n1. Create separate data objects for the same and different groups.\n2. Run the Shapiro-Wilk test on each group’s data.\n3. Examine the results. What do you conclude from the test outcomes?\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## same group\nsame <- simon_effect %>% \n  filter(similarity == \"same\")\n\nshapiro.test(same$simon_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  same$simon_effect\nW = 0.98921, p-value = 0.7447\n```\n:::\n\n```{.r .cell-code}\n## different group\ndifferent <- simon_effect %>% \n  filter(similarity == \"different\")\n\nshapiro.test(different$simon_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  different$simon_effect\nW = 0.96949, p-value = 0.05262\n```\n:::\n:::\n\n\n**Interpretation:**\n\nShapiro-Wilk's test also suggests that the data for both groups, \"same\" and \"different\", are normally distributed as all p-values are above .05. \n\nAgain, if you used this method in your report, you would have to write up the results in APA style (refer to the section on the one-sample t-test for guidance on reporting).\n\n:::\n\n:::\n\n\n::: {.callout-important}\n\nIf you have read the Delacre et al. (2017) paper ([https://rips-irsp.com/articles/10.5334/irsp.82](https://rips-irsp.com/articles/10.5334/irsp.82){target=\"_blank\"}), you might be aware that the **normality assumption is not critical for the Welch t-test**.\n\nThis means that, whether you consider both groups to be \"normally distributed\" or interpret one as slightly deviating from normality, the Welch t-test remains an appropriate choice for this dataset.\n\n:::\n\nAfter verifying all the assumptions, we concluded that they were met. Therefore, we will compute a **Welch two-sample t-test**.\n\n\n\n\n\n## Activity 8: Compute a Two-sample t-test and effect size\n\nThe `t.test()` function, which we previously used for the one-sample t-test, can also be used here, but with a slightly different approach. It supports a formula option, which simplifies the process. This means we don’t need to wrangle the data further or use the `$` operator to access columns directly. Instead, we can specify the formula as `DV ~ IV`.\n\nThe key arguments for `t.test()` are:\n\n* The first argument in the formula with the pattern `DV ~ IV`\n* The second argument is the data\n* The third argument is specifying whether variances are equal between the groups. The default value is `var.equal = FALSE`, which conducts a **Welch t-test**. If you set `var.equal = TRUE`, you would conduct a Student t-test instead.\n* The 4th argument `alternative` specifies the alternative hypothesis. The default value is \"two.sided\", meaning the test will check for differences in both directions (i.e., a non-directional hypothesis)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(simon_effect ~ similarity, data = simon_effect, var.equal = FALSE, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  simon_effect by similarity\nt = -0.91809, df = 157.14, p-value = 0.36\nalternative hypothesis: true difference in means between group different and group same is not equal to 0\n95 percent confidence interval:\n -9.885574  3.611799\nsample estimates:\nmean in group different      mean in group same \n               32.85726                35.99415 \n```\n:::\n:::\n\n\nThe output of the `t.test()` function tells us:\n\n* the **type of test** that was conducted (here Welch t-test)\n* the **variables** that were tested (here `simon_effect` by `similarity`), \n* the **t-value**, **degrees of freedom**, and **p**,\n* the **alternative hypothesis** tested, \n* a **95% confidence interval** for the difference between group means, and\n* the **mean of both groups** (which should match our descriptive stats)\n\n\nThe `t.test()` function does not calculate an **effect size**, so we have to compute it separately once again. As with the one-sample t-test, we can use the `CohensD()` function from the `lsr` package. The formula-based approach works here too. For the **Welch version** of the t-test, you need to include the argument `method = \"unequal\"` in the `CohensD()` function to account for unequal variances.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohensD(simon_effect ~ similarity, data = simon_effect, method = \"unequal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1451628\n```\n:::\n:::\n\n\n\n## Activity 9: Sensitivity power analysis\n\nNext, we will conduct a **sensitivity power analysis** to determine the minimum effect size that could have been reliably detected with our sample size, an alpha level of 0.05, and a power of 0.8.\n\nTo perform this analysis, we use the `pwr.t.test()` from the `pwr` package. The arguments are the same as those used for the one-sample t-test, but with a few adjustments:\n\n* **Number of Participants**: Specify the number of observations per sample (i.e., n)\n* **Test Type**: Set the `type` argument to \"two.sample\" for a two-sample t-test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(n = 80, sig.level = 0.05, power = 0.8, type = \"two.sample\", alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 80\n              d = 0.445672\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\nSooo, the smallest effect size we can detect with a sample size of 80 participants in each group, an alpha level of .05, and power of .8 is **0.45**. Our observed effect size was only 0.15 (calculated with the `CohensD()` function). Because the observed effect is smaller than the smallest detectable effect, the analysis is underpowered, meaning it is unlikely to detect such a small effect reliably.\n\n#### Hypothetical Replication Study {.unnumbered}\n\nOut of curiosity, if we were to replicate this study and wanted to reliably detect an effect size as small as **0.15**, how many participants would we need?\n\nWe can use the `pwr.t.test()` function again. This time, instead of specifying `n`, we provide the effect size (`d = 0.145`). The result shows that we would need approximately **1,500 participants in total** (750 per group). Ooft; that's quite a few people to recruit.\n\nHowever, it’s worth noting that an effect size of 0.15 may not be practically meaningful, even if statistically detectable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(d = 0.145, sig.level = 0.05, power = 0.8, type = \"two.sample\", alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Two-sample t test power calculation \n\n              n = 747.5833\n              d = 0.145\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n:::\n:::\n\n\n\n::: {.callout-tip}\n\n## But my two groups have unequal sample sizes, and there is only one n in `pwr.t.test`. What do I do?\n\nNo problem! You can use the `pwr.t2n.test()` function, which allows you to specify different sample sizes for the two groups (`n1` and `n2`). \n\nThe rest of the arguments are essentially the same as with `pwr.t.test()`. Additionally, there is no need to specify the `type` argument, as the function is specifically designed for two-sample t-tests with unequal sample sizes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t2n.test(n1 = NULL, n2= NULL, d = NULL, sig.level = 0.05, power = NULL, alternative = c(\"two.sided\", \"less\",\"greater\"))\n```\n:::\n\n\nLet's try it for our example. We should get the same result though.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t2n.test(n1 = 80, n2= 80, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     t test power calculation \n\n             n1 = 80\n             n2 = 80\n              d = 0.445672\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n:::\n:::\n\n\n:::\n\n\n## Activity 10: The write-up\n\nWe hypothesised that there would be a significant difference in the Simon effect between participants who received the same stimuli in both sessions $(N = 80, M = 35.99 \\ \\text{msec}, SD = 22.40 \\ \\text{msec})$ and those who received different stimuli $(N = 80, M = 32.86 \\ \\text{msec}, SD = 20.79 \\ \\text{msec})$. A Welch two-sample  t-test revealed the small effect to be non-significant, $t(157.14) = 0.92, p = .360, d = 0.15$. Therefore, we fail to reject the null hypothesis. However, the analysis was underpowered to reliably detect such a small effect.\n\n\n## Activity 11: Non-parametric alternative {#sec-alternative_two_sample}\n\nThe **Mann-Whitney U-test** is the non-parametric equivalent of the independent two-sample t-test. It is used to compare the medians of two samples and is particularly useful when the assumptions of the t-test are not met.\n\nAccording to Delacre et al. (2017), the Mann-Whitney U-test is robust to violations of normality but remains sensitive to heteroscedasticity. In this case, we don’t need to worry about heteroscedasticity, as the variances in the two groups are equal. However, it’s important to keep this in mind when assessing assumptions and interpreting results with other datasets.\n\n\nFirst, let's start by computing some **summary statistics** for each group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsimon_effect %>% \n  group_by(similarity) %>% \n  summarise(n = n(), \n            median = median(simon_effect))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|similarity |  n|   median|\n|:----------|--:|--------:|\n|different  | 80| 34.44134|\n|same       | 80| 35.68470|\n\n</div>\n:::\n:::\n\n\n\nTo **conduct a Mann-Whitney U-test**, use the `wilcox.test()` function. As with the independent t-test, you can use the formula approach `DV ~ IV`. The code structure is identical to what we used for the independent t-test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(simon_effect ~ similarity, data = simon_effect)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  simon_effect by similarity\nW = 3001, p-value = 0.4981\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\n\nWe should compute the **standardised test statistic Z** manually. To do this, use the `qnorm()` function on the halved p-value obtained from the Wilcoxon test conducted earlier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# storing the p-value\np_wilcoxon <- wilcox.test(simon_effect ~ similarity, data = simon_effect)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.6774047\n```\n:::\n:::\n\n\n\nThe **effect size** for the Mann-Whitney U-test is **r**. To compute r, we'd need the standardised test statistic z and divide that the square-root of the number of pairs n: $r = \\frac{|z|}{\\sqrt n}$. \n\nAlternatively, you can use the `wilcox_effsize()` function from the `rstatix` package to simplify the process.\n\nThe arguments for this function are slightly different in order but otherwise identical to those used in the `wilcox.test()` function above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox_effsize(data = simon_effect, formula = simon_effect ~ similarity)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.y.          |group1    |group2 |   effsize| n1| n2|magnitude |\n|:------------|:---------|:------|---------:|--:|--:|:---------|\n|simon_effect |different |same   | 0.0536884| 80| 80|small     |\n\n</div>\n:::\n:::\n\n\nThis is once again considered a small effect. Anyway, we do have all the numbers now to **write up the results**:\n\n\nA Mann-Whitney U-test was conducted to determine whether there was a significant difference in the Simon effect between participants who received the same stimuli in both sessions $(N = 80, Mdn = 35.68 \\ \\text{msec})$ and those who received different stimuli $(N = 80, Mdn = 34.44 \\ \\text{msec})$. The results indicate that the median difference in response time was non-significant and of small magnitude, $W = 3001, Z = -0.68, p = .498, r = .054$. Therefore, we fail to reject the null hypothesis.\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n#### Question 1 {.unnumbered}\n\n**What is the main purpose of an independent t-test?**\n\n<div class='webex-radiogroup' id='radio_FREVRLVDJV'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FREVRLVDJV\" value=\"answer\"></input> <span>To compare means between two independent groups</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FREVRLVDJV\" value=\"x\"></input> <span>To assess the correlation between two continuous variables</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FREVRLVDJV\" value=\"x\"></input> <span>To test for differences in variances between two independent groups</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_FREVRLVDJV\" value=\"x\"></input> <span>To compare means between two related groups</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe independent t-test is specifically designed to compare the means of two separate (independent) groups to determine whether the difference between their means is statistically significant. For example, it could be used to compare the test scores of students who received two different teaching methods (Group 1 vs. Group 2).\n\n:::\n\n#### Question 2 {.unnumbered}\n\n**Which of the following is a key assumption of the two-sample t-test that should be considered?**\n\n<div class='webex-radiogroup' id='radio_LVAXDXMGYE'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LVAXDXMGYE\" value=\"x\"></input> <span>The sample sizes must be equal</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LVAXDXMGYE\" value=\"x\"></input> <span>The dependent variable is categorical</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LVAXDXMGYE\" value=\"answer\"></input> <span>The observations are independent of each other</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LVAXDXMGYE\" value=\"x\"></input> <span>The independent variable is normally distributed</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nIndependence of observations is a crucial assumption for the two-sample t-test. It means that the data collected from one participant should not influence the data from another participant.\n\n:::\n\n\n#### Question 3 {.unnumbered}\n\n**How can you recognise the difference between the output of a Student’s t-test and a Welch t-test?**\n\n<div class='webex-radiogroup' id='radio_PNFYADSVKF'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PNFYADSVKF\" value=\"x\"></input> <span>The Welch t-test reports an effect size directly, while the Student’s t-test does not.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PNFYADSVKF\" value=\"x\"></input> <span>The Welch t-test uses medians instead of means, unlike the Student’s t-test.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PNFYADSVKF\" value=\"x\"></input> <span>The Welch t-test includes a confidence interval, while the Student’s t-test does not.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PNFYADSVKF\" value=\"answer\"></input> <span>The Welch t-test reports non-integer degrees of freedom, while the Student’s t-test reports integer degrees of freedom.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe Welch t-test adjusts for unequal variances and sample sizes, which leads to non-integer degrees of freedom. In contrast, the Student’s t-test assumes equal variances and reports integer degrees of freedom based on total sample size minus the number of groups.\n\nThe other options are incorrect: \n\n* Both tests report confidence intervals for the mean difference.\n* Both tests compare means, not medians.\n* Neither test reports effect size directly; it must be calculated separately (e.g., using Cohen’s d).\n\n:::\n\n\n\n#### Question 4 {.unnumbered}\n\n**You perform an independent t-test and find $t(48)=2.10,p=.042,d=0.58$. How would you interpret these results?**\n\n<div class='webex-radiogroup' id='radio_AYPWLVGKVP'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AYPWLVGKVP\" value=\"x\"></input> <span>There is a significant difference between the two groups, with a small effect size.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AYPWLVGKVP\" value=\"answer\"></input> <span>There is a significant difference between the two groups, with a medium effect size.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AYPWLVGKVP\" value=\"x\"></input> <span>There is a significant difference between the two groups, with a large effect size.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AYPWLVGKVP\" value=\"x\"></input> <span>There is no significant difference between the two groups</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe p-value ($p=.042$) is less than the common significance threshold of 0.05, indicating that the difference between the two groups is statistically significant. This means we reject the null hypothesis and conclude that there is evidence of a difference between the group means.\n\n:::\n\n\n",
    "supporting": [
      "07-independent_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}