{
  "hash": "11a341c2d6f0c8f91c622c810a688b59",
  "result": {
    "engine": "knitr",
    "markdown": "\n# Chi-square and one-sample t-test  {#sec-nhstI}\n\n\n\n\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n-   compute a Cross-tabulation Chi-square test and report the results\n-   compute a one-sample t-test and report the results\n-   understand when to use a non-parametric equivalent for the one-sample t-test, compute it, and report the results\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n## Overview {.unnumbered}\n\nFrom here on, we will explore inferential statistics, including chi-square test, various t-tests, correlations, ANOVAs, and regression. Most of these tests belong to the General Linear Model (GLM) family, which helps us analyse relationships between variables using linear equations. The chi-square test, while not part of the GLM, is also included here as it’s useful for analysing categorical data.\n\nTo help you choose the most appropriate test, refer to the simplified flowchart below. It guides you based on the types of variables - whether they are categorical or continuous.\n\n\n![Simplified flowchart to help select the most appropriate test (created with [drawio](https://draw.io/){target=\"_blank\"}). To view a larger version, click on the image or click [here](images/Flowchart_tests_drawio.png){target=\"_blank\"}](images/Flowchart_tests_drawio.png)\n\nEach test is discussed in its respective chapter with guidance on when and how to apply it:\n\n* Cross-tabulation chi-Square test (this chapter, @sec-chi_square)\n* One-sample t-test (this chapter, @sec-onesample)\n* Two-sample or independent t-test (between-subjects design, @sec-independent) \n* Paired t-test (within-subjects design, @sec-paired)\n* Correlation (@sec-cor)\n* Simple regression (@sec-reg)\n* Multiple regression (@sec-reg_mult)\n* One-way ANOVA (@sec-oneway)\n* Factorial ANOVA (@sec-factorial)\n\n\n## Activity 1: Setup & download the data\n\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\n* **Create a new project** and name it something meaningful (e.g., \"2A_chapter6\", or \"06_chi_square_one_sample_t\"). See @sec-project if you need some guidance.\n* **Create a new `.Rmd` file** and save it to your project folder. See @sec-rmd if you get stuck. \n* Delete everything after the setup code chunk (e.g., line 12 and below)\n* **Download the new dataset** here: [data_ch6.zip](data/data_ch6.zip \"download\"). This zip file contains one csv file with demographic information and questionnaire data as well as and Excel codebook.\n* Extract the data files from the zip folder and place them directly in your project folder (next to the project icon, not in a subfolder). For more help, see @sec-download_data_ch1.\n\n\n**Citation**\n\n> Ballou, N., Vuorre, M., Hakman, T., Magnusson, K., & Przybylski, A. K. (2024, July 12). Perceived value of video games, but not hours played, predicts mental well-being in adult Nintendo players. [https://doi.org/10.31234/osf.io/3srcw](https://doi.org/10.31234/osf.io/3srcw){target=\"_blank\"}\n\n\nAs you can see, the study is a pre-print published on PsyArXiv Preprints. The data and supplementary materials are available on OSF: [https://osf.io/6xkdg/](https://osf.io/6xkdg/){target=\"_blank\"}\n\n\n**Abstract**\n\n> Studies on video games and well-being often rely on self-report measures or data from a single game. Here, we study how 703 US adults’ time spent playing for over 140,000 hours across 150 Nintendo Switch games relates to their life satisfaction, affect, depressive symptoms, and general mental well-being. We replicate previous findings that playtime over the past two weeks does not predict well-being, and extend these findings to a wider range of timescales (one hour to one year). Results suggest that relationships, if present, dissipate within two hours of gameplay. Our non-causal findings suggest substantial confounding would be needed to shift a meaningful true effect to the observed null. Although playtime was not related to well-being, players’ assessments of the value of game time—so called gaming life fit—was. Results emphasise the importance of defining the gaming population of interest, collecting data from more than one game, and focusing on how players integrate gaming into their lives rather than the amount of time spent.\n\n\n\n**Changes made to the dataset**\n\n* We extracted key demographic variables from the rich dataset, including age, gender, ethnicity, employment, education level, and scores from the Warwick-Edinburgh Mental Wellbeing Scale.\n* We removed rows with missing values and categorical groupings with low observed frequencies for the purpose of this chapter.\n* We won’t explore any associations related to gaming, but feel free to download the full dataset if you wish to investigate further.\n* Unlike the original study, which applied strict inclusion criteria, we used more flexible criteria, resulting in a larger sample size than the original analysis.\n\n\n## Activity 2: Load in the library, read in the data, and familiarise yourself with the data\n\nToday, we will be using the following packages: `tidyverse`, `lsr`, `scales`, `qqplotr`, `car`, `pwr`, and `rcompanion`. If you need to install any of them, do so via the console (see @sec-install_packages for more detail). \n\nAdditionally, we will need to read in the data `data_ballou_reduced`. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load in the packages\n???\n\n# read in the data\ndata_ballou <- ???\n```\n:::\n\n\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load in the packages\nlibrary(tidyverse)\nlibrary(lsr)\nlibrary(scales)\nlibrary(qqplotr)\nlibrary(car)\nlibrary(pwr)\nlibrary(rcompanion)\n\n# read in the data\ndata_ballou <- read_csv(\"data_ballou_reduced.csv\")\n```\n:::\n\n\n\n\n:::\n\n\n## Activity 3: Data wrangling\n\nThe categorical variables in our dataset look tidy, but we need to make a few adjustments to prepare for our analysis:\n\n* **Convert `gender` and `education_level` into factors** in the original `data_ballou` object. Our statistical tests require these variables to be factors, and converting them will also help with sorting categories effectively for plotting. Feel free to arrange the categories in a meaningful order.\n* Create a new data object called `data_wemwbs` to **calculate the total score for the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS**): According to the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"}, the individual item scores should be summed to get the total. \n* **Join** the the original `data_ballou` dataset with the new `data_wemwbs` dataset to have all the information in one place.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"} \n\n## Hints\n\n* We converted categorical variables into factors previously in @sec-dataviz - refer back if you need a refresher\n* Check how we handled the `QRPs` questionnaire in @sec-wrangling for guidance on aggregating scores \n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_wemwbs <- data_ballou %>% \n  pivot_longer(cols = wemwbs_1:wemwbs_14, names_to = \"Questions\", values_to = \"Scores\") %>% \n  group_by(pid) %>% \n  summarise(wemwbs_sum = sum(Scores))\n\ndata_ballou <- data_ballou %>% \n  mutate(gender = factor(gender,\n                         levels = c(\"Woman\", \"Man\", \"Non-binary\")),\n         eduLevel = factor(eduLevel,\n                           levels = c(\"Completed Secondary School\", \"Some University but no degree\", \"University Bachelors Degree\", \"Vocational or Similar\", \"Graduate or professional degree (MA, MS, MBA, PhD, etc)\"))) %>% \n  left_join(data_wemwbs)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(pid)`\n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n:::\n\n\n## Activity 4: Cross-tabulation Chi-square test {#sec-chi_square}\n\nA Cross-Tabulation Chi-Square Test, also known as a Chi-Square Test of Association or Independence, tests how one variable is associated with the distribution of outcomes in another variable.\n\nWe will be performing a Chi-Square test using the categorical variables **gender** and **eduLevel**:\n\n* **Potential research question**: \"Is there an association between gender and level of education in the population?\"\n* **Null Hypothesis (H~0~)**: \"Gender and level of education are independent; there is no association between gender and level of education.\"\n* **Alternative Hypothesis (H~1~)**: \"Gender and level of education are not independent; there is an association between gender and level of education.\"\n\n\n\n### Task 1: Preparing the dataframe\n\nFirst, select your variables of interest - here participant id, gender, and education levels. This dataset does not contain missing values, but in future datasets that might, use `drop_na()` to remove them before converting categorical variables into factors.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_square <- data_ballou %>% \n  select(pid, gender, eduLevel)\n```\n:::\n\n\n\n\n\n### Task 2: Compute descriptives\n\nNext, we need to calculate counts for each combination of the variables, which is best done in a frequency table - or more precisely a **contingency table** since we are looking at a combination of 2 categorical variables (sometimes they are called crosstabulation and two-way tables). \n\nThis will also allow us to verify that there are no missing values in any cells, as the function we’re using cannot handle missing values\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_square_frequency <- chi_square %>% \n  count(gender, eduLevel) %>% \n  pivot_wider(names_from = eduLevel, values_from = n)\n\nchi_square_frequency\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gender     | Completed Secondary School| Some University but no degree| University Bachelors Degree| Vocational or Similar| Graduate or professional degree (MA, MS, MBA, PhD, etc)|\n|:----------|--------------------------:|-----------------------------:|---------------------------:|---------------------:|-------------------------------------------------------:|\n|Woman      |                         63|                           118|                         169|                    42|                                                      65|\n|Man        |                         70|                           125|                         250|                    34|                                                      81|\n|Non-binary |                          9|                            23|                          20|                     4|                                                      10|\n\n</div>\n:::\n:::\n\n\n\n\nWe should be fine here, even though the count for the non-binary/vocational category is quite low.\n\n\n### Task 3: Check assumptions\n\n\n#### Assumption 1: Categorical data {.unnumbered}\n\nBoth variables should be categorical, measured at either the ordinal or nominal level.\n\nWe can confirm that for our dataset. Gender is <select class='webex-select'><option value='blank'></option><option value='x'>ordinal</option><option value='answer'>nominal</option></select>, and level of education is <select class='webex-select'><option value='blank'></option><option value='answer'>ordinal</option><option value='x'>nominal</option></select>.\n\n\n#### Assumption 2: Independent observartions {.unnumbered}\n\nEach observation in the dataset has to be independent, meaning the value of one observation does not affect the value of any other. \n\nAnd we assume as much for our data.\n\n\n\n#### Assumption 3: Cells in the contingency table are mutually exclusive {.unnumbered}\n\nEach individual can belong to only one cell in the contingency table. We can confirm this by examining the data and reviewing the contingency table.\n\n\n#### Assumption 4: Expected frequencies are sufficiently large {.unnumbered}\n\nAssumption 4 is not an assumption that is listed consistently across various sources. When it is, it suggests that expected frequencies are larger than 5 or at least 80% of the the expected frequencies are above 5 and none of them are below 1. However, Danielle Navarro points out that this seems to be a \"somewhat conservative\" criterion and should be taken as \"rough guidelines\" only (see [https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions](https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions){target=\"_blank\"}.\n\nThis is information, we can either compute manually (see lecture slides) or wait till we get the output from the inferential statistics later.\n\n\n### Task 4: Create an appropriate plot\n\nNow we can create the appropriate plot. Which plot would you choose when building one from object `chi_square`? A <select class='webex-select'><option value='blank'></option><option value='answer'>Barchart</option><option value='x'>Histogram</option><option value='x'>Scatterplot</option><option value='x'>Violin-Boxplot</option></select> with geom layer <select class='webex-select'><option value='blank'></option><option value='x'>geom_col</option><option value='answer'>geom_bar</option><option value='x'>geom_histogram</option><option value='x'>geom_point</option><option value='x'>geom_boxplot and geom_violin</option></select>\n\n\nTry creating the plot on your own before checking the solution. Feel free to practice adding different layers to make the plot pretty!\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## One possible solution\n\n... is a grouped bar chart.\n\nI played about with the labels of the x-axis categories since the graduate label is super long. Google was my friend in this instance and showed me a nifty function called `label_wrap()` from the `scales` package which automatically inserts line breaks after a set number of characters. Setting it to 12 characters looked best. (See other options for long labels at [https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/](https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/){target=\"_blank\"}).\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(chi_square, aes(x = eduLevel, fill = gender)) +\n  geom_bar(position = \"dodge\") + \n  scale_fill_viridis_d(name = \"Gender\") +\n  scale_x_discrete(name = \"Level of Education\",\n                   labels = label_wrap(12)) +\n  scale_y_continuous(name = \"Count\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\n\n\n\n### Task 5: Compute a chi-square test\n\n\nBefore we can do that, we need to turn our tibble into a dataframe - the `associationTest()` function we are using to compute the Chi-square test does not like tibbles. [*you have nooooo clue how long that took to figure out - let's say the error message was not exactly helpful*]\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_square_df <- as.data.frame(chi_square)\n```\n:::\n\n\n\n\n\nNow we can run the `associationTest()` function from the `lsr` package. The first argument is a formula. It starts with a `~` followed by the two variables you want to associate, separated by a `+`. The second argument is the dataframe.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nassociationTest(formula = ~ eduLevel + gender, data = chi_square_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in associationTest(formula = ~eduLevel + gender, data = chi_square_df):\nExpected frequencies too small: chi-squared approximation may be incorrect\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Chi-square test of categorical association\n\nVariables:   eduLevel, gender \n\nHypotheses: \n   null:        variables are independent of one another\n   alternative: some contingency exists between variables\n\nObserved contingency table:\n                                                         gender\neduLevel                                                  Woman Man Non-binary\n  Completed Secondary School                                 63  70          9\n  Some University but no degree                             118 125         23\n  University Bachelors Degree                               169 250         20\n  Vocational or Similar                                      42  34          4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)    65  81         10\n\nExpected contingency table under the null hypothesis:\n                                                         gender\neduLevel                                                  Woman   Man\n  Completed Secondary School                               59.9  73.4\n  Some University but no degree                           112.2 137.5\n  University Bachelors Degree                             185.2 227.0\n  Vocational or Similar                                    33.8  41.4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)  65.8  80.7\n                                                         gender\neduLevel                                                  Non-binary\n  Completed Secondary School                                    8.65\n  Some University but no degree                                16.21\n  University Bachelors Degree                                  26.75\n  Vocational or Similar                                         4.88\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)       9.51\n\nTest results: \n   X-squared statistic:  13.594 \n   degrees of freedom:  8 \n   p-value:  0.093 \n\nOther information: \n   estimated effect size (Cramer's v):  0.079 \n   warning: expected frequencies too small, results may be inaccurate\n```\n\n\n:::\n:::\n\n\n\n\n\nThe output is quite informative as it gives information about:\n\n* the variables that were tested, \n* the null and alternative hypotheses, \n* a table with the observed frequencies (which matches our calculations in `chi_square_frequency` without the rows/columns of the missing values we removed), \n* an output of the frequencies you'd expect if the null hypothesis were true, \n* the result of the hypothesis test, and \n* the effect size Cramer's v.\n\nIt also gives us a **warning message** saying that expected frequencies are too small and that the chi-squared approximation may be incorrect. This relates to Assumption 4. Depending on your stance on Assumption 4, you may choose to either address or ignore this warning.\n\nThe p-value indicates that we do not reject the null hypothesis, as it is greater than 0.05.\n\n\n### Task 6: Sensitivity power analysis\n\nA **sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect** given the number of participants you have in the sample (i.e., sample size), the alpha level at 0.05, and an assumed power of 0.8. Remember, power analysis relies on four key factors — alpha, power, effect size, and sample size (APES). If you know three of these, you can calculate the fourth.\n\n\nFor a Chi-square test, we use the `pwr.chisq.test()` function from the `pwr` package. In this case, we already know the alpha, power, and sample size, and we want to calculate the smallest effect size detectable with this design. The function also requires the degrees of freedom (`df`), which tells `R` how many groups are being compared. You can find the `df` value in the output of your Chi-square test (e.g., from `associationTest()`).\n\nThe key arguments for this function are:\n\n* `w` = Effect size (Cohen's omega, ⍵). *(Leave this one out to calculate it.)*\n* `N` = Total number of observations.\n* `df` = Degree of freedom (from your Chi-square test).\n* `sig.level` = The significance level of the study (usually set to 0.05). \n* `power` = The power level of the study (usually set to 0.8).\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.chisq.test(N = 1083,\n               df = 8,\n               sig.level = 0.05,\n               power = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Chi squared power calculation \n\n              w = 0.1178008\n              N = 1083\n             df = 8\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: N is the number of observations\n```\n\n\n:::\n:::\n\n\n\n\nThis output gives us the smallest effect size detectable with this design. To interpret it, we need to compare it with the effect size from our test output. However, there’s a catch: the power analysis reports Cohen’s omega (⍵), while the Chi-square test reports Cramer’s V. To make them comparable, we need to convert Cramer’s V into Cohen’s omega.\n\nThe formula to do so is: \n\n$$\nCohen's \\; \\omega = Cramer's \\; V * \\sqrt(k-1)\n$$\n\nwhere `k` s the number of categories in the variable with fewer levels.\n\nFor example, if one variable has 3 levels (e.g., `gender`) and the other has 5 (e.g., `eduLevel`), then `k = 3`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nw = 0.079 * sqrt(3-1)\n\nw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1117229\n```\n\n\n:::\n:::\n\n\n\n\n\n**Comparison:**\n\nWith 1,083 observations, alpha = 0.05, and power = 0.8, the smallest detectable effect size is `⍵ = 0.118. Our calculated effect size from the Chi-square test was ⍵ = 0.112. Because 0.112 is smaller than 0.118, our study is slightly underpowered, meaning there’s a higher risk of missing an effect that actually exists (a Type II error). In this case, because our Chi-square test was non-significant, the lack of significance might reflect low power rather than the true absence of an effect.\n\n\n\n::: {.callout-note}\n\nIf one of your categorical variables only has 2 levels (e.g., yes/no), then Cramer’s V and Cohen’s ⍵ are identical. In that case, you can compare them directly:\n\n* if Cohen's ⍵ (sensitivity) < Cramer's V (observed), your design is sufficiently powered.\n* if Cramer's V (observed) < Cohen's ⍵ (sensitivity), your study is underpowered, and you should be cautious about drawing strong conclusions.\n\n:::\n\n\n\n### Task 7: The write-up\n\nThe Cross-Tabulation Chi-Square Test revealed a small association between Gender and Level of Education that was not statistically significant, $\\chi^2(8) = 13.59, p = .093, V = .079$. We therefore fail to reject the null hypothesis. However, a sensitivity power analysis indicated that the study was slightly underpowered, which means the non-significant result may reflect limited power rather than the true absence of an association.\n\n\n\n\n\n## Activity 5: One-sample t-test {#sec-onesample}\n\nThe one-sample t-test is used to determine whether a sample comes from a population with a specific mean. This population mean is not always known, but is sometimes hypothesised. \n\nWe will perform a one-sample t-test using the continuous variable **wemwbs_sum**. The [official website for the Warwick-Edinburgh Mental Wellbeing Scales](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"} states that the \"WEMWBS has a mean score of 51.0 in general population samples in the UK with a standard deviation of 7 (Tennant et al., 2007)\".\n\n* **Potential research question**: \"Is the average mental well-being of gamers different from the general population's average well-being?\"\n* **Null Hypothesis (H~0~)**: \"The summed-up WEMWBS score of gamers is not different to 51.0.\"\n* **Alternative Hypothesis (H~1~)**: \"The summed-up WEMWBS score of gamers is different from 51.0.\"\n\n\n### Task 1: Preparing the dataframe\n\nFirst, we need to select the variables of interest: participant ID and `wemwbs_sum`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\none_sample <- data_ballou %>% \n  select(pid, wemwbs_sum)\n```\n:::\n\n\n\n\n\n### Task 2: Compute descriptives\n\nNext, we want to compute means and standard deviations for our variable of interest. This should be straight forward. Try it yourself and then compare your result with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescriptives <- one_sample %>% \n  summarise(mean_wemwbs = mean(wemwbs_sum),\n            sd = sd(wemwbs_sum))\n\ndescriptives\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| mean_wemwbs|       sd|\n|-----------:|--------:|\n|    45.42013| 10.88615|\n\n</div>\n:::\n:::\n\n\n\n\n:::\n\n\n### Task 3: Create an appropriate plot\n\nThis is the plot you will want to include in your report, so make sure everything is clearly labelled. Which plot would you choose? Try creating one on your own first, then compare it with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = \"\", y = wemwbs_sum)) +\n  geom_violin(fill = \"#FB8D61\", alpha = 0.4) + # alpha for opacity, fill for adding colour\n  geom_boxplot(fill = \"#FB8D61\", width = 0.5) + # change width of the boxes\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Total WEMWBS Scores\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\n\n\n### Task 4: Check assumptions\n\n\n#### Assumption 1: Continuous DV {.unnumbered}\n\nThe dependent variable (DV) needs to be measured at interval or ratio level. We can confirm that by looking at `one_sample`. \n\n\n\n#### Assumption 2: Data are independent {.unnumbered}\n\nThere should be no relationship between the observations. While this is an important assumption, it is more related to study design and isn’t something we can easily test for. Anyway, we will assume this assumption holds for our data.\n\n\n\n#### Assumption 3: No significant outliers {.unnumbered}\n\nWe can check for that visually, for example in the violin-boxplot above. \n\nIt appears there is one outlier in the lower tail. However, upon inspecting the `one_sample` data, we see it is a single participant with a score of 14, which is a possible value. Additionally, with a large sample size of 1,083 participants, removing a single outlier makes not much sense. Thus, we have checked this assumption, considered this outlier not significant, and therefore keep this observation in the dataset.\n\n::: {.callout-important} \n\nIf you decide to remove any outliers, remember to recalculate the descriptive statistics.\n\n:::\n\n#### Assumption 4: DV should be approximately normally distributed {.unnumbered}\n\nWe can already check normality from the violin-boxplot above but you could also use a histogram, a density plot, or a Q-Q plot as an alternative to assess normality visually.\n\nEach of these options shows that **the data is normally distributed**. This allows us to proceed with a parametric test, specifically a one-sample t-test.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Alternatives to visually assess normality\n\n::: {.panel-tabset}\n\n## Histogram\n\nWe've already covered histograms in @sec-dataviz2. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_histogram(binwidth = 1, fill = \"magenta\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n## Density plot\n\nA density plot shows a smooth distribution curve of the data. Unlike a histogram, the height of the curve reflects the proportion of data within each range rather than the frequency of individual values. This means the curve shows where data points are concentrated, not how many times each value appears.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_density(fill = \"magenta\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Q-Q plot\n\nQ-Q plot stands for Quantile-Quantile Plot and compare two distributions by matching a common set of quantiles. Essentially, it compares the distribution of your data to a normal distribution and plots the points along a 45-degree line.\n\n**If the dots in the Q-Q plot fall roughly along that line, we can assume the data is normally distributed. If they stray away from the line (and worse in some sort of pattern), we might not assume normality and conduct a non-parametric test instead. For the non-parametric equivalent, see @sec-alternative_one_sample.**\n\nTo create the Q-Q plot, you can use either the `car` or `qqplotr` package\n\n* The `qqPlot()` function is a single line but requires BaseR syntax (i.e., the `$` symbol) to access the column within the data object. For example, `one_sample$wemwbs_sum` directs R to look for a column named `wemwbs_sum` that is located within the data object `one_sample`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Version 1 with the car package\nqqPlot(one_sample$wemwbs_sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 295 394\n```\n\n\n:::\n\n::: {.cell-output-display}\n![Q-Q plot created with the car package](06-chi-square-one-sample_files/figure-html/fig-qqplot1-1.png){#fig-qqplot1 width=672}\n:::\n:::\n\n\n\n\n* If you have gotten used to ggplot by now, and prefer avoiding BaseR, you can use the package `qqplotr`. The downside is that you have to add the points, the line, and the confidence envelope yourself. On the plus, it has layers like ggplot, and is more customisable (just in case you wanted to look at something more colourful in the 2 seconds it'll take you to assess normality).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Version 2 with package qqplotr\nggplot(one_sample, aes(sample = wemwbs_sum)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n```\n\n::: {.cell-output-display}\n![Q-Q plot created with the qqplotr package](06-chi-square-one-sample_files/figure-html/fig-qqplot2-1.png){#fig-qqplot2 width=672}\n:::\n:::\n\n\n\n\n:::\n\n:::\n\n\nYou could also assess normality with the **Shapiro-Wilk’s test**. The null hypothesis is that the population is distributed normally. Therefore, if the p-value of the Shapiro-Wilk’s test smaller than .05, normality is rejected. \n\n::: {.callout-important}\n\nShapiro-Wilk is an OK method for small sample sizes (e.g., smaller than 50 samples) if the deviation from normality is fairly obvious. If we are dealing with slight deviations from normality, it might not be sensitive enough to pick that up. But t-tests, ANOVAs etc. should be robust for slight deviations from normality anyway.\n\nIn contrast, when you have large sample sizes, Shapiro-Wilk is overly sensitive and will definitely produce a significant p-value regardless of what the distribution looks like. So don't rely on its output when you have large sample sizes, and be mindful of its output when you have small sample sizes.\n\n:::\n\nThe function in R for this test is `shapiro.test()` which is part of BaseR. This means, we need to specify our data object, use the `$`, and indicate the column we want to address.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(one_sample$wemwbs_sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  one_sample$wemwbs_sum\nW = 0.99404, p-value = 0.0002619\n```\n\n\n:::\n:::\n\n\n\n\nNo surprise here! The test shows a p-value of  < .001 due to our large sample size of over 1000 participants. Nevertheless, if you decided on using the Shapiro-Wilk test in your report, you'd need to write this result up in APA style: $W = .99, p < .001$.\n\n\n::: {.callout-tip}\n\n## Report-writing Tip\n\nEither choose visual or computational inspection for normality tests. NO NEED TO DO BOTH!!!\n\n* State what method you used and your reasons for choosing the method (visual/computational and what plot/test you used)\n* State the outcome of the test - for visual inspection just say whether normality assumption held or not (no need to include that extra plot in the results section). For computational methods, report the test result in APA style\n* State the conclusions you draw from it - parametric or non-parametric test\n\n:::\n\n\n\n### Task 5: Compute a One-sample t-test and effect size\n\n\nTo compute a one-sample t-test, we can use the `t.test() function`, which is part of Base R. And yes, you guessed it, our first argument should follow the pattern `data$column`. The second argument, `mu`, specifies the population mean we are testing our sample against (in this case, 51.0). The `alternative` is \"two.sided\" by default, so it can be omitted if you are conducting a two-sided test.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(one_sample$wemwbs_sum, mu = 51.0, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  one_sample$wemwbs_sum\nt = -16.868, df = 1082, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 51\n95 percent confidence interval:\n 44.77106 46.06920\nsample estimates:\nmean of x \n 45.42013 \n```\n\n\n:::\n:::\n\n\n\n\nThe output is quite informative. It provides information about:\n\n* the variable column that was tested, \n* the t value, degrees of freedom, and p,\n* the alternative hypothesis, \n* a 95% confidence interval,\n* and the mean of the column (which matches the one we computed in the descriptive - yay)\n\nWhat it doesn't give us is an **effect size**. Meh. So we will need to compute one ourselves.\n\nWe will calculate **Cohen's d** using the function `cohensD()` from the `lsr` package. Similar to the t-test we just conducted, the first argument is `data$column`, the second argument is `mu`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohensD(one_sample$wemwbs_sum, mu = 51.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5125662\n```\n\n\n:::\n:::\n\n\n\n\n\n### Task 6: Sensitivity power analysis\n\nA **sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect** given the number of participants you have in the sample (i.e., sample size), the alpha level at 0.05, and an assumed power of 0.8. \n\n\nTo perform this calculation, we use the `pwr.t.test()` function from the `pwr` package. This function relies on four key factors — alpha, power, effect size, and sample size (APES). If you know three, you can calculate the fourth. Since we have three specified, we can solve for the effect size. Additionally, we need to specify the `type` argument to indicate we are using a one-sample t-test, and set `alternative` to \"two.sided\" for a non-directional hypothesis.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(n = 1083, sig.level = 0.05, power = 0.8, type = \"one.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     One-sample t test power calculation \n\n              n = 1083\n              d = 0.08520677\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n\n\n:::\n:::\n\n\n\n\nSo the smallest effect size we can detect with a sample size of 1083, an alpha level of 0.05, and power of 0.8 is 0.09. This is a smaller value than the actual effect size we calculated with our CohensD function above (i.e., 0.51) which means our analysis is sufficiently powered.\n\n\n### Task 7: The write-up\n\nA one-sample t-test was computed to determine whether the average mental well-being of gamers as measured by the WEMWBS was different to the population well-being mean. The average WEMWBS of the gamers $(N = 1083, M = 45.42, SD = 10.89)$ was significantly lower than the population mean well-being score of 51.0, $t(1082) = 16.87, p < .001, d = .51$. The strength of the effect is considered medium and the study was sufficiently powered. We therefore reject the null hypothesis in favour of H~1~. \n\n\n\n\n## Activity 6: Non-parametric alternative {#sec-alternative_one_sample}\n\nIf any of the assumptions are violated, switch to the non-parametric alternative. For the one-sample t-test, this would be a **One-sample Wilcoxon signed-rank test**. Instead of the mean, it compares the median of a sample against a single value (i.e., the population median).\n\nThat means we will need to determine the population median, and calculate some **summary stats** for our sample:\n\n* The population median is listed in a supporting document on the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"} as 53.0. \n* We can easily calculate the summary statistics using the function `summary()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(one_sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     pid              wemwbs_sum   \n Length:1083        Min.   :14.00  \n Class :character   1st Qu.:38.00  \n Mode  :character   Median :46.00  \n                    Mean   :45.42  \n                    3rd Qu.:53.00  \n                    Max.   :70.00  \n```\n\n\n:::\n:::\n\n\n\n\n\nThe function to **compute a one-sample Wilcoxon test** is `wilcox.test()` which is part of BaseR. Code-wise, it works very similar to the one-sample t-test.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(one_sample$wemwbs_sum, mu = 53.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  one_sample$wemwbs_sum\nV = 87218, p-value < 2.2e-16\nalternative hypothesis: true location is not equal to 53\n```\n\n\n:::\n:::\n\n\n\n\nAs we can see, the output shows a V value, but for the final write-up, we need to report **the standardised test statistic Z** in the final write-up. Unfortunately, this requires manual calculation. According to Andy Field (2012, p. 665), we need to use the qnorm function on the halved p-value from our Wilcoxon test above. Here, we store the p-value in the `Global Environment` as `p_wilcoxon`. This retains more decimal places than shown in the output, giving us a more precise Z value.\"\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# storing the p-value\np_wilcoxon <- wilcox.test(one_sample$wemwbs_sum, mu = 53.0)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -19.12264\n```\n\n\n:::\n:::\n\n\n\n\n\n\nWe also need to **calculate the effect size `r`** for the One-sample Wilcoxon signed-rank test. This can be done using the `wilcoxonOneSampleR()` function from the `rcompanion` package. By default, the result is rounded to three decimal places, but you can adjust this by adding the `digits` argument.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    r \n-0.59 \n```\n\n\n:::\n:::\n\n\n\n\nNow we have all the numbers we need to **write up the results**: \n\nA One-sample Wilcoxon signed-rank test was used to compare Gamers’ mental-wellbeing median scores (Mdn = 46.0) to the population median of 53.0. The test showed a significant difference, $Z = -19.12, p < .001, r = .590$. The strength of the effect is considered medium. We therefore reject the null hypothesis in favour of H~1~. \n\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n#### Question 1: Conceptual Understanding - Chi-Square Test {.unnumbered}\n\n**What is the primary purpose of a Chi-square test?**\n\n<div class='webex-radiogroup' id='radio_ACWDZDWUZF'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ACWDZDWUZF\" value=\"x\"></input> <span>To assess the correlation between two continuous variables</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ACWDZDWUZF\" value=\"answer\"></input> <span>To test the relationship between categorical variables</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ACWDZDWUZF\" value=\"x\"></input> <span>To test for differences in variances</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ACWDZDWUZF\" value=\"x\"></input> <span>To compare means between two groups</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe Chi-square test evaluates whether there is an association or relationship between two categorical variables. Those variables can either be nominal or ordinal.\n\n:::\n\n#### Question 2: Application - Chi-Square Test {.unnumbered}\n\n**Which of the following scenarios would require a Chi-square test?**\n\n<div class='webex-radiogroup' id='radio_LFEEUSSIVY'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LFEEUSSIVY\" value=\"x\"></input> <span>Comparing the average exam scores of students in two classrooms</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LFEEUSSIVY\" value=\"answer\"></input> <span>Determining if there is an association between people’s favourite pizza topping and their region of residence</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LFEEUSSIVY\" value=\"x\"></input> <span>Testing whether the average height of basketball players differs from the general population</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LFEEUSSIVY\" value=\"x\"></input> <span>Assessing whether the reaction times of drivers are influenced by caffeine consumption</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe only option with 2 categorical variables is pizza topping (e.g., pepperoni, vegetarian, cheese) and region of residence (e.g., North, South, East, West).\n\n:::\n\n\n#### Question 3: Interpreting Output - Chi-Square Test {.unnumbered}\n\n**In a Chi-square test, the p-value is .005. What does this imply if the significance level is set at .05?**\n\n<div class='webex-radiogroup' id='radio_EHUWLNCDUI'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHUWLNCDUI\" value=\"x\"></input> <span>The null hypothesis is rejected; there is no significant association.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHUWLNCDUI\" value=\"x\"></input> <span>The null hypothesis is not rejected; there is a significant association.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHUWLNCDUI\" value=\"x\"></input> <span>The null hypothesis is not rejected; there is no significant association.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHUWLNCDUI\" value=\"answer\"></input> <span>The null hypothesis is rejected; there is a significant association.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nA p-value of .005 is less than the significance level (.05), indicating that the observed association between the variables is unlikely to have happened by chance.\n\n:::\n\n\n\n#### Question 4: Using R - Chi-Square Test {.unnumbered}\n\n**Which of the following R functions is used to perform a Chi-square test and displays a Cramer's V in the output?**\n\n<div class='webex-radiogroup' id='radio_PMTIHRKIYQ'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PMTIHRKIYQ\" value=\"x\"></input> <span>t.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PMTIHRKIYQ\" value=\"x\"></input> <span>one.sample()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PMTIHRKIYQ\" value=\"answer\"></input> <span>associationTest()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PMTIHRKIYQ\" value=\"x\"></input> <span>chisq.test()</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe `associationTest()` function from the `lsr` package performs a Chi-square test and directly provides Cramer's V as part of the output. The `chisq.test()` function exists it but does not compute Cramer's V. The other options either don’t exist or don’t meet the criteria.\n\n:::\n\n\n\n#### Question 5: Conceptual Understanding - One-sample t-test {.unnumbered}\n\n**What is the null hypothesis in a one-sample t-test?**\n\n<div class='webex-radiogroup' id='radio_RMGHFJPEYB'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RMGHFJPEYB\" value=\"answer\"></input> <span>The sample mean is equal to the population mean</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RMGHFJPEYB\" value=\"x\"></input> <span>The sample mean is greater than the population mean</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RMGHFJPEYB\" value=\"x\"></input> <span>The sample mean is less than the population mean</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RMGHFJPEYB\" value=\"x\"></input> <span>The population mean is equal to zero</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe one-sample t-test tests whether the sample mean is significantly different from a known or hypothesised population mean.\n\n:::\n\n#### Question 6: Application - One-sample t-test {.unnumbered}\n\n**Which of the following scenarios would require a one-sample t-test?**\n\n<div class='webex-radiogroup' id='radio_AKUOOVZCMR'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKUOOVZCMR\" value=\"x\"></input> <span>Comparing the average exam scores of students in two classrooms</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKUOOVZCMR\" value=\"x\"></input> <span>Determining if there is an association between people’s favourite pizza topping and their region of residence</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKUOOVZCMR\" value=\"answer\"></input> <span>Testing whether the average height of basketball players differs from the general population</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AKUOOVZCMR\" value=\"x\"></input> <span>Assessing whether the reaction times of drivers are influenced by caffeine consumption</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nA one-sample t-test is appropriate when comparing the mean of a single sample (e.g., basketball players’ heights) to a known or hypothesised population mean (e.g., mean of the general population). The other options involve comparisons between groups (option 1), categorical associations (option 2), or repeated measures (option 4).\n\n:::\n\n\n#### Question 7: Interpreting Output - One-sample t-test {.unnumbered}\n\n**If the p-value in a one-sample t-test is .15 and the significance level is .05, what is the conclusion?**\n\n<div class='webex-radiogroup' id='radio_RJYFTOKTHU'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RJYFTOKTHU\" value=\"answer\"></input> <span>The sample mean is not significantly different from the population mean.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RJYFTOKTHU\" value=\"x\"></input> <span>The sample mean is significantly different from the population mean.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RJYFTOKTHU\" value=\"x\"></input> <span>The sample mean is equal to the population mean.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_RJYFTOKTHU\" value=\"x\"></input> <span>The sample mean is further from the population mean than expected by chance.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nSince the p-value (.15) is greater than the significance level (.05), we fail to reject the null hypothesis. This means there is no evidence to suggest that the sample mean is significantly different from the population mean.\n\nHowever, this does not mean we have evidence to confirm that the sample mean is exactly equal to the population mean. In statistics, 'not significantly different' is not the same as 'equal.' Therefore, the option 'The sample mean is equal to the population mean' is incorrect.\n\n:::\n\n\n\n#### Question 8: Using R - One-sample t-test {.unnumbered}\n\n**Which of the following R functions is used to perform a one-sample t-test?**\n\n<div class='webex-radiogroup' id='radio_EHEEXVMMSX'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHEEXVMMSX\" value=\"answer\"></input> <span>t.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHEEXVMMSX\" value=\"x\"></input> <span>associationTest()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHEEXVMMSX\" value=\"x\"></input> <span>chisq.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_EHEEXVMMSX\" value=\"x\"></input> <span>one.sample()</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\n`t.test()` is the standard function in R for performing a one-sample t-test. In the next 2 weeks, we will see that the function can also be used for two-sample and paired t-tests. \n\nThe function `one.sample()` does not exist. \n\nThe other two functions perform Chi-square tests, which are specifically designed for categorical variables. They cannot be used when one of the variables is continuous.\n\n:::\n\n",
    "supporting": [
      "06-chi-square-one-sample_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}