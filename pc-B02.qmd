# 2B Lab 2 Week 3  {.unnumbered}


```{r include=FALSE}
library(webexercises)
```

**This is the pair coding activity related to @sec-cor.**


## Task 1: Open the R project for the lab {.unnumbered}

## Task 2: Create a new `.Rmd` file {.unnumbered}

... and name it something useful. If you need help, have a look at @sec-rmd.

## Task 3: Load in the library and read in the data {.unnumbered}

The data should already be in your project folder. If you want a fresh copy, you can download the data again here: [data_pair_coding](data/data_pair_coding.zip "download").

We are using the packages `tidyverse` and `correlation` today.
If you have already worked through this chapter, you will have all the packages installed. If you have yet to complete @sec-cor, you will need to install the package `correlation` (see @sec-install_packages for guidance if needed).

We also need to read in `dog_data_clean_wide.csv`. Again, I've named my data object `dog_data_wide` to shorten the name but feel free to use whatever object name sounds intuitive to you. 


```{r reading in data for me, echo=FALSE, message=FALSE}
library(tidyverse)
library(correlation)

dog_data_wide <- read_csv("data/dog_data_clean_wide.csv")

dog_happy <- dog_data_wide %>%
  select(RID, SHS_pre, SHS_post) %>% 
  drop_na() %>% 
  mutate(RID = factor(RID))
```


## Task 4: Tidy data & Selecting variables of interest {.unnumbered}

**Step 1:** Select the variables of interest. We need 2 continuous variables today, so any of the pre- vs post-test comparison will do. I would suggest happiness ratings (i.e., `SHS_pre`, `SHS_post`). Also keep the participant id `RID`. Store them in a new data object called `dog_happy`. 

**Step 2:** Check for missing values and remove participants with missing in either pre- or post-ratings.

**Step 3:** Convert participant ID into a factor

::: {.callout-caution collapse="true" icon="false"}

## Solution for Tasks 3 and 4

```{r eval=FALSE}
## Task 3
library(tidyverse)
library(correlation)

dog_data_wide <- read_csv("dog_data_clean_wide.csv")


## Task 4
dog_happy <- dog_data_wide %>%
  # Step 1
  select(RID, SHS_pre, SHS_post) %>% 
  # Step 2
  drop_na() %>% 
  # Step 3
  mutate(RID = factor(RID))
```

:::

## Task 5: Re-create the scatterplot below {.unnumbered}

```{r echo=FALSE}
ggplot(dog_happy, aes(x = SHS_pre, y = SHS_post)) +
  geom_point() +
  geom_smooth(method = "lm")

```

::: {.callout-caution collapse="true" icon="false"}

## Solution

```{r eval=FALSE, warning=FALSE, message=FALSE}
ggplot(dog_happy, aes(x = SHS_pre, y = SHS_post)) +
  geom_point() +
  geom_smooth(method = "lm")
```
:::

## Task 6: Assumptions check {.unnumbered}

We can either do the assumption check by looking at the scatterplot above or we can run the code `plot(lm(SHS_pre~SHS_post, data = dog_happy))` and assess the assumptions there. Either way, it should give you similar responses.

* Linearity: a `r mcq(sample(c(answer = "linear", x = "non-linear")))` relationship
* Normality: residuals are `r mcq(sample(c(answer = "approximately normally distributed", x = "not normally distributed")))`
* Homoscedasticity: There is `r longmcq(sample(c(answer = "homoscedasticity as there is no distinct pattern in the residuals", x = "heteroscedasticity as the residuals show a distinct pattern")))`
* Outliers: `r mcq(sample(c(answer = "the data does not have any clear outliers", x = "the data has some outliers")))`



**What is your conclusion from the assumptions check?**

`r longmcq(c(answer = "All assumptions hold. Therefore, we are conducting a parametric test, specifically Pearson’s correlation.", x = "Some assumptions are violated. Therefore, we are conducting a non-parametric test, specifically Spearman’s correlation.", x = "All assumptions are violated. Therefore, we are conducting a non-parametric test, specifically Spearman’s correlation."))`



## Task 7: Compute a Pearson correlation & interpret the output {.unnumbered}

* **Step 1**: Compute the Pearson correlation. The structure of the function is as follows:

```{r eval=FALSE}
correlation(data = your_dataframe,
            select = "variable1",
            select2 = "variable2",
            method = "Pearson",
            alternative = "two.sided")
```

The default method argument is Pearson, but if you thought any of the assumptions were violated and conduct a Spearman correlation instead, change the `method` argument to"Spearman".

::: {.callout-caution collapse="true" icon="false"}

## Solution

```{r}
correlation(data = dog_happy,
            select = "SHS_pre",
            select2 = "SHS_post",
            method = "Pearson",
            alternative = "two.sided")
```

```{r eval=FALSE}
# alternative because there are only 2 numeric columns in `dog_happy`
correlation(dog_happy)
```
:::



* **Step 2**: Interpret the output


A Pearson correlation revealed a `r mcq(c(answer = "strong", x = "moderately strong", x = "weak"))`, `r mcq(c(answer = "positive", x = "negative"))`, and statistically `r mcq(c(answer = "significant", x = "non-significant"))` relationship between happiness before and after the dog intervention, *r*(`r fitb("281")`) = `r fitb(c(".88", ".884"))`, *p* `r fitb(c("<.001", "< .001"))`, *95% CI* = [`r fitb(c(".86", ".856"))`, `r fitb(c(".91", ".907"))`]. We therefore `r mcq(c(x = "fail to reject the null hypothesis", answer = "reject the null hypothesis in favour of H1"))`.

::: {.callout-important}
In the write-up paragraph above, the open fields accepted answers with 2 or 3 decimal places as correct. However, in your reports, ensure that correlation values are reported with 3 decimal places.
:::

