{
  "hash": "0d8ef2ce048fdf483df1ff1abdd4af52",
  "result": {
    "engine": "knitr",
    "markdown": "# One-way ANOVA {#sec-oneway}\n\n\n\n\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n- Apply and interpret a one-way ANOVA.\n- Break down the results of a one-way ANOVA using post-hocs tests and apply a correction for multiple comparisons.\n- Conduct a power analysis for a one-way ANOVA.\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n## Activity 1: Setup & download the data\n\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\n* **Create a new project** and name it something meaningful (e.g., \"2B_chapter12\", or \"12_anova\"). See @sec-project if you need some guidance.\n* **Create a new `.Rmd` file** and save it to your project folder. See @sec-rmd if you need help. \n* Delete everything after the setup code chunk (e.g., line 12 and below) \n* **Download the new dataset** here: [data_ch12.zip](data/data_ch12.zip \"download\"). The zip folder includes:\n  * the data file for Experiment 2 (`James_2015_Expt_2.csv`), and the\n  * the codebook for Experiment 2 (`James Holmes Experiment 2 Data Code Book.doc`).\n* Extract the data file from the zip folder and place it in your project folder. If you need help, see @sec-download_data_ch1.\n\n\n**Citation**\n\n> James, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J. R., Milton, A. L., & Holmes, E. A. (2015). Computer Game Play Reduces Intrusive Memories of Experimental Trauma via Reconsolidation-Update Mechanisms. *Psychological Science, 26*(8), 1201-1215. [https://doi.org/10.1177/0956797615583071](https://doi.org/10.1177/0956797615583071){target=\"_blank\"}\n\n\n\n\n**Abstract**\n\n> Memory of a traumatic event becomes consolidated within hours. Intrusive memories can then flash back repeatedly into the mind’s eye and cause distress. We investigated whether reconsolidation—the process during which memories become malleable when recalled—can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions. We predicted that reconsolidation of a reactivated visual memory of experimental trauma could be disrupted by engaging in a visuospatial task that would compete for visual working memory resources. We showed that intrusive memories were virtually abolished by playing the computer game *Tetris* following a memory-reactivation task 24 hr after initial exposure to experimental trauma. Furthermore, both memory reactivation and playing *Tetris* were required to reduce subsequent intrusions (Experiment 2), consistent with reconsolidation-update mechanisms. A simple, noninvasive cognitive-task procedure administered after emotional memory has already consolidated (i.e., > 24 hours after exposure to experimental trauma) may prevent the recurrence of intrusive memories of those emotional events.\n\nThe data is available on OSF: [https://osf.io/ij7ea/](https://osf.io/ij7ea/){target=\"_blank\"}\n\n\n\n**Changes made to the dataset**\n\n* The original SPSS file was converted to CSV format. This time, we downloaded the numeric version of the data, allowing you to practice recoding values.\n* Missing values were coded as 9999.000 in the original data file; however, we replaced them with `NA`.\n\n\n\n## Activity 2: Load in the library, read in the data, and familiarise yourself with the data\n\nToday, we will use several packages: `effectsize`, `rstatix`, `tidyverse`, `qqplotr`, `car`, `emmeans`, and `pwr`, and, of course, the dataset `James_2015_Expt_2.csv`. The order in which the packages are loaded matters today. I believe we have used all of these packages before, but if you need help installing them, see @sec-install_packages for more details.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n???\n\ndata_james <- ???\n```\n:::\n\n\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(effectsize)\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(qqplotr)\nlibrary(car)\nlibrary(emmeans)\nlibrary(pwr)\n\ndata_james <- read_csv(\"James_2015_Expt_2.csv\")\n```\n:::\n\n\n\n\n:::\n\nAs always, take a moment to familiarise yourself with the data before starting your analysis.\n\nOnce you have explored the data objects and the codebook, try answering the following questions: \n\n* How many conditions were included in the experiment? <input class='webex-solveme nospaces' size='1' data-answer='[\"4\"]'/>\n* How many participants were allocated to each condition? <input class='webex-solveme nospaces' size='2' data-answer='[\"18\"]'/>\n* How many of participants were allowed to play *Tetris* during the experiment? <input class='webex-solveme nospaces' size='2' data-answer='[\"36\"]'/>\n* How many visual analogue mood scales did participants complete before the experiment? <input class='webex-solveme nospaces' size='1' data-answer='[\"6\"]'/>\n* Name one of them: <input class='webex-solveme nospaces' size='22' data-answer='[\"pre_film_VAS_Sad\",\"pre_film_VAS_Hopeless\",\"pre_film_VAS_Depressed\",\"pre_film_VAS_Fear\",\"pre_film_VAS_Horror\",\"pre_film_VAS_Anxious\"]'/> *(Hint: Match the spelling exactly.)*\n* Name the column that stores the main outcome variable: <input class='webex-solveme nospaces' size='59' data-answer='[\"Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary\"]'/> *(Hint: You can find the information in the codebook.)*\n\n\n\n## Activity 3: Preparing the dataframe\n\nLet's start by wrangling the data we need for today's analysis:\n\n* Convert the `Condition` column into a factor and replace its values with descriptive labels.\n* Add a column called `Participant_ID`. *This requires using a new function `row_number()` within `mutate()`.*\n* Rename `Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary` to `Intrusions`.\n* Select only the columns `Participant_ID`, `Condition`, and `Intrusions`\n* Store the cleaned dataset as `james_data`.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njames_data <- data_james %>% \n  mutate(Participant_ID = row_number(),\n         Condition = factor(Condition,\n                            labels = c(\"No-Task Control\", \"Reactivation+Tetris\", \"Tetris Only\", \"Reactivation Only\"))) %>% \n  select(Participant_ID, Condition, Intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary)\n```\n:::\n\n\n\n\n:::\n\n\n## Activity 4: Compute descriptives\n\nNow, we can calculate the means and standard deviations for each experimental group.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n## Hints\n\n* Summarise the data to display the mean and standard deviation of intrusive memories, grouped by `Condition`.\n* Your table should contain three columns: `Condition`, `mean`, and `sd`.\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nWe are simply computing the values again rather than storing them. However, if you prefer, you can save the output as an object in your `Global Environment`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\njames_data %>%\n  group_by(Condition) %>%\n  summarise(mean = mean(Intrusions), \n            sd = sd(Intrusions))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Condition           |     mean|       sd|\n|:-------------------|--------:|--------:|\n|No-Task Control     | 5.111111| 4.227207|\n|Reactivation+Tetris | 1.888889| 1.745208|\n|Tetris Only         | 3.888889| 2.887883|\n|Reactivation Only   | 4.833333| 3.329900|\n\n</div>\n:::\n:::\n\n\n\n:::\n\n\n\n## Activity 5: Create an appropriate plot\n\n\nNow, let's visualise the data. The original paper uses a bar plot, but we’ll create a more informative plot instead.\n\n* Generate a violin-boxplot with the number of intrusive memories on the y-axis and experimental group on the x-axis.\n* Rename the y-axis title to *Number of Intrusions*.\n* Feel free to add any additional layers in your own time.\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nHere is one possible solution. The axis title could also have been modified using the `scale_y_continuous()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(james_data, aes(x = Condition, y = Intrusions))+\n  geom_violin()+\n  geom_boxplot(width = 0.2) +\n  labs(y = \"Number of Intrusions\")\n```\n\n::: {.cell-output-display}\n![](12-one-way-anova_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\nThis plot reveals a few potential outliers in each group. This information would be missing in a bar plot. This is why bar plots are not ideal for visualising this type of data.\n\n:::\n\n\n## Activity 6: Store the ANOVA model and check assumptions\n\n### The ANOVA model\n\nBefore testing assumptions, we first need to store the ANOVA model.\n\nFor designs with equal group sizes, we could use the `aov()` function from the `stats` package, which is part of `Base R`. The formula for `aov()` is:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov(DV ~ IV, data)\n```\n:::\n\n\n\n\nHowever, there is a catch. `aov` only supports between-subjects designs. Additionally, it assumes balanced designs (i.e., equal sample sizes in each group; Type I sum of squares). It should not be used for unbalanced designs where group sizes differ.\n\nIn our current design, this is not a concern since we have equal sample sizes and no within-subject variable. However, you may encounter different designs in the future, so we recommend a more flexible approach.\n\nLast week, we saw that the `lm()` function can handle categorical variables. We can apply it here.\n\nThe structure of `lm()` is identical to `aov()`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(DV ~ IV, data)\n```\n:::\n\n\n\n\n\nLet's use this approach with our variables and store the model in a separate object called `mod`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- lm(Intrusions ~ Condition, data = james_data)\n```\n:::\n\n\n\n\n\n\n### Assumption checks\n\nNow that we have stored the model, we can proceed with the assumption checks. For a one-way independent ANOVA, the assumptions are the same as those for an independent t-test.\n\n\n#### Assumption 1: Continuous DV {.unnumbered}\n\nThe dependent variable must be measured at interval or ratio level. We can confirm that by looking at `Intrusions`. \n\n\n#### Assumption 2: Data are independent {.unnumbered}\n\nThere should be no relationship between the observations. Scores in one condition or observation should not influence scores in another. We assume this assumption holds for our data.\n\n\n#### Assumption 3: The residuals of the DV should be normally distributed {.unnumbered}\n\nAgain, this assumption applies to **each group**.\n\nThere are several ways to test normality, and here we will use QQ plots from the `qqplotr` package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(james_data, aes(sample = Intrusions, fill = Condition)) +\n  stat_qq_band(alpha = 0.5) +\n  stat_qq_line() +\n  stat_qq_point() +\n  facet_wrap(~Condition) +\n  theme_bw() +\n  scale_fill_viridis_d()\n```\n\n::: {.cell-output-display}\n![](12-one-way-anova_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\nOverall, the assumption of normality appears to hold.\n\n\n\n#### Assumption 4: Homoscedasticity (homogeneity of variance) {.unnumbered}\n\nThis assumption requires the variances across the four groups to be similar (i.e., homoscedasticity). If the variances differ significantly between groups, this is known as heteroscedasticity.\n\nWe can test this using **Levene’s Test for Equality of Variance**, available in the `car` package. The `leveneTest()` function takes the formula `DV ~ IV` and the data object as arguments. Here’s how to apply it:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleveneTest(Intrusions ~ Condition, data = james_data)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|      | Df|  F value|    Pr(>F)|\n|:-----|--:|--------:|---------:|\n|group |  3| 1.692984| 0.1767091|\n|      | 68|       NA|        NA|\n\n</div>\n:::\n:::\n\n\n\n\nThe test output shows a p-value greater than .05, indicating that we do not have enough evidence to reject the null hypothesis. Therefore, we can assume that the variances across the four groups are equal.\n\nIf reporting Levene’s Test in a report, you would need to follow APA style: \nA Levene’s test of homogeneity of variances was conducted to compare the variances across the groups. The test indicated that the variances were homogeneous, $F(3,67) = 1.69, p = .177$.\n\n\n\n## Activity 7: Compute a one-way ANOVA\n\nWe can compute the ANOVA output using the `anova_test()` function from the `rstatix` package. This function supports both model and formula input and allows additional arguments, such as specifying the type of ANOVA, calculating effect sizes, or manually defining within- or between-subject factors.\n\nMore information can be found on the [rdocumentation support page](https://www.rdocumentation.org/packages/rstatix/versions/0.7.2/topics/anova_test){target=\"_blank\"}\n\n\nIn this example, we will use `anova_test()` on the model `mod`. Since `mod` already contains the data and formula, we only need to specify a few additional arguments:\n\n* `type` specifies the type of sums of squares for ANOVA. The default is `type = 2`, which produces identical results to `type = 1` when data are balanced, but `type = 2` will additionally yield various assumption tests where appropriate.\n* `effect.size` specifies the effect size. Here, we set it to \"pes\" (partial eta squared). Note that for one-way between-subjects designs, partial eta squared is equivalent to eta squared.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_test(mod, type = 2, effect.size = \"pes\")\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Effect    | DFn| DFd|     F|     p|p<.05 |   pes|\n|:---------|---:|---:|-----:|-----:|:-----|-----:|\n|Condition |   3|  68| 3.795| 0.014|*     | 0.143|\n\n</div>\n:::\n:::\n\n\n\n::: {.callout-tip} \n\nLet's explore alternative ways to use the `anova_test()` function. As you will see, these approaches produce exactly the same output as the one above.\n\n::: {.panel-tabset group=\"layers\"}\n## Option 1: Formula approach without a pre-defined model\n\nIf you prefer not to store the model separately, you can directly specify the formula and data within the `anova_test()` function:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_test(data = james_data, \n           formula = Intrusions ~ Condition, \n           type = 2, \n           effect.size = \"pes\")\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Effect    | DFn| DFd|     F|     p|p<.05 |   pes|\n|:---------|---:|---:|-----:|-----:|:-----|-----:|\n|Condition |   3|  68| 3.795| 0.014|*     | 0.143|\n\n</div>\n:::\n:::\n\n\n\n\n## Option 2: Specifying arguments individually\n\nIf the formula approach isn't for you, you can specify the arguments individually.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_test(data, dv, wid, between, type, effect.size)\n```\n:::\n\n\n\n\n* data = The data object.\n* dv = The dependent variable (DV; numeric).\n* wid = The column name of the participant identifier (factor).\n* between = The optional between-subjects factor variables.\n* type = The type of sums of squares for ANOVA.\n* effect.size = The effect size to compute and to show in the ANOVA results.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_test(data = james_data, \n           dv = Intrusions,\n           wid = Participant_ID, \n           between = Condition, \n           type = 2, \n           effect.size = \"pes\")\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Effect    | DFn| DFd|     F|     p|p<.05 |   pes|\n|:---------|---:|---:|-----:|-----:|:-----|-----:|\n|Condition |   3|  68| 3.795| 0.014|*     | 0.143|\n\n</div>\n:::\n:::\n\n\n\n\n\n\n:::\n\n:::\n\n\nThe output may be displayed slightly differently from what you saw in the lecture, but all the necessary numbers are there.\n\n::: {.callout-note icon=\"false\"} \n\n## Your Turn\n\nAnswer the following questions:\n\n* Is the overall effect of Condition significant? <select class='webex-select'><option value='blank'></option><option value='answer'>Yes</option><option value=''>No</option></select>\n\n* What is the F-statistic rounded to 2 decimal places? <input class='webex-solveme nospaces' size='4' data-answer='[\"3.79\"]'/>\n\n* According to the rules of thumb, the effect size is <select class='webex-select'><option value='blank'></option><option value=''>Small</option><option value=''>Medium</option><option value='answer'>Large</option></select>\n\n:::\n\n\n\n::: {.callout-important}\n## What do I do if my One-way ANOVA uses a within-subject design???\n\nYou can still use the `anova_test()` function as shown in Option 2. However, instead of the between argument, you would use the **within argument** to specify the within-subjects factor. The rest of the arguments remain the same as in Option 2.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova_test(data, dv, wid, within, type, effect.size)\n```\n:::\n\n\n\n\nObviously, we cannot run this for a within-subjects design, as today's dataset follows a between-subjects design.\n\n:::\n\n\n\n## Activity 8: Compute post-hoc tests and effect sizes\n\n### Post-hoc comparisons\n\nSo far, we know that the model is significant, meaning there are differences between groups. However, we do not yet know which groups differ from one another.\n\nOne approach would be to run independent Welch t-tests for each pairwise comparison between the four groups  (1 vs 2, 1 vs 3, 1 vs 4, etc.). This would involve some data wrangling (e.g., filtering and dropping factor levels) which is quite time-consuming. Furthermore, we would need to apply corrections for multiple comparisons manually. (Even though, note that the original authors did not mention whether or not they corrected for multiple comparisons.) \n\n\n**A quicker and more efficient way** to perform these comparisons is by using the `emmeans()` function from the `emmeans` package. This function computes all possible pairwise t-tests and automatically applies a correction for multiple comparisons to the p-values.\n\nIn this case, we will use the **Bonferroni adjustment** method.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(mod, \n        pairwise ~ Condition, \n        adjust = \"bonferroni\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$emmeans\n Condition           emmean    SE df lower.CL upper.CL\n No-Task Control       5.11 0.749 68    3.617     6.60\n Reactivation+Tetris   1.89 0.749 68    0.395     3.38\n Tetris Only           3.89 0.749 68    2.395     5.38\n Reactivation Only     4.83 0.749 68    3.340     6.33\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                  estimate   SE df t.ratio p.value\n (No-Task Control) - (Reactivation+Tetris)    3.222 1.06 68   3.044  0.0199\n (No-Task Control) - Tetris Only              1.222 1.06 68   1.155  1.0000\n (No-Task Control) - Reactivation Only        0.278 1.06 68   0.262  1.0000\n (Reactivation+Tetris) - Tetris Only         -2.000 1.06 68  -1.889  0.3787\n (Reactivation+Tetris) - Reactivation Only   -2.944 1.06 68  -2.781  0.0420\n Tetris Only - Reactivation Only             -0.944 1.06 68  -0.892  1.0000\n\nP value adjustment: bonferroni method for 6 tests \n```\n\n\n:::\n:::\n\n\n\n\nThe output consists of two tables:\n\n1. The first one (**$emmeans**) displays the means, standard errors, degrees of freedom, and confidence intervals (referred to as *Confidence Limits* here).\n\n2. The second (**$contrasts**) contains the pairwise comparisons between all groups. The `estimate` represents the difference between groups, `t.ratio` is the t-value, and `p.value` provides the Bonferroni-corrected p-value. Note that there are no asterisks indicating significance - you will need to compare the p-values against the .05 cutoff manually.\n\n### Effect sizes for each comparison\n\nTo compute effect sizes, we can use the `cohens_d` function from the `rstatix` package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohens_d(data = james_data, \n         formula = Intrusions ~ Condition)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|.y.        |group1              |group2              |    effsize| n1| n2|magnitude  |\n|:----------|:-------------------|:-------------------|----------:|--:|--:|:----------|\n|Intrusions |No-Task Control     |Reactivation+Tetris |  0.9964172| 18| 18|large      |\n|Intrusions |No-Task Control     |Tetris Only         |  0.3376282| 18| 18|small      |\n|Intrusions |No-Task Control     |Reactivation Only   |  0.0730015| 18| 18|negligible |\n|Intrusions |Reactivation+Tetris |Tetris Only         | -0.8382366| 18| 18|large      |\n|Intrusions |Reactivation+Tetris |Reactivation Only   | -1.1076078| 18| 18|large      |\n|Intrusions |Tetris Only         |Reactivation Only   | -0.3030234| 18| 18|small      |\n\n</div>\n:::\n:::\n\n\n\n\n\n\n## Activity 9: Sensitivity power analysis\n\nAs always, we want to determine the smallest effect size that this study could detect, given its design and sample size.\n\nTo do this, we use the `pwr.anova.test()` function from the `pwr` package. The key arguments for this function are:\n\n* `k` = The number of groups.\n* `n` = The number of participants in each group.\n* `sig.level` = The significance level of the study (usually set to 0.05). \n* `power` = The power level of the study (usually set to 0.8).\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.anova.test(k = 4, n = 18, sig.level = .05, power = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18\n              f = 0.4005038\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n```\n\n\n:::\n:::\n\n\n\n:::\n\n\nSince the power analysis computes Cohen’s f, but the model output provides partial eta squared, we need to convert the eta squared value into f to be able to compare the two. We can achieve this using the `eta2_to_f()` function from the `effectsize` package. The partial eta squared value from the model was 0.143.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neta2_to_f(0.143)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4084864\n```\n\n\n:::\n:::\n\n\n\n\nThe smallest effect size (Cohen's $f$) that can be detected with four groups, 18 participants in each group, a significance level of 0.05, and 80% power was $f = .40$. This was smaller than the effect size determined by the ANOVA ($\\eta_p^2 = 0.143; f = 0.41)$. Therefore, the study was sufficiently powered.\n\n\n\n## Activity 10: The write-up\n\nA one-way between-subjects ANOVA was conducted on the 7-day diary post-intervention to examine the effect of cognitive task on overall intrusion scores. The analysis revealed a statistically significant effect,  $F(3, 68) = 3.79, p = .014, \\eta_p^2 = 0.143$.\n\nSince the ANOVA result was significant, post-hoc pairwise comparisons were conducted with Bonferroni corrections for multiple comparisons to identify which groups differed significantly.\n\nComparisons demonstrated that the reactivation-plus-Tetris group $(M = 1.89, SD = 1.75)$ experienced significantly fewer intrusive memories compared to\nthe no-task control group $(M = 5.11, SD = 4.23)$, $t(68) = 3.04, p_{adj} = .020, d = 1.00$. This effect is considered large.\n\nFurthermore, the reactivation-plus-Tetris group $(M = 1.89, SD = 1.75)$ experienced significantly fewer intrusive memories compared to\nthe reactivation-only group $(M = 4.83, SD = 3.33)$, $t(68) = 2.78, p_{adj} = .042, d = 1.11$. This effect is also considered large.\n\nThere were no significant differences between the no-task control group and the Tetris-only group $(t(68) = 1.15, p_{adj} = 1, d = 0.34)$, the no-task control group and the reactivation-only group $(t(68) = 0.26, p_{adj} = 1, d = 0.07)$, the reactivation-plus-Tetris group and the Tetris-only group $(t(68) = 1.89, p_{adj} = .379, d = 0.84)$, or the Tetris-only group and the reactivation-only group $(t(68) = 0.89, p_{adj} = 1, d = 0.30)$.\n\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n#### Question 1 {.unnumbered}\n\n**Why do we use a one-way ANOVA instead of multiple independent t-tests when comparing three or more groups?**\n\n<div class='webex-radiogroup' id='radio_GXGJCKPVLB'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GXGJCKPVLB\" value=\"x\"></input> <span>ANOVA is the only test that works when sample sizes are unequal.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GXGJCKPVLB\" value=\"x\"></input> <span>ANOVA does not require the dependent variable to be normally distributed.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GXGJCKPVLB\" value=\"answer\"></input> <span>ANOVA reduces the risk of Type I errors caused by multiple comparisons.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_GXGJCKPVLB\" value=\"x\"></input> <span>ANOVA can test for interactions between independent variables.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nCorrect Answer:\n\n**ANOVA reduces the risk of Type I errors caused by multiple comparisons** is correct because performing multiple comparisons increases the risk of Type I errors (false positives). \n\n\nIncorrect Answers:\n\n* \"ANOVA can test for interactions between independent variables\" is incorrect because testing for interactions requires a factorial ANOVA, not a one-way ANOVA.\n* \"ANOVA is the only test that works when sample sizes are unequal\" is incorrect because unequal sample sizes can be handled in both ANOVA and t-tests.\n* \"ANOVA does not require the dependent variable to be normally distributed\" is incorrect because normality of the dependent variable is still an assumption for ANOVA.\n\n:::\n\n#### Question 2 {.unnumbered}\n\n**Which assumption must be met for an ANOVA to be valid?**\n\n<div class='webex-radiogroup' id='radio_BBNBLAQSSU'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BBNBLAQSSU\" value=\"x\"></input> <span>The groups must have different sample sizes.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BBNBLAQSSU\" value=\"x\"></input> <span>The independent variable must be measured on an interval scale.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BBNBLAQSSU\" value=\"x\"></input> <span>Each group must have an equal mean before running ANOVA.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BBNBLAQSSU\" value=\"answer\"></input> <span>The residuals of the dependent variable should be normally distributed in each group.</span></label></div>\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe correct answer: ANOVA assumes that the residuals of the dependent variable are normally distributed within each group to ensure valid results.\n\nThe other options are incorrect:\n\n* The independent variable in ANOVA is categorical, not interval or ratio.\n* While equal sample sizes can be beneficial, ANOVA does not require them to be different (or equal for that matter).\n* The groups are not required to have equal means before running the ANOVA. ANOVA is used to test for mean differences.\n\n* One incorrect option includes an interaction term (`*`), which was not specified in the task. A basic multiple regression only includes main effects (`+`).\n* Another incorrect option swaps the predictor and outcome, which would lead to an incorrect model specification.\n* The last incorrect option incorrectly treats test anxiety as the outcome, when it is actually a predictor in the model.\n:::\n\n\n#### Question 3 {.unnumbered}\n\n**After finding a significant ANOVA result, which of the following statements about post-hoc tests is true?**\n\n\n<div class='webex-radiogroup' id='radio_QDKBWPOQGN'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QDKBWPOQGN\" value=\"x\"></input> <span>Post-hoc tests are unnecessary unless more than five groups are being compared.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QDKBWPOQGN\" value=\"answer\"></input> <span>Post-hoc tests help identify which specific groups differ after a significant ANOVA result.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QDKBWPOQGN\" value=\"x\"></input> <span>Post-hoc tests should only be conducted if Levene’s test is significant.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QDKBWPOQGN\" value=\"x\"></input> <span>A significant ANOVA result automatically tells us which groups are different without further tests.</span></label></div>\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nCorrect Answer:\n\nANOVA tells us that at least one group differs significantly from another, but post-hoc tests (e.g., Tukey, Bonferroni) are needed to determine which specific groups are different.\n\nWhy are the other options incorrect?\n\n* Post-hoc tests are used after a significant ANOVA result, regardless of Levene’s test outcome.\n* ANOVA does not automatically tell us which groups differ. It only detects an overall effect. That's why we have to run a post-hoc test.\n* Post-hoc tests are necessary whenever there are more than two groups, not just when there are more than five.\n\n:::\n\n\n\n#### Question 4 {.unnumbered}\n\n**A researcher reports an effect size of ηₚ² = 0.02 after conducting a one-way ANOVA. How should this effect size be interpreted?**\n\n<div class='webex-radiogroup' id='radio_XFOOLJXMTM'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XFOOLJXMTM\" value=\"x\"></input> <span>Moderate effect</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XFOOLJXMTM\" value=\"answer\"></input> <span>Small effect</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XFOOLJXMTM\" value=\"x\"></input> <span>Large effect</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XFOOLJXMTM\" value=\"x\"></input> <span>Cannot determine without the F-ratio</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nAccording to Cohen’s guidelines, ηₚ² = 0.01 is small, ηₚ² = 0.06 is medium, and ηₚ² = 0.14 is large. Since 0.02 is closer to 0.01, it represents a small effect.\n\nThe effect size is independent of the F-ratio. You do not need the F-ratio to interpret ηₚ².\n\n:::\n\n\n",
    "supporting": [
      "12-one-way-anova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}