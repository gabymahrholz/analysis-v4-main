{
  "hash": "d83577cfd539c6f6c97765b808d9eabf",
  "result": {
    "markdown": "\n# Chi-square and one-sample t-test  {#sec-nhstI}\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n-   compute a Cross-tabulation Chi-square test and report the results\n-   compute a one-sample t-test and report the results\n-   understand when to use a non-parametric equivalent for the one-sample t-test, compute it, and report the results\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n## Overview\n\nFrom here on, we will explore inferential statistics, including chi-square test, various t-tests, correlations, ANOVAs, and regression. Most of these tests belong to the General Linear Model (GLM) family, which helps us analyse relationships between variables using linear equations. The chi-square test, while not part of the GLM, is also included here as it’s useful for analysing categorical data.\n\nTo help you choose the most appropriate test, refer to the simplified flowchart below. It guides you based on the types of variables - whether they are categorical or continuous.\n\n\n![Simplified flowchart to help select the most appropriate test (created with [drawio](https://draw.io/){target=\"_blank\"}). [View larger version](images/Flowchart_tests_drawio.png){target=\"_blank\"}](images/Flowchart_tests_drawio.png)\n\nEach test is discussed in its respective chapter with guidance on when and how to apply it:\n\n* Cross-tabulation chi-Square test (this chapter, @sec-chi_square)\n* One-sample t-test (this chapter, @sec-onesample)\n* Two-sample or independent t-test (between-subjects design, @sec-independent) \n* Paired t-test (within-subjects design, @sec-paired)\n* Correlation (@sec-cor)\n* Simple regression (@sec-reg)\n* Multiple regression (@sec-reg_mult)\n* One-way ANOVA (@sec-oneway)\n* Factorial ANOVA (@sec-factorial)\n\n\n## Activity 1: Setup & download the data\n\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\n* **Create a new project** and name it something meaningful (e.g., \"2A_chapter6\", or \"06_chi_square_one_sample_t\"). See @sec-project if you need some guidance.\n* **Create a new `.Rmd` file** and save it to your project folder. See @sec-rmd if you get stuck. \n* Delete everything after the setup code chunk (e.g., line 12 and below)\n* **Download the new dataset** here: [data_ch6.zip](data/data_ch6.zip \"download\"). This zip file contains one csv file with demographic information and questionnaire data as well as and Excel codebook.\n* Extract the data files from the zip folder and place them directly in your project folder (next to the project icon, not in a subfolder). For more help, see @sec-download_data_ch1.\n\n\n**Citation**\n\n> Ballou, N., Vuorre, M., Hakman, T., Magnusson, K., & Przybylski, A. K. (2024, July 12). Perceived value of video games, but not hours played, predicts mental well-being in adult Nintendo players. [https://doi.org/10.31234/osf.io/3srcw](https://doi.org/10.31234/osf.io/3srcw){target=\"_blank\"}\n\n\nAs you can see, the study is a pre-print published on PsyArXiv Preprints. The data and supplementary materials are available on OSF: [https://osf.io/6xkdg/](https://osf.io/6xkdg/){target=\"_blank\"}\n\n\n**Abstract**\n\n> Studies on video games and well-being often rely on self-report measures or data from a single game. Here, we study how 703 US adults’ time spent playing for over 140,000 hours across 150 Nintendo Switch games relates to their life satisfaction, affect, depressive symptoms, and general mental well-being. We replicate previous findings that playtime over the past two weeks does not predict well-being, and extend these findings to a wider range of timescales (one hour to one year). Results suggest that relationships, if present, dissipate within two hours of gameplay. Our non-causal findings suggest substantial confounding would be needed to shift a meaningful true effect to the observed null. Although playtime was not related to well-being, players’ assessments of the value of game time—so called gaming life fit—was. Results emphasise the importance of defining the gaming population of interest, collecting data from more than one game, and focusing on how players integrate gaming into their lives rather than the amount of time spent.\n\n\n\n**Changes made to the dataset**\n\n* We extracted key demographic variables from the rich dataset, including age, gender, ethnicity, employment, education level, and scores from the Warwick-Edinburgh Mental Wellbeing Scale.\n* We removed rows with missing values and categorical groupings with low observed frequencies for the purpose of this chapter.\n* We won’t explore any associations related to gaming, but feel free to download the full dataset if you wish to investigate further.\n* Unlike the original study, which applied strict inclusion criteria, we used more flexible criteria, resulting in a larger sample size than the original analysis.\n\n\n## Activity 2: Load in the library, read in the data, and familiarise yourself with the data\n\nToday, we will be using the following packages: `tidyverse`, `lsr`, `scales`, `qqplotr`, `car`, `pwr`, and `rcompanion`. If you need to install any of them, do so via the console (see @sec-install_packages for more detail). \n\nAdditionally, we will need to read in the data `data_ballou_reduced`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load in the packages\n???\n\n# read in the data\ndata_ballou <- ???\n```\n:::\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load in the packages\nlibrary(tidyverse)\nlibrary(lsr)\nlibrary(scales)\nlibrary(qqplotr)\nlibrary(car)\nlibrary(pwr)\nlibrary(rcompanion)\n\n# read in the data\ndata_ballou <- read_csv(\"data_ballou_reduced.csv\")\n```\n:::\n\n\n:::\n\n\n## Activity 3: Data wrangling\n\nThe categorical variables in our dataset look tidy, but we need to make a few adjustments to prepare for our analysis:\n\n* **Convert `gender` and `education_level` into factors** in the original `data_ballou` object. Our statistical tests require these variables to be factors, and converting them will also help with sorting categories effectively for plotting. Feel free to arrange the categories in a meaningful order.\n* Create a new data object called `data_wemwbs` to **calculate the total score for the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS**): According to the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"}, the individual item scores should be summed to get the total. \n* **Join** the the original `data_ballou` dataset with the new `data_wemwbs` dataset to have all the information in one place.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"} \n\n## Hints\n\n* We converted categorical variables into factors previously in @sec-dataviz - refer back if you need a refresher\n* Check how we handled the `QRPs` questionnaire in @sec-wrangling for guidance on aggregating scores \n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_wemwbs <- data_ballou %>% \n  pivot_longer(cols = wemwbs_1:wemwbs_14, names_to = \"Questions\", values_to = \"Scores\") %>% \n  group_by(pid) %>% \n  summarise(wemwbs_sum = sum(Scores))\n\ndata_ballou <- data_ballou %>% \n  mutate(gender = factor(gender,\n                         levels = c(\"Woman\", \"Man\", \"Non-binary\")),\n         eduLevel = factor(eduLevel,\n                           levels = c(\"Completed Secondary School\", \"Some University but no degree\", \"University Bachelors Degree\", \"Vocational or Similar\", \"Graduate or professional degree (MA, MS, MBA, PhD, etc)\"))) %>% \n  left_join(data_wemwbs)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(pid)`\n```\n:::\n:::\n\n\n:::\n\n:::\n\n\n## Activity 4: Cross-tabulation Chi-square test {#sec-chi_square}\n\nA Cross-Tabulation Chi-Square Test, also known as a Chi-Square Test of Association or Independence, tests how one variable is associated with the distribution of outcomes in another variable.\n\nWe will be performing a Chi-Square test using the categorical variables **gender** and **eduLevel**:\n\n* **Potential research question**: \"Is there an association between gender and level of education in the population?\"\n* **Null Hypothesis (H~0~)**: \"Gender and level of education are independent; there is no association between gender and level of education.\"\n* **Alternative Hypothesis (H~1~)**: \"Gender and level of education are not independent; there is an association between gender and level of education.\"\n\n\n\n### Task 1: Preparing the dataframe\n\nFirst, select your variables of interest - here participant id, gender, and education levels. This dataset does not contain missing values, but in future datasets that might, use `drop_na()` to remove them before converting categorical variables into factors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_square <- data_ballou %>% \n  select(pid, gender, eduLevel)\n```\n:::\n\n\n\n### Task 2: Compute descriptives\n\nNext, we need to calculate counts for each combination of the variables, which is best done in a frequency table - or more precisely a **contingency table** since we are looking at a combination of 2 categorical variables (sometimes they are called crosstabulation and two-way tables). \n\nThis will also allow us to verify that there are no missing values in any cells, as the function we’re using cannot handle missing values\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_square_frequency <- chi_square %>% \n  count(gender, eduLevel) %>% \n  pivot_wider(names_from = eduLevel, values_from = n)\n\nchi_square_frequency\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|gender     | Completed Secondary School| Some University but no degree| University Bachelors Degree| Vocational or Similar| Graduate or professional degree (MA, MS, MBA, PhD, etc)|\n|:----------|--------------------------:|-----------------------------:|---------------------------:|---------------------:|-------------------------------------------------------:|\n|Woman      |                         63|                           118|                         169|                    42|                                                      65|\n|Man        |                         70|                           125|                         250|                    34|                                                      81|\n|Non-binary |                          9|                            23|                          20|                     4|                                                      10|\n\n</div>\n:::\n:::\n\n\nWe should be fine here, even though the count for the non-binary/vocational category is quite low.\n\n\n### Task 3: Check assumptions\n\n\n#### Assumption 1: Categorical data {.unnumbered}\n\nBoth variables should be categorical, measured at either the ordinal or nominal level.\n\nWe can confirm that for our dataset. Gender is <select class='webex-select'><option value='blank'></option><option value='x'>ordinal</option><option value='answer'>nominal</option></select>, and level of education is <select class='webex-select'><option value='blank'></option><option value='answer'>ordinal</option><option value='x'>nominal</option></select>.\n\n\n#### Assumption 2: Independent observartions {.unnumbered}\n\nEach observation in the dataset has to be independent, meaning the value of one observation does not affect the value of any other. \n\nAnd we assume as much for our data.\n\n\n\n#### Assumption 3: Cells in the contingency table are mutually exclusive {.unnumbered}\n\nEach individual can belong to only one cell in the contingency table. We can confirm this by examining the data and reviewing the contingency table.\n\n\n#### Assumption 4: Expected frequencies are sufficiently large {.unnumbered}\n\nAssumption 4 is not an assumption that is listed consistently across various sources. When it is, it suggests that expected frequencies are larger than 5 or at least 80% of the the expected frequencies are above 5 and none of them are below 1. However, Danielle Navarro points out that this seems to be a \"somewhat conservative\" criterion and should be taken as \"rough guidelines\" only (see [https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions](https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions){target=\"_blank\"}.\n\nThis is information, we can either compute manually (see lecture slides) or wait till we get the output from the inferential statistics later.\n\n\n### Task 4: Create an appropriate plot\n\nNow we can create the appropriate plot. Which plot would you choose when building one from object `chi_square`? A <select class='webex-select'><option value='blank'></option><option value='answer'>Barchart</option><option value='x'>Histogram</option><option value='x'>Scatterplot</option><option value='x'>Violin-Boxplot</option></select> with geom layer <select class='webex-select'><option value='blank'></option><option value='x'>geom_col</option><option value='answer'>geom_bar</option><option value='x'>geom_histogram</option><option value='x'>geom_point</option><option value='x'>geom_boxplot and geom_violin</option></select>\n\n\nTry creating the plot on your own before checking the solution. Feel free to practice adding different layers to make the plot pretty!\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## One possible solution\n\n... is a grouped bar chart.\n\nI played about with the labels of the x-axis categories since the graduate label is super long. Google was my friend in this instance and showed me a nifty function called `label_wrap()` from the `scales` package which automatically inserts line breaks after a set number of characters. Setting it to 12 characters looked best. (See other options for long labels at [https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/](https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/){target=\"_blank\"}).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(chi_square, aes(x = eduLevel, fill = gender)) +\n  geom_bar(position = \"dodge\") + \n  scale_fill_viridis_d(name = \"Gender\") +\n  scale_x_discrete(name = \"Level of Education\",\n                   labels = label_wrap(12)) +\n  scale_y_continuous(name = \"Count\") +\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n\n\n\n\n### Task 5: Compute a chi-square test\n\n\nBefore we can do that, we need to turn our tibble into a dataframe - the `associationTest()` function we are using to compute the Chi-square test does not like tibbles. [*you have nooooo clue how long that took to figure out - let's say the error message was not exactly helpful*]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_square_df <- as.data.frame(chi_square)\n```\n:::\n\n\n\nNow we can run the `associationTest()` function from the `lsr` package. The first argument is a formula. It starts with a `~` followed by the two variables you want to associate, separated by a `+`. The second argument is the dataframe.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nassociationTest(formula = ~ eduLevel + gender, data = chi_square_df)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in associationTest(formula = ~eduLevel + gender, data = chi_square_df):\nExpected frequencies too small: chi-squared approximation may be incorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Chi-square test of categorical association\n\nVariables:   eduLevel, gender \n\nHypotheses: \n   null:        variables are independent of one another\n   alternative: some contingency exists between variables\n\nObserved contingency table:\n                                                         gender\neduLevel                                                  Woman Man Non-binary\n  Completed Secondary School                                 63  70          9\n  Some University but no degree                             118 125         23\n  University Bachelors Degree                               169 250         20\n  Vocational or Similar                                      42  34          4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)    65  81         10\n\nExpected contingency table under the null hypothesis:\n                                                         gender\neduLevel                                                  Woman   Man\n  Completed Secondary School                               59.9  73.4\n  Some University but no degree                           112.2 137.5\n  University Bachelors Degree                             185.2 227.0\n  Vocational or Similar                                    33.8  41.4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)  65.8  80.7\n                                                         gender\neduLevel                                                  Non-binary\n  Completed Secondary School                                    8.65\n  Some University but no degree                                16.21\n  University Bachelors Degree                                  26.75\n  Vocational or Similar                                         4.88\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)       9.51\n\nTest results: \n   X-squared statistic:  13.594 \n   degrees of freedom:  8 \n   p-value:  0.093 \n\nOther information: \n   estimated effect size (Cramer's v):  0.079 \n   warning: expected frequencies too small, results may be inaccurate\n```\n:::\n:::\n\n\n\nThe output is quite informative as it gives information about:\n\n* the variables that were tested, \n* the null and alternative hypotheses, \n* a table with the observed frequencies (which matches our calculations in `chi_square_frequency` without the rows/columns of the missing values we removed), \n* an output of the frequencies you'd expect if the null hypothesis were true, \n* the result of the hypothesis test, and \n* the effect size Cramer's v.\n\nIt also gives us a **warning message** saying that expected frequencies are too small and that the chi-squared approximation may be incorrect. This relates to Assumption 4. Depending on your stance on Assumption 4, you may choose to either address or ignore this warning.\n\nThe p-value indicates that we do not reject the null hypothesis, as it is greater than 0.05.\n\n### Task 6: The write-up\n\nThe Chi-Square test revealed that there is no statistically significant association between Gender and Level of Education, $\\chi^2(8) = 13.59, p = .093, V = .079$. The strength of the association between the variables is considered small. We therefore fail to reject the null hypothesis. \n\n\n\n\n\n## Activity 5: One-sample t-test {#sec-onesample}\n\nThe one-sample t-test is used to determine whether a sample comes from a population with a specific mean. This population mean is not always known, but is sometimes hypothesised. \n\nWe will perform a one-sample t-test using the continuous variable **wemwbs_sum**. The [official website for the Warwick-Edinburgh Mental Wellbeing Scales](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"} states that the \"WEMWBS has a mean score of 51.0 in general population samples in the UK with a standard deviation of 7 (Tennant et al., 2007)\".\n\n* **Potential research question**: \"Is the average mental well-being of gamers different from the general population's average well-being?\"\n* **Null Hypothesis (H~0~)**: \"The summed-up WEMWBS score of gamers is not different to 51.0.\"\n* **Alternative Hypothesis (H~1~)**: \"The summed-up WEMWBS score of gamers is different from 51.0.\"\n\n\n### Task 1: Preparing the dataframe\n\nFirst, we need to select the variables of interest: participant ID and `wemwbs_sum`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\none_sample <- data_ballou %>% \n  select(pid, wemwbs_sum)\n```\n:::\n\n\n\n### Task 2: Compute descriptives\n\nNext, we want to compute means and standard deviations for our variable of interest. This should be straight forward. Try it yourself and then compare your result with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescriptives <- one_sample %>% \n  summarise(mean_wemwbs = mean(wemwbs_sum),\n            sd = sd(wemwbs_sum))\n\ndescriptives\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| mean_wemwbs|       sd|\n|-----------:|--------:|\n|    45.42013| 10.88615|\n\n</div>\n:::\n:::\n\n\n:::\n\n\n### Task 3: Create an appropriate plot\n\nThis is the plot you will want to include in your report, so make sure everything is clearly labelled. Which plot would you choose? Try creating one on your own first, then compare it with the solution below.\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = \"\", y = wemwbs_sum)) +\n  geom_violin(fill = \"#FB8D61\", alpha = 0.4) + # alpha for opacity, fill for adding colour\n  geom_boxplot(fill = \"#FB8D61\", width = 0.5) + # change width of the boxes\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Total WEMWBS Scores\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n:::\n\n\n\n### Task 4: Check assumptions\n\n\n#### Assumption 1: Continuous DV {.unnumbered}\n\nThe dependent variable (DV) needs to be measured at interval or ratio level. We can confirm that by looking at `one_sample`. \n\n\n\n#### Assumption 2: Data are independent {.unnumbered}\n\nThere should be no relationship between the observations. While this is an important assumption, it is more related to study design and isn’t something we can easily test for. Anyway, we will assume this assumption holds for our data.\n\n\n\n#### Assumption 3: No significant outliers {.unnumbered}\n\nWe can check for that visually, for example in the violin-boxplot above. \n\nIt appears there is one outlier in the lower tail. However, upon inspecting the `one_sample` data, we see it is a single participant with a score of 14, which is a possible value. Additionally, with a large sample size of 1,083 participants, removing a single outlier makes not much sense. Thus, we have checked this assumption, considered this outlier not significant, and therefore keep this observation in the dataset.\n\n::: {.callout-important} \n\nIf you decide to remove any outliers, remember to recalculate the descriptive statistics.\n\n:::\n\n#### Assumption 4: DV should be approximately normally distributed {.unnumbered}\n\nWe can already check normality from the violin-boxplot above but you could also use a histogram, a density plot, or a Q-Q plot as an alternative to assess normality visually.\n\nEach of these options shows that **the data is normally distributed**. This allows us to proceed with a parametric test, specifically a one-sample t-test.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Alternatives to visually assess normality\n\n::: {.panel-tabset}\n\n## Histogram\n\nWe've already covered histograms in @sec-dataviz2. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_histogram(binwidth = 1, fill = \"magenta\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n## Density plot\n\nA density plot shows a smooth distribution curve of the data. Unlike a histogram, the height of the curve reflects the proportion of data within each range rather than the frequency of individual values. This means the curve shows where data points are concentrated, not how many times each value appears.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_density(fill = \"magenta\")\n```\n\n::: {.cell-output-display}\n![](06-chi-square-one-sample_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n## Q-Q plot\n\nQ-Q plot stands for Quantile-Quantile Plot and compare two distributions by matching a common set of quantiles. Essentially, it compares the distribution of your data to a normal distribution and plots the points along a 45-degree line.\n\n**If the dots in the Q-Q plot fall roughly along that line, we can assume the data is normally distributed. If they stray away from the line (and worse in some sort of pattern), we might not assume normality and conduct a non-parametric test instead. For the non-parametric equivalent, see @sec-alternative_one_sample.**\n\nTo create the Q-Q plot, you can use either the `car` or `qqplotr` package\n\n* The `qqPlot()` function is a single line but requires BaseR syntax (i.e., the `$` symbol) to access the column within the data object. For example, `one_sample$wemwbs_sum` directs R to look for a column named `wemwbs_sum` that is located within the data object `one_sample`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Version 1 with the car package\nqqPlot(one_sample$wemwbs_sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 295 394\n```\n:::\n\n::: {.cell-output-display}\n![Q-Q plot created with the car package](06-chi-square-one-sample_files/figure-html/fig-qqplot1-1.png){#fig-qqplot1 width=672}\n:::\n:::\n\n\n* If you have gotten used to ggplot by now, and prefer avoiding BaseR, you can use the package `qqplotr`. The downside is that you have to add the points, the line, and the confidence envelope yourself. On the plus, it has layers like ggplot, and is more customisable (just in case you wanted to look at something more colourful in the 2 seconds it'll take you to assess normality).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Version 2 with package qqplotr\nggplot(one_sample, aes(sample = wemwbs_sum)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n```\n\n::: {.cell-output-display}\n![Q-Q plot created with the qqplotr package](06-chi-square-one-sample_files/figure-html/fig-qqplot2-1.png){#fig-qqplot2 width=672}\n:::\n:::\n\n\n:::\n\n:::\n\n\nYou could also assess normality with the **Shapiro-Wilk’s test**. The null hypothesis is that the population is distributed normally. Therefore, if the p-value of the Shapiro-Wilk’s test smaller than .05, normality is rejected. \n\n::: {.callout-important}\n\nShapiro-Wilk is an OK method for small sample sizes (e.g., smaller than 50 samples) if the deviation from normality is fairly obvious. If we are dealing with slight deviations from normality, it might not be sensitive enough to pick that up. But t-tests, ANOVAs etc. should be robust for slight deviations from normality anyway.\n\nIn contrast, when you have large sample sizes, Shapiro-Wilk is overly sensitive and will definitely produce a significant p-value regardless of what the distribution looks like. So don't rely on its output when you have large sample sizes, and be mindful of its output when you have small sample sizes.\n\n:::\n\nThe function in R for this test is `shapiro.test()` which is part of BaseR. This means, we need to specify our data object, use the `$`, and indicate the column we want to address.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(one_sample$wemwbs_sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  one_sample$wemwbs_sum\nW = 0.99404, p-value = 0.0002619\n```\n:::\n:::\n\n\nNo surprise here! The test shows a p-value of  < .001 due to our large sample size of over 1000 participants. Nevertheless, if you decided on using the Shapiro-Wilk test in your report, you'd need to write this result up in APA style: $W = .99, p < .001$.\n\n\n::: {.callout-tip}\n\n## Report-writing Tip\n\nEither choose visual or computational inspection for normality tests. NO NEED TO DO BOTH!!!\n\n* State what method you used and your reasons for choosing the method (visual/computational and what plot/test you used)\n* State the outcome of the test - for visual inspection just say whether normality assumption held or not (no need to include that extra plot in the results section). For computational methods, report the test result in APA style\n* State the conclusions you draw from it - parametric or non-parametric test\n\n:::\n\n\n\n### Task 5: Compute a One-sample t-test and effect size\n\n\nTo compute a one-sample t-test, we can use the `t.test() function`, which is part of Base R. And yes, you guessed it, our first argument should follow the pattern `data$column`. The second argument, `mu`, specifies the population mean we are testing our sample against (in this case, 51.0). The `alternative` is \"two.sided\" by default, so it can be omitted if you are conducting a two-sided test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(one_sample$wemwbs_sum, mu = 51.0, alternative = \"two.sided\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  one_sample$wemwbs_sum\nt = -16.868, df = 1082, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 51\n95 percent confidence interval:\n 44.77106 46.06920\nsample estimates:\nmean of x \n 45.42013 \n```\n:::\n:::\n\n\nThe output is quite informative. It provides information about:\n\n* the variable column that was tested, \n* the t value, degrees of freedom, and p,\n* the alternative hypothesis, \n* a 95% confidence interval,\n* and the mean of the column (which matches the one we computed in the descriptive - yay)\n\nWhat it doesn't give us is an **effect size**. Meh. So we will need to compute one ourselves.\n\nWe will calculate **Cohen's d** using the function `cohensD()` from the `lsr` package. Similar to the t-test we just conducted, the first argument is `data$column`, the second argument is `mu`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncohensD(one_sample$wemwbs_sum, mu = 51.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5125662\n```\n:::\n:::\n\n\n\n### Task 6: Sensitivity power analysis\n\nA **sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect** given the number of participants you have in the sample (i.e., sample size), the alpha level at 0.05, and an assumed power of 0.8. \n\n\nTo perform this calculation, we use the `pwr.t.test()` function from the `pwr` package. This function relies on four key factors — alpha, power, effect size, and sample size (APES). If you know three, you can calculate the fourth. Since we have three specified, we can solve for the effect size. Additionally, we need to specify the `type` argument to indicate we are using a one-sample t-test, and set `alternative` to \"two.sided\" for a non-directional hypothesis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.t.test(n = 1083, sig.level = 0.05, power = 0.8, type = \"one.sample\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     One-sample t test power calculation \n\n              n = 1083\n              d = 0.08520677\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n```\n:::\n:::\n\n\nSo the smallest effect size we can detect with a sample size of 1083, an alpha level of 0.05, and power of 0.8 is 0.09. This is a smaller value than the actual effect size we calculated with our CohensD function above (i.e., 0.51) which means our analysis is sufficiently powered.\n\n\n### Task 7: The write-up\n\nA one-sample t-test was computed to determine whether the average mental well-being of gamers as measured by the WEMWBS was different to the population well-being mean. The average WEMWBS of the gamers $(N = 1083, M = 45.42, SD = 10.89)$ was significantly lower than the population mean well-being score of 51.0, $t(1082) = 16.87, p < .001, d = .51$. The strength of the effect is considered medium and the study was sufficiently powered. We therefore reject the null hypothesis in favour of H~1~. \n\n\n\n\n## Activity 6: Non-parametric alternative {#sec-alternative_one_sample}\n\nIf any of the assumptions are violated, switch to the non-parametric alternative. For the one-sample t-test, this would be a **One-sample Wilcoxon signed-rank test**. Instead of the mean, it compares the median of a sample against a single value (i.e., the population median).\n\nThat means we will need to determine the population median, and calculate some **summary stats** for our sample:\n\n* The population median is listed in a supporting document on the [official WEMWBS website](https://warwick.ac.uk/fac/sci/med/research/platform/wemwbs/using/howto/){target=\"_blank\"} as 53.0. \n* We can easily calculate the summary statistics using the function `summary()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(one_sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     pid              wemwbs_sum   \n Length:1083        Min.   :14.00  \n Class :character   1st Qu.:38.00  \n Mode  :character   Median :46.00  \n                    Mean   :45.42  \n                    3rd Qu.:53.00  \n                    Max.   :70.00  \n```\n:::\n:::\n\n\n\nThe function to **compute a one-sample Wilcoxon test** is `wilcox.test()` which is part of BaseR. Code-wise, it works very similar to the one-sample t-test.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(one_sample$wemwbs_sum, mu = 53.0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  one_sample$wemwbs_sum\nV = 87218, p-value < 2.2e-16\nalternative hypothesis: true location is not equal to 53\n```\n:::\n:::\n\n\nAs we can see, the output shows a V value, but for the final write-up, we need to report **the standardised test statistic Z** in the final write-up. Unfortunately, this requires manual calculation. According to Andy Field (2012, p. 665), we need to use the qnorm function on the halved p-value from our Wilcoxon test above. Here, we store the p-value in the `Global Environment` as `p_wilcoxon`. This retains more decimal places than shown in the output, giving us a more precise Z value.\"\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# storing the p-value\np_wilcoxon <- wilcox.test(one_sample$wemwbs_sum, mu = 53.0)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -19.12264\n```\n:::\n:::\n\n\n\n\nWe also need to **calculate the effect size `r`** for the One-sample Wilcoxon signed-rank test. This can be done using the `wilcoxonOneSampleR()` function from the `rcompanion` package. By default, the result is rounded to three decimal places, but you can adjust this by adding the `digits` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    r \n-0.59 \n```\n:::\n:::\n\n\nNow we have all the numbers we need to **write up the results**: \n\nA One-sample Wilcoxon signed-rank test was used to compare Gamers’ mental-wellbeing median scores (Mdn = 46.0) to the population median of 53.0. The test showed a significant difference, $Z = -19.12, p < .001, r = .590$. The strength of the effect is considered medium. We therefore reject the null hypothesis in favour of H~1~. \n\n\n## [Pair-coding]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n::: {.callout-important}\n\nThis pair coding task is a bit long to fully complete in class. Try to progress as far as possible without compromising understanding, and treat the remaining section as a \"Challenge Yourself\" activity.\n\n**Intentions behind it?**\n\nThe task is designed to walk you through conducting a full Chi-Square test on a dataset different from the one in the chapter. I did not want to cherry-pick specific steps from the Chi-Square test, as real-life data analysis requires computing descriptives and checking assumptions before conducting inferential statistics.\n\n:::\n\n### Task 1: Open the R project for the lab {.unnumbered}\n\n### Task 2: Create a new `.Rmd` file {.unnumbered}\n\n... and name it something useful. If you need help, have a look at @sec-rmd.\n\n### Task 3: Load in the library and read in the data {.unnumbered}\n\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: [data_pair_coding](data/data_pair_coding.zip \"download\").\n\nWe are using the packages `tidyverse` and `lsr` today, and the data file we need to read in is `dog_data_clean_wide.csv`. I've named my data object `dog_data_wide` to shorten the name but feel free to use whatever object name sounds intuitive to you.\n\nIf you have not worked through chapter 6 yet, you may need to install the package `lsr` before you can load it into the library. Run `install.packages(\"lsr\")` in your **CONSOLE**.\n\n\n::: {.cell}\n\n:::\n\n\n\n### Task 4: Tidy data for a Chi-Square t-test {.unnumbered}\n\nLook at `dog_data_wide` and choose two categorical variables. To guide you through this example, I have selected Year of Study and whether or not the students owned pets as my categorical variable.\n\n\n* **Step 1**: Select all relevant columns from `dog_data_wide`. In my case, those would be the participant ID `RID`, `Year_of_Study`, and `Live_Pets`. Store this data in an object called `dog_chi`.\n\n* **Step 2**: Check if we have any missing values in the `dog_chi`. If so remove them with the function `drop_na()`.\n\n* **Step 3**: Convert `Year_of_Study` and `Live_Pets` into factors. Feel free to order the categories meaningfully.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndog_chi <- ??? %>% \n  # Step 1\n  select(???, ???, ???) %>% \n  # Step 2\n  drop_na() %>% \n  # Step 3\n  mutate(Year_of_Study = ???(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")),\n         Live_Pets = ???(Live_Pets,\n                            levels = c(\"yes\", \"no\")))\n```\n:::\n\n\n:::\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution for Tasks 3 and 4\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# loading tidyverse and lsr into the library\nlibrary(tidyverse)\nlibrary(lsr)\n\n# reading in `dog_data_clean_wide.csv`\ndog_data_wide <- read_csv(\"dog_data_clean_wide.csv\")\n\n# Task 4: Tidying \ndog_chi <- dog_data_wide %>% \n  # Step 1\n  select(RID, Year_of_Study, Live_Pets) %>% \n  # Step 2\n  drop_na() %>% \n  # Step 3\n  mutate(Year_of_Study = factor(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")),\n         Live_Pets = factor(Live_Pets,\n                            levels = c(\"yes\", \"no\")))\n```\n:::\n\n\n\n:::\n\n### Task 5: Compute descriptives {.unnumbered}\n\nCreate a frequency table (or contingency table to be more exact) from `dog_chi`, i.e., we need counts for each combination of the variables. Store the data in a new data object `dog_chi_contingency`. `dog_chi_contingency` should look like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Year_of_Study </th>\n   <th style=\"text-align:right;\"> yes </th>\n   <th style=\"text-align:right;\"> no </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> First </td>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:right;\"> 89 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Second </td>\n   <td style=\"text-align:right;\"> 37 </td>\n   <td style=\"text-align:right;\"> 64 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Third </td>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:right;\"> 22 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Fourth </td>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:right;\"> 18 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Fifth or above </td>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:right;\"> 2 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndog_chi_contingency <- dog_chi %>% \n  count(???, ???) %>% \n  pivot_wider(names_from = ???, values_from = n)\n```\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Task 5: Frequency table\ndog_chi_contingency <- dog_chi %>% \n  count(Live_Pets, Year_of_Study) %>% \n  pivot_wider(names_from = Live_Pets, values_from = n)\n```\n:::\n\n\n:::\n\n:::\n\n\n### Task 6: Check assumptions {.unnumbered}\n\n\n1. Both variables should be categorical, measured at either the ordinal or nominal level. Answer: <select class='webex-select'><option value='blank'></option><option value='answer'>yes</option><option value='x'>no</option></select> as `Year_of_Study` is <select class='webex-select'><option value='blank'></option><option value='answer'>ordinal</option><option value='x'>nominal</option></select>, and `Live_Pets` is <select class='webex-select'><option value='blank'></option><option value='x'>ordinal</option><option value='answer'>nominal</option></select>.\n\n2. Each observation in the dataset has to be independent, meaning the value of one observation does not affect the value of any other. Answer: <select class='webex-select'><option value='blank'></option><option value='answer'>yes</option><option value='x'>no</option></select>\n\n3. Cells in the contingency table are mutually exclusive. Answer: <select class='webex-select'><option value='blank'></option><option value='answer'>yes</option><option value='x'>no</option></select> because each individual can belong to <select class='webex-select'><option value='blank'></option><option value='x'>multiple cells</option><option value='answer'>only one cell</option></select> in the contingency table.\n\n\n### Task 7: Compute a chi-square test & interpret the output {.unnumbered}\n\n* **Step 1**: Use the function `as.data.frame` to turn `dog_chi` into a dataframe. Store this output in a new data object called `dog_chi_df`.\n\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints\n\n\n::: {.cell}\n\n```{.r .cell-code}\n??? <- as.data.frame(???)\n```\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndog_chi_df <- as.data.frame(dog_chi)\n```\n:::\n\n\n:::\n\n:::\n\n* **Step 2**: Run the `associationTest()` function from the `lsr` package to compute the Chi-Square test. The structure of the function is as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nassociationTest(formula = ~ Variable1 + Variable2, data = your_dataframe)\n```\n:::\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nassociationTest(formula = ~ Year_of_Study + Live_Pets, data = dog_chi_df)\n```\n:::\n\n\n:::\n\n\n* **Step 3**: Interpreting the output\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nWarning in associationTest(formula = ~Year_of_Study + Live_Pets, data =\ndog_chi_df): Expected frequencies too small: chi-squared approximation may be\nincorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Chi-square test of categorical association\n\nVariables:   Year_of_Study, Live_Pets \n\nHypotheses: \n   null:        variables are independent of one another\n   alternative: some contingency exists between variables\n\nObserved contingency table:\n                Live_Pets\nYear_of_Study    yes no\n  First           21 89\n  Second          37 64\n  Third           12 22\n  Fourth          12 18\n  Fifth or above   3  2\n\nExpected contingency table under the null hypothesis:\n                Live_Pets\nYear_of_Study      yes    no\n  First          33.39 76.61\n  Second         30.66 70.34\n  Third          10.32 23.68\n  Fourth          9.11 20.89\n  Fifth or above  1.52  3.48\n\nTest results: \n   X-squared statistic:  12.276 \n   degrees of freedom:  4 \n   p-value:  0.015 \n\nOther information: \n   estimated effect size (Cramer's v):  0.209 \n   warning: expected frequencies too small, results may be inaccurate\n```\n:::\n:::\n\n\n\nThe Chi-Square test revealed that there is <select class='webex-select'><option value='blank'></option><option value='answer'>a statistically significant association</option><option value='x'>no statistically significant association</option></select> between Year of Study and whether students live with pets, $\\chi^2$ (<input class='webex-solveme nospaces' size='1' data-answer='[\"4\"]'/>) = <input class='webex-solveme nospaces' size='5' data-answer='[\"12.28\"]'/>, p = <input class='webex-solveme nospaces' size='4' data-answer='[\".015\"]'/>, V = <input class='webex-solveme nospaces' size='4' data-answer='[\".209\"]'/>. The strength of the association between the variables is considered <select class='webex-select'><option value='blank'></option><option value='x'>small</option><option value='answer'>moderate</option><option value='x'>strong</option></select>. We therefore <select class='webex-select'><option value='blank'></option><option value='x'>fail to reject the null hypothesis</option><option value='answer'>reject the null hypothesis</option></select>.\n\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n#### Question 1: Conceptual Understanding - Chi-Square Test {.unnumbered}\n\n**What is the primary purpose of a Chi-square test?**\n\n<div class='webex-radiogroup' id='radio_SGLAQYWEYX'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SGLAQYWEYX\" value=\"x\"></input> <span>To compare means between two groups</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SGLAQYWEYX\" value=\"x\"></input> <span>To test for differences in variances</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SGLAQYWEYX\" value=\"x\"></input> <span>To assess the correlation between two continuous variables</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_SGLAQYWEYX\" value=\"answer\"></input> <span>To test the relationship between categorical variables</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe Chi-square test evaluates whether there is an association or relationship between two categorical variables. Those variables can either be nominal or ordinal.\n\n:::\n\n#### Question 2: Application - Chi-Square Test {.unnumbered}\n\n**Which of the following scenarios would require a Chi-square test?**\n\n<div class='webex-radiogroup' id='radio_UDKCJGRTYD'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UDKCJGRTYD\" value=\"x\"></input> <span>Comparing the average exam scores of students in two classrooms</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UDKCJGRTYD\" value=\"answer\"></input> <span>Determining if there is an association between people’s favourite pizza topping and their region of residence</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UDKCJGRTYD\" value=\"x\"></input> <span>Testing whether the average height of basketball players differs from the general population</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UDKCJGRTYD\" value=\"x\"></input> <span>Assessing whether the reaction times of drivers are influenced by caffeine consumption</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe only option with 2 categorical variables is pizza topping (e.g., pepperoni, vegetarian, cheese) and region of residence (e.g., North, South, East, West).\n\n:::\n\n\n#### Question 3: Interpreting Output - Chi-Square Test {.unnumbered}\n\n**In a Chi-square test, the p-value is .005. What does this imply if the significance level is set at .05?**\n\n<div class='webex-radiogroup' id='radio_YUCYGZNILL'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YUCYGZNILL\" value=\"x\"></input> <span>The null hypothesis is not rejected; there is a significant association.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YUCYGZNILL\" value=\"x\"></input> <span>The null hypothesis is rejected; there is no significant association.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YUCYGZNILL\" value=\"answer\"></input> <span>The null hypothesis is rejected; there is a significant association.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YUCYGZNILL\" value=\"x\"></input> <span>The null hypothesis is not rejected; there is no significant association.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nA p-value of .005 is less than the significance level (.05), indicating that the observed association between the variables is unlikely to have happened by chance.\n\n:::\n\n\n\n#### Question 4: Using R - Chi-Square Test {.unnumbered}\n\n**Which of the following R functions is used to perform a Chi-square test and displays a Cramer's V in the output?**\n\n<div class='webex-radiogroup' id='radio_UFDNUWVKYQ'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UFDNUWVKYQ\" value=\"x\"></input> <span>t.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UFDNUWVKYQ\" value=\"answer\"></input> <span>associationTest()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UFDNUWVKYQ\" value=\"x\"></input> <span>chisq.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_UFDNUWVKYQ\" value=\"x\"></input> <span>one.sample()</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe `associationTest()` function from the `lsr` package performs a Chi-square test and directly provides Cramer's V as part of the output. The `chisq.test()` function exists it but does not compute Cramer's V. The other options either don’t exist or don’t meet the criteria.\n\n:::\n\n\n\n#### Question 5: Conceptual Understanding - One-sample t-test {.unnumbered}\n\n**What is the null hypothesis in a one-sample t-test?**\n\n<div class='webex-radiogroup' id='radio_JAHQCHIWCD'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_JAHQCHIWCD\" value=\"x\"></input> <span>The sample mean is greater than the population mean</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_JAHQCHIWCD\" value=\"answer\"></input> <span>The sample mean is equal to the population mean</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_JAHQCHIWCD\" value=\"x\"></input> <span>The population mean is equal to zero</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_JAHQCHIWCD\" value=\"x\"></input> <span>The sample mean is less than the population mean</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nThe one-sample t-test tests whether the sample mean is significantly different from a known or hypothesised population mean.\n\n:::\n\n#### Question 6: Application - One-sample t-test {.unnumbered}\n\n**Which of the following scenarios would require a one-sample t-test?**\n\n<div class='webex-radiogroup' id='radio_NICBHMRRZO'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NICBHMRRZO\" value=\"x\"></input> <span>Comparing the average exam scores of students in two classrooms</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NICBHMRRZO\" value=\"x\"></input> <span>Determining if there is an association between people’s favourite pizza topping and their region of residence</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NICBHMRRZO\" value=\"answer\"></input> <span>Testing whether the average height of basketball players differs from the general population</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NICBHMRRZO\" value=\"x\"></input> <span>Assessing whether the reaction times of drivers are influenced by caffeine consumption</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nA one-sample t-test is appropriate when comparing the mean of a single sample (e.g., basketball players’ heights) to a known or hypothesised population mean (e.g., mean of the general population). The other options involve comparisons between groups (option 1), categorical associations (option 2), or repeated measures (option 4).\n\n:::\n\n\n#### Question 7: Interpreting Output - One-sample t-test {.unnumbered}\n\n**If the p-value in a one-sample t-test is .15 and the significance level is .05, what is the conclusion?**\n\n<div class='webex-radiogroup' id='radio_LSYGZPGNBO'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LSYGZPGNBO\" value=\"answer\"></input> <span>The sample mean is not significantly different from the population mean.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LSYGZPGNBO\" value=\"x\"></input> <span>The sample mean is significantly different from the population mean.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LSYGZPGNBO\" value=\"x\"></input> <span>The sample mean is further from the population mean than expected by chance.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LSYGZPGNBO\" value=\"x\"></input> <span>The sample mean is equal to the population mean.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nSince the p-value (.15) is greater than the significance level (.05), we fail to reject the null hypothesis. This means there is no evidence to suggest that the sample mean is significantly different from the population mean.\n\nHowever, this does not mean we have evidence to confirm that the sample mean is exactly equal to the population mean. In statistics, 'not significantly different' is not the same as 'equal.' Therefore, the option 'The sample mean is equal to the population mean' is incorrect.\n\n:::\n\n\n\n#### Question 8: Using R - One-sample t-test {.unnumbered}\n\n**Which of the following R functions is used to perform a one-sample t-test?**\n\n<div class='webex-radiogroup' id='radio_LKEBRELXAK'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LKEBRELXAK\" value=\"answer\"></input> <span>t.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LKEBRELXAK\" value=\"x\"></input> <span>associationTest()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LKEBRELXAK\" value=\"x\"></input> <span>chisq.test()</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_LKEBRELXAK\" value=\"x\"></input> <span>one.sample()</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\n`t.test()` is the standard function in R for performing a one-sample t-test. In the next 2 weeks, we will see that the function can also be used for two-sample and paired t-tests. \n\nThe function `one.sample()` does not exist. \n\nThe other two functions perform Chi-square tests, which are specifically designed for categorical variables. They cannot be used when one of the variables is continuous.\n\n:::\n\n",
    "supporting": [
      "06-chi-square-one-sample_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}