{
  "hash": "294fb40bbab5d355de5b5fc585d94f97",
  "result": {
    "markdown": "# Multiple regression {#sec-reg_mult}\n\n\n\n\n\n## Intended Learning Outcomes {.unnumbered}\n\nBy the end of this chapter you should be able to:\n\n- Apply and interpret multiple linear regression models.\n- Interpret coefficients from individual predictors and interactions.\n- Visualise interactions as model predictions to understand and communicate your findings.\n- Calculate statistical power for a multiple regression model.\n\nIn the previous chapter, we have looked at simple regressions - predicting an outcome variable using one predictor variable. In this chapter, we will expand on that and look at scenarios where we predict an outcome using more than one predictor in the model - hence, multiple regression.\n\n## [Individual Walkthrough]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n\n## Activity 1: Setup & download the data\n\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\n* **Create a new project** and name it something meaningful (e.g., \"2B_chapter11\", or \"11_multiple_regression\"). See @sec-project if you need some guidance.\n* **Create a new `.Rmd` file** and save it to your project folder. See @sec-rmd if you need help. \n* Delete everything after the setup code chunk (e.g., line 12 and below) \n* **Download the new dataset** here: [data_ch11.zip](data/data_ch11.zip \"download\"). The zip folder includes:\n  * the demographics data file (`Przybylski_2017_demographics.csv`)\n  * the screentime data file (`Przybylski_2017_screentime.csv`)\n  * the wellbeing data file (`Przybylski_2017_wellbeing.csv`), and the\n  * the codebook (`Przybylski_2017_Codebook.xlsx`).\n* Extract the data file from the zip folder and place it in your project folder. If you need help, see @sec-download_data_ch1.\n\n\n\n**Citation**\n\n> Przybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. *Psychological Science, 28*(2), 204-215. [https://doi.org/10.1177/0956797616678438](https://doi.org/10.1177/0956797616678438){target=\"_blank\"}\n\n\n\n\n**Abstract**\n\n> Although the time adolescents spend with digital technologies has sparked widespread concerns that their use might be negatively associated with mental well-being, these potential deleterious influences have not been rigorously studied. Using a preregistered plan for analyzing data collected from a representative sample of English adolescents (*n* = 120,115), we obtained evidence that the links between digital-screen time and mental well-being are described by quadratic functions. Further, our results showed that these links vary as a function of when digital technologies are used (i.e., weekday vs. weekend), suggesting that a full understanding of the impact of these recreational activities will require examining their functionality among other daily pursuits. Overall, the evidence indicated that moderate use of digital technology is not intrinsically harmful and may be advantageous in a connected world. The findings inform recommendations for limiting adolescents’ technology use and provide a template for conducting rigorous investigations into the relations between digital technology and children’s and adolescents’ health.\n\nThe data is available on OSF: [https://osf.io/bk7vw/](https://osf.io/bk7vw/){target=\"_blank\"}\n\n\n\n**Changes made to the dataset**\n\n* The original SPSS file was converted into a CSV format. Although a CSV file was available in the OSF folder, it lacked labels and value explanations, so we opted to work from the SPSS file, which contained more information.\n* We reduced the dataset by selecting some of the variables relating to demographics, screentime and wellbeing.\n* The data was split into three separate files: demographics, screentime, and wellbeing.\n* Screen time values were recoded to reflect hours according to the codebook.\n* Rows with missing values were removed from `screentime.csv` and `wellbeing.csv`.\n* A codebook was created for the selected variables.\n\n\n\n\n\n\n## Activity 2: Load in the library, read in the data, and familiarise yourself with the data\n\nToday, we will use the following packages `tidyverse`, `sjPlot`, `performance`, and `pwr`, along with the three data files from the Przybylski and Weinstein (2017) study.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n???\n\ndemo <- ???\nscreentime <- ???\nwellbeing <- ???\n```\n:::\n\n\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(performance)\nlibrary(pwr)\n\ndemo <- read_csv(\"Przybylski_2017_demographics.csv\")\nscreentime <- read_csv(\"Przybylski_2017_screentime.csv\")\nwellbeing <- read_csv(\"Przybylski_2017_wellbeing.csv\")\n```\n:::\n\n\n:::\n\nAs always, take a moment to familiarise yourself with the data before starting your analysis.\n\nOnce you have explored the data objects and the codebook, try and answer the following questions: \n\n* The variable **Gender** is located in the object named <select class='webex-select'><option value='blank'></option><option value='answer'>demo</option><option value='x'>wellbeing</option><option value='x'>screentime</option></select>.\n* The **wellbeing data** is in <select class='webex-select'><option value='blank'></option><option value='x'>long</option><option value='answer'>wide</option></select> format and contains observations from <input class='webex-solveme nospaces' size='7' data-answer='[\"102580\",\"102,580\"]'/> participants. \n* The **wellbeing questionnaire** has <input class='webex-solveme nospaces' size='2' data-answer='[\"14\"]'/> items.\n* Individual participants in this dataset are identified by the variable <input class='webex-solveme nospaces' size='6' data-answer='[\"Serial\"]'/>, which allows us to link information across the three tables.\n* Are there any missing data points? <select class='webex-select'><option value='blank'></option><option value='x'>Yes</option><option value='answer'>No</option></select>\n\n\n#### Potential Research Question & Hypthesis {.unnumbered}\n\nThere is ongoing debate about how smartphones affect well-being, particularly among children and teenagers. Therefore, we will examine whether smartphone use predicts mental well-being and whether this relationship varies by gender among adolescents.\n\n\n* **Potential research question**: \"Does smartphone use predict mental well-being, and does this relationship differ between male and female adolescents?\"\n* **Null Hypothesis (H~0~)**: \"Smartphone use does not predict mental well-being, and there is no difference in this relationship between male and female adolescents.\"\n* **Alternative Hypothesis (H~1~)**: \"Smartphone use is a significant predictor of mental well-being, and the effect of smartphone use on well-being differs between male and female adolescents.\"\n\n\n\nNote that in this analysis, we have:\n\n* A continuous dependent variable (DV)/Outcome: well-being\n* A continuous independent variable (IV)/Predictor: screen time\n* A categorical independent variable (IV)/Predictor: gender\n\n_* these variables are only quasi-continuous, inasmuch as only discrete values are possible. However, there are a sufficient number of discrete categories that we can treat them as effectively continuous._\n\n## Activity 3: Compute descriptives\n\nToday, most of the data wrangling will be done in the upcoming activities. To streamline the process, we will move \"Computing descriptives\" forward.\n\n\n### Well-being \n\nWe need to do some initial data wrangling on `wellbeing`.\n\nFor each participant, compute the total score for the mental health questionnaire. Store the output in a new data object called `wemwbs`. \n\nThe new dataset should have two variables:\n\n* `Serial` - the participant ID.\n* `WEMWBS_sum` - the total WEMWBS score.\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwemwbs <- wellbeing %>%\n  pivot_longer(cols = starts_with(\"WB\"), # -Serial or WBOptimf:WBCheer also work\n               names_to = \"Qs\", \n               values_to = \"Score\") %>%\n  group_by(Serial) %>%\n  summarise(WEMWBS_sum = sum(Score)) %>% \n  ungroup()\n```\n:::\n\n\n:::\n\n\nIn the original paper, Przybylski and Weinstein (2017) reported: \"Scores ranged from 14 to 70 (M = 47.52, SD = 9.55)\". Can you reproduce these values?\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hint\n\nMeans and standard deviations should not be an issue at this stage, but how would you calculate the minimum and the maximum? \n\nWe briefly covered this in @sec-wrangling, and the solution is more intuitive than you might think...\n\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nYes, that's right! The functions `min()` and `max()` are used to calculate the minimum and maximum values, respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwemwbs %>% \n  summarise(mean = mean(WEMWBS_sum),\n            sd = sd(WEMWBS_sum),\n            min = min(WEMWBS_sum),\n            max = max(WEMWBS_sum))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|     mean|       sd| min| max|\n|--------:|--------:|---:|---:|\n| 47.52189| 9.546374|  14|  70|\n\n</div>\n:::\n:::\n\n:::\n\n\n### Screentime\n\nWe need to calculate the means and standard deviations for smartphone use (in hours) during the week and on the weekend.\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nAt this stage, we are simply computing the values rather than storing them. However, if you’d like to save the output as an object in your `Global Environment`, feel free to do so.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscreentime %>% \n  summarise(smart_weekday_mean = mean(Smart_wk),\n            smart_weekday_sd = sd(Smart_wk),\n            smart_weekend_mean = mean(Smart_we),\n            smart_weekend_sd = sd(Smart_we))\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| smart_weekday_mean| smart_weekday_sd| smart_weekend_mean| smart_weekend_sd|\n|------------------:|----------------:|------------------:|----------------:|\n|           2.910655|          2.33917|           3.517003|         2.497139|\n\n</div>\n:::\n:::\n\n:::\n\n\n## Activity 4: Recreating the plot from the paper\n\nIf there's a challenge in this session, this is it! Our task is to wrangle the data and recreate the plot from the original article (shown below).\n\n![Fig. 1. Mental well-being as a function of daily digital-screen time on weekdays and weekends. Results are shown separately for time spent (a) watching TV and movies, (b) playing video games, (c) using computers, and (d) using smartphones. Error bars denote the 95% confidence intervals for the observed means. (Przybylski & Weinstein, 2017)](images/figure_Przybylski.jpeg)\n\nThe graph shows that smartphone use of more than 1 hour per day is associated with increasingly negative well-being.\n\nWe can plot the relationship between well-being and hours of technology use, split into four categories of technology (video games, computers, smartphones, TV).\n\nThis plot involves faceting, and some of the required functions may be new to you. Don't worry—we'll guide you through the process!\n\n::: {.callout-tip icon=\"false\"}\n\n## Observations\n\nLet's start with some observations:\n\nA) We need data on screen time (x-axis) and mental well-being (y-axis), which are currently stored in `screentime` and `wellbeing`, respectively. This means we will need to join the two datasets at some point.\n\nB) The data needs to be restructured into long format so we can use the function `facet_wrap()`.\n\nC) Since the plot includes separate lines for weekday and weekend screen time, we need to create a variable with two levels (weekday, weekend) rather than storing this information in separate columns.\n\nD) We also need to compute the average well-being scores for each screen time level, separately for weekdays and weekends.\n\nE) The visualization requires both a line plot (`geom_line()`) and a scatterplot (`geom_point()`) to create a \"line with dots\".\n\nF) For clarity, it would be best to label the different technology categories directly in the plot rather than listing them in the figure caption.\n\n:::\n\nNow it's just figuring out which sequence we need them to be in. There are steps to do (or that easier to do) in the dataframe and then there is plotting. \n\nSooo, let's start with any changes we can apply to the dataframe `screentime`. We should store the new output in an object called `screen_long`.\n\n**Step 1**: Pivot `screentime` into long format.\n\n**Step 2**: Extracting technology type and time period\nTo access information on weekday/weekend and the four categories of technology, we need to separate information currently stored in column names. Anything **before** the separator `_` represents the **technology type**. Anything **after** the separator `_` indicates whether the data is from **weekdays (`wk`) or weekends (`we`)**. (e.g., `Watch_we`, `Smart_wk`). Restructuring is easier when the data is in long format.\n\n**Step 3**: The current labels `Watch`, `Smart`, `we` or `wk` are not really informative. Since these labels will be displayed in the facets and legends of the final plot, we should rename them here to improve readability. Although legend labels can be adjusted later in the plot, facet labels are more difficult to modify, so it’s better to clean them now.\n\n* \"Watch\" $\\rightarrow$ \"Watching TV\",\n* \"Comp\" $\\rightarrow$ \"Playing Video Games\",\n* \"Comph\" $\\rightarrow$ \"Using Computers\",\n* \"Smart\" $\\rightarrow$ \"Using Smartphone\",\n* \"wk\" $\\rightarrow$ \"Weekdays\", and\n* \"we\" $\\rightarrow$ \"Weekends\".\n\n**Step 4**: To ensure all necessary information is in one place, join `screen_long` and `wemwbs` so that each participant has corresponding values from both dataframes.\n\n**Step 5**: For each technology type and screen time level, compute the average well-being scores separately for weekdays and weekends. \n\nSince steps 4 and 5 contribute to creating a summary dataset rather than modifying individual records, it might be best to store the output in a new object called `dat_means`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n## Hints\n\n* Step 1: uses `pivot_longer()`\n* Step 2: remember the `separate()` function. It will come in handy here. And the separator needs to be \"_\".\n* Step 3: requires a simple recoding of the values, no conditional statements necessary\n* Step 4: `inner_join()`\n* Step 5: think about what column you need to `group_by()` before you can `summarise()`\n\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\nWe are just computing the information rather than storing it. If you want to save it as an object to your `Global Environment`, feel free to do so.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscreen_long <- screentime %>%\n  # Step 1: Pivot into long format\n  pivot_longer(cols = -Serial, names_to = \"headings\", values_to = \"hours\") %>%\n  # Step 2: `separate()`\n  separate(col = headings, into = c(\"technology_type\", \"day\"), sep = \"_\") %>% \n  # Step 3: Recode the values\n  mutate(technology_type = case_match(technology_type,\n                                      \"Watch\" ~ \"Watching TV\",\n                                      \"Comp\" ~ \"Playing Video Games\",\n                                      \"Comph\" ~ \"Using Computers\",\n                                      \"Smart\" ~ \"Using Smartphone\"),\n         day = case_match(day,\n                          \"wk\" ~ \"Weekdays\",\n                          \"we\" ~ \"Weekends\"))\n\ndat_means <- inner_join(wemwbs, screen_long, by = \"Serial\") %>% # Step 4: joining\n  # Step 5: group_by & summarise\n  group_by(technology_type, day, hours) %>%\n  summarise(mean_wellbeing = mean(WEMWBS_sum))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`summarise()` has grouped output by 'technology_type', 'day'. You can override\nusing the `.groups` argument.\n```\n:::\n:::\n\n:::\n\nNow we are ready to create the plot! This visualization includes a few new features related to line plots and point shapes. Take a moment to explore them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat_means, aes(x = hours, y = mean_wellbeing, linetype = day, shape = day)) +\n  geom_line() +\n  geom_point() +\n  scale_shape_manual(values=c(15, 16)) +\n  facet_wrap(~ technology_type) + \n  theme_classic() + \n  labs(x = \"Hours of Technology Use\",\n       y = \"Mean Well-Being Score\")\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## More info on plot parameters\n\n* The `aes(linetype = …)` argument controls the type of line (e.g., solid or dotted). Here, we used it to differentiate between weekdays and weekends. More on line types can be found here: [https://sape.inf.usi.ch/quick-reference/ggplot2/linetype.html](https://sape.inf.usi.ch/quick-reference/ggplot2/linetype.html){target=\"_blank\"}\n* To change the shape of the points, we set `shape` inside `aes()`, linking it to the day type. However, by default, the shapes appeared as dots and triangles, whereas the original plot suggests dots and squares. We corrected this using `scale_shape_manual()`. More on point shapes can be found here: [https://www.sthda.com/english/wiki/ggplot2-point-shapes](https://www.sthda.com/english/wiki/ggplot2-point-shapes){target=\"_blank\"}\n\nIf you are looking really closely, you will notice that the order of the categories is slightly different, and that the x- and y-axis ranges extend a bit further. Feel free to fix that yourself.\n\nHmm. Actually, it seems the original authors created four separate plots and then combined them using a package like `patchwork`. Here, we used facets rather than creating those individual plots. That also means that the axis labels span across all plots rather than being repeated for each. Plus, the legend appears on the side instead of within each plot.\n\nAh well! Let's call it a conceptual replication, then, shall we?\n\n:::\n\n\n\n## Activity 5: Dataframe for the regression model\n\nNow, we shift our focus to our hypothetical research question:\n\n>\"Does smartphone use predict mental well-being, and does this relationship differ between male and female adolescents?\"\n\n### Final data wrangling steps\n\nCreate a new data object that contains the average daily smartphone use per participant, averaged across weekdays and weekends.\n\nSince Przybylski and Weinstein's findings suggest that smartphone use exceeding one hour per day is associated with increasingly negative well-being, we will filter the data to include only participants who use a smartphone for more than one hour per day.\n\nWe have already structured much of the data when creating `screen_long`, so we have two options:\n\n* Start from `screen_long` to simplify the process, or\n* Return to the original `screentime` dataset, where smartphone use was recorded separately for weekdays and weekends.\n\nNext, we need to merge the wrangled data with well-being scores (as we did earlier) and also join it with the participant information, since we need the Gender variable for our analysis.\n\nFinally, store the cleaned dataset in an object called `data_smartphone`.\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints: Option 1 (using `screen_long`)\n\n* Step 1: Only include smartphone use and exclude other technologies.\n* Step 2: Calculate the average smartphone use for each participant.\n* Step 3: Only include participants who use a smartphone for more than 1 hour per day.\n* Step 4: Join the filtered output with `wemwbs`, and `demo`, ensuring only participants with values in all three datasets are retained.\n* Step 5: Select all variables of interest (i.e., Participant ID, the well-being score, the average smartphone use, and gender information)\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution Option 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_smartphone <- screen_long %>% \n  # Step 1\n  filter(technology_type == \"Using Smartphone\") %>% \n  # Step 2\n  group_by(Serial) %>% \n  summarise(average_hours = mean(hours)) %>% \n  # Step 3\n  filter(average_hours > 1) %>% \n  # Step 4\n  inner_join(wemwbs) %>% \n  inner_join(demo) %>% \n  # Step 5\n  select(Serial, WEMWBS_sum, average_hours, Gender)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Serial)`\nJoining with `by = join_by(Serial)`\n```\n:::\n:::\n\n:::\n\n::: {.callout-note collapse=\"true\" icon=\"false\"}\n\n## Hints Option 2 (using `screentime`)\n\n* Step 1: Select all relevant variables from `screentime`. \n* Step 2: Calculate the average smartphone use for each participant. This can be done by pivoting, grouping, and summarising (as we typically do), or simply by computing the mean as `(col1 + col2) / 2`.\n* Step 3: Only include participants who use a smartphone for more than 1 hour per day.\n* Step 4: Join the filtered output with `wemwbs`, and `demo`, ensuring only participants with values in all three datasets are retained.\n* Step 5: Select all variables of interest (i.e., Participant ID, the well-being score, the average smartphone use, and gender information)\n\n:::\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution Option 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_smartphone <- screentime %>% \n  # Step 1\n  select(Serial, Smart_wk, Smart_we) %>% \n  # Step 2 - different approach to computing averages\n  mutate(average_hours = (Smart_wk + Smart_we)/2) %>% \n  # Step 3\n  filter(average_hours > 1) %>% \n  # Step 4\n  inner_join(wemwbs) %>% \n  inner_join(demo) %>% \n  # Step 5\n  select(Serial, WEMWBS_sum, average_hours, Gender)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Serial)`\nJoining with `by = join_by(Serial)`\n```\n:::\n:::\n\n:::\n\n### Mean-centering variables\n\nAs you have seen in the lectures, when you have continuous variables in a regression model, it is often sensible to transform them by **mean centering**. You mean center a predictor `X` by subtracting the mean of the predictor (`X_centered = X - mean(X)`) or you can use the `scale()` function. This has two useful consequences:\n\n- The model intercept represents the predicted value of $Y$ when the predictor variable is at its mean, rather than at zero in the unscaled version.\n\n- When interactions are included in the model, significant effects can be interpreted as the overall effect of a predictor on the outcome (i.e., a main effect) rather than its effect at a specific level of another predictor (i.e., a simple effect).\n\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0). This is also known as deviation coding.\n\nIf we used dummy coding (i.e., leaving the categorical predictor as \"Male\" and \"Female or unknown; default for R) instead of deviation coding, the interpretation would change slightly:\n\n* **Dummy-coding interpretation**: The intercept represents the predicted outcome for the reference group (coded as 0), and the coefficient for the categorical predictor represents the difference in the outcome between the two groups.\n* **Deviation-coding interpretation**: The intercept represents the overall mean outcome across both groups, and the coefficient for the categorical predictor represents the average difference between the two groups, centered around zero.\n\n\nUse `mutate()` to add two new variables to `data_smartphone`: \n\n* `average_hours_centered`: calculated as a mean-centered version of the `total_hours` predictor\n* `gender_recoded`: recode Gender .5 for \"Male\" and -.5 for \"Female or unknown\".\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_smartphone <- data_smartphone %>%\n  mutate(average_hours_centered = average_hours - mean(average_hours),\n         #alternative with the scale function: \n         #average_hours_centered = scale(average_hours, scale = FALSE),\n         gender_recoded = case_match(Gender,\n                                     \"Male\"  ~ 0.5,\n                                     \"Female or unknown\" ~ -0.5),\n         gender_recoded = factor(gender_recoded),\n         Gender = factor(Gender))\n```\n:::\n\n:::\n\n\n\n## Activity 6: Compute the regression, confidence intervals, and effect size\n\nFor the data in `data_smartphone`, use the `lm()` function to calculate the multiple regression model:\n\n$Y_i = \\beta_0 + \\beta_1 X_{1i}  + \\beta_2 X_{2i}  + \\beta_3 X_{3i} + e_i$\n\nwhere\n\n- $Y_i$ is the well-being score for participant $i$;\n\n- $X_{1i}$ is the mean-centered smartphone use for participant $i$;\n\n- $X_{2i}$ is gender (coded as -0.5 = female, 0.5 = male);\n\n- $X_{3i}$ is the interaction between smartphone use and gender ($= X_{1i} \\times X_{2i}$)\n\nIn R, this model is specified as:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(Outcome ~ Predictor1 + Predictor2 + Interaction, data)\n```\n:::\n\n\n\n\n::: {.callout-tip}\n\nThe formula `lm(Outcome ~ Predictor1 + Predictor2, data)` includes both predictors in the model, allowing you to examine their individual contributions (i.e., main effects) in explaining the outcome variable.\n\nHowever, if you are also interested in their interaction, you have two options:\n\n* Using the shorthand `*` operator: `lm(Outcome ~ Predictor1 * Predictor2, data)` automatically includes both main effects and their interaction. OR\n* Manually specifying the interaction term by using the `:` operator: `lm(Outcome ~ Predictor1 + Predictor2 + Predictor1:Predictor2, data)`. **Note:** The colon (`:`) specifies an interaction term without including the main effects, so both predictors must also be listed separately to ensure a full model.\n\nBoth approaches yield the same results, but the `*` shorthand is often preferred for readability.\n\n:::\n\n::: {.callout-note icon=\"false\"}\n\n## Your Turn\n\n* Save your model in an object `mod`. \n* Run `summary(mod)` to see the output of the regression. \n* Compute confidence intervals for the model coefficients.\n* Calculate the effect size ($f^2$).\n\nThe functions you’ll use are the same as last time, except that this model includes multiple predictors and an interaction term.\n\nAnswer the following questions:\n\n* The interaction between smartphone use and gender is shown by the variable <select class='webex-select'><option value='blank'></option><option value='x'>average_hours_centered</option><option value='x'>gender_recoded0.5</option><option value='answer'>average_hours_centered:gender_recoded0.5</option></select>, and this interaction was <select class='webex-select'><option value='blank'></option><option value='answer'>significant</option><option value='x'>non-significant</option></select> at the $\\alpha = .05$ level.\n\n* To 2 decimal places, adjusted $R^2$ suggests the overall model explains what percentage of the variance in well-being scores? <input class='webex-solveme nospaces' size='4' data-answer='[\"9.38\"]'/>\n\n* The *p*-value for the overall model fit is `<2e-16`. Is this statistically significant? <select class='webex-select'><option value='blank'></option><option value='answer'>Yes</option><option value=''>No</option></select>. How would you note that p-value in APA style when writing up the results? <input class='webex-solveme nospaces' size='8' data-answer='[\"p<.001\",\"p < .001\"]'/>\n\n* What is the observed effect size (in $f^2$) for the study to 3 decimal places? <input class='webex-solveme nospaces' data-tol='0.001' size='5' data-answer='[\"0.103\",\".103\"]'/> \n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## model\nmod <- lm(formula = WEMWBS_sum ~ average_hours_centered * gender_recoded, \n               data = data_smartphone)\n\n## regression output\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = WEMWBS_sum ~ average_hours_centered * gender_recoded, \n    data = data_smartphone)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                                         Estimate Std. Error t value Pr(>|t|)\n(Intercept)                              44.86740    0.04478 1001.87   <2e-16\naverage_hours_centered                   -0.77121    0.02340  -32.96   <2e-16\ngender_recoded0.5                         5.13968    0.07113   72.25   <2e-16\naverage_hours_centered:gender_recoded0.5  0.45205    0.03693   12.24   <2e-16\n                                            \n(Intercept)                              ***\naverage_hours_centered                   ***\ngender_recoded0.5                        ***\naverage_hours_centered:gender_recoded0.5 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,\tAdjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## confidence intervals\nconfint(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                              2.5 %     97.5 %\n(Intercept)                              44.7796275 44.9551788\naverage_hours_centered                   -0.8170719 -0.7253385\ngender_recoded0.5                         5.0002576  5.2791028\naverage_hours_centered:gender_recoded0.5  0.3796615  0.5244376\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## effect size\nr_sq_adj <- summary(mod)$adj.r.squared\nf_2 <- r_sq_adj/(1-r_sq_adj)\nf_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1034697\n```\n:::\n:::\n\n\n:::\n\n:::\n\n## Activity 7: Visualising interactions {#ch11_act_7}\n\nIt is very difficult to understand an interaction from the coefficient alone, so your best bet is visualising the interaction to help you understand the results and communicate your results to your readers. \n\nThere is a great package called `sjPlot` which takes regression models and helps you plot them in different ways. We will demonstrate plotting interactions, but for further information and options, see the [online documentation](https://strengejacke.github.io/sjPlot/articles/plot_interactions.html){target=\"_blank\"}.\n\nTo plot the interaction, you need the model object (not the summary), specify \"pred\" as the `type` as we want to plot predictions, and add the `terms` you want to plot. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(mod, \n           type = \"pred\", \n           terms = c(\"average_hours_centered\", \"gender_recoded\"))\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nWhat is the most reasonable interpretation of the interaction? \n\n<div class='webex-radiogroup' id='radio_WIUBBLPGTO'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WIUBBLPGTO\" value=\"answer\"></input> <span>smartphone use was more negatively associated with wellbeing for girls than for boys</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WIUBBLPGTO\" value=\"x\"></input> <span>there is no evidence for gender differences in the relationship between smartphone use and well-being</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WIUBBLPGTO\" value=\"x\"></input> <span>smartphone use harms boys more than girls</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WIUBBLPGTO\" value=\"x\"></input> <span>smartphone use harms girls more than boys</span></label></div>\n\n\n\n\n::: {.callout-note} \n\n`plot_model()` uses `ggplot2` in the background. You can add further customisation by adding layers after the initial function. You can also use `ggsave()` to save your plots and insert them into your work. \n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n## Example of a more tidy plot\n\nFor example, we can tidy up the axis labels and remove the title, and set a theme. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_model(mod, \n           type = \"pred\", \n           terms = c(\"average_hours_centered\", \"gender_recoded\")) + \n  labs(x = \"Total Hours Smartphone Use\",\n       y = \"Total Well-Being Score\",\n       title = \"\") + \n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n:::\n\n:::\n\n\n## Activity 8: Check assumptions\n\nNow it's time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity. This is the idea that predictor variables should not be too highly correlated.\n\nAssumptions are:\n\n1. The outcome/DV is a interval/ratio level data, and the predictor variable is interval/ratio or categorical (with two levels).\n2. All values of the outcome variable are independent (i.e., each score should come from a different participant). \n3. The predictors have non-zero variance.\n4. The relationship between outcome and predictor is linear.\n5. The residuals should be normally distributed.\n6. There should be homoscedasticity (homogeneity of variance, but for the residuals).\n7. Multicollinearity: predictor variables should not be too highly correlated.\n\nWe can use the `plot()` function for diagnostic plots or the `check_model()` from the `performance` package. \n\nOne difference from when we used `check_model()` previously is that rather than just letting it run all the tests it wants, we are going to specify which tests to stop it throwing an error. \n\n::: {.callout-important}\n\nA word of warning - these assumption tests will take longer than usual to run because it's such a big data set.\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(mod, \n            check = c(\"vif\", \n                      \"qq\", \n                      \"normality\", \n                      \"linearity\", \n                      \"homogeneity\"))\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n#### Assumptions 1-3 {.unnumbered}\n\nFrom the work we have done so far, we know that we meet assumptions 1-3.\n\n\n#### Assumption 4: Linearity {.unnumbered}\n\nWe already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\n\n#### Assumption 5: Normality of residuals {.unnumbered}\n\nThe residuals look good in both plots and this provides an excellent example of why it's often better to visualise than rely on statistics. With a sample size this large, any statistical diagnostic tests will be highly significant as they are sensitive to sample size.\n\n#### Assumption 6: Homoscedasticity {.unnumbered}\n\nThe plot is missing the reference line. Fun fact, this took us several days of our lives and asking for help on social media to figure out. The reason the line is not there is because the data set is so large that is creates a memory issue. However, if you use the `plot()` version, it does show the reference line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(mod, which = 3)\n```\n\n::: {.cell-output-display}\n![](11-multiple-regression_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nIt is not perfect, but the reference line is roughly flat to suggest there are no serious issues with homoscedasticity. \n\n#### Assumption 7: Multicollinearity {.unnumbered}\n\nFrom the collinearity plot, we can see that both main effects and the interaction term are in the \"green zone\" which is great. Howeverm we can also test this statistically using `check_collinearity()` to produce VIF (variance inflation factor) and tolerance values.\n\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor is not actually adding any unique variance to the model, it's just really strongly related to other predictors. [You can read more about this online](https://statisticalhorizons.com/multicollinearity){target=\"_blank\"}. Thankfully, VIF is not affected by large samples like other statistical diagnostic tests.\n\nThere are various rules of thumb, but most converge on a **VIF of above 2 - 2.5** for any one predictor to be problematic. Here we are well under 2 for all 3 terms of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(mod)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Term                                  |      VIF| VIF_CI_low| VIF_CI_high| SE_factor| Tolerance| Tolerance_CI_low| Tolerance_CI_high|\n|:-------------------------------------|--------:|----------:|-----------:|---------:|---------:|----------------:|-----------------:|\n|average_hours_centered                | 1.721968|   1.704219|    1.740165|  1.312238| 0.5807308|        0.5746582|         0.5867789|\n|gender_recoded                        | 1.035552|   1.028488|    1.044369|  1.017621| 0.9656682|        0.9575159|         0.9723014|\n|average_hours_centered:gender_recoded | 1.716349|   1.698683|    1.734463|  1.310095| 0.5826319|        0.5765474|         0.5886915|\n\n</div>\n:::\n:::\n\n\n## Activity 9: Sensitivity power analysis\n\nAs usual, we want to calculate the smallest effect size that our study was able to detect, given our design and sample size.\n\nTo do this, we use the `pwr.f2.test()` function from the `pwr` package. This is the same as in chapter 10 for simple linear regression. Remember the arguments for this function:\n\n\n* `u` = Numerator degrees of freedom. This the number of coefficients you have in your model (minus the intercept)\n* `v` = Denominator degrees of freedom. This is calculated as $v=n-u-1$, where $n$ is the number of participants.\n* `f2` = The effect size. Here we are solving the effect size, so this parameter is left out\n* `sig.level` = The significance level of your study. This is usually set to 0.05 \n* `power` = The power level of your study. This is usually set to 0.8, but let's go for 0.99 this time (just because we have such a large number of participants)\n\n\nRun the sensitivity power analysis and then answer the following questions:\n\n* To 4 decimal places, what is the smallest effect size that this study could reliably detect? <input class='webex-solveme nospaces' size='0.0004' data-answer='[\".0004\"]'/>\n\nSince the observed effect size from our inferential statistics was <select class='webex-select'><option value='blank'></option><option value='x'>smaller</option><option value='answer'>larger</option></select> than the effect you could reliably detect with this design, the test was <select class='webex-select'><option value='blank'></option><option value='answer'>sufficiently powered</option><option value=''>underpowered</option></select> to detect the observed effect. \n\n::: {.callout-caution collapse=\"true\" icon=\"false\"} \n\n## Solution \n\n\n::: {.cell}\n\n```{.r .cell-code}\npwr.f2.test(u = 3, v = 71029, sig.level = 0.05, power = 0.99)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n```\n:::\n:::\n\n\nThe study was incredibly sensitive, where they would detect effects of \n$f^2 = .0004$ with 99% power. Needless to say, this study was sufficiently powered.\n:::\n\n## Activity 10: The write-up\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted wellbeing $(F(3, 71029) = 2451, p < .001, R^2_{Adjusted} = .094, f^2 = 0.103)$, accounting for 9.4% of the variance. Total screen time was a significant negative predictor of wellbeing scores $(\\beta = -0.77, 95\\% CI = [-0.82, -0.73], p < .001$), as was gender $(\\beta = 5.14, p < .001$), with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screen time and gender $(\\beta = 0.45, 95\\% CI = [0.38, 0.52], p < .001$), meaning that smartphone use was more negatively associated with well-being for girls than for boys. Therefore, we reject the null hypothesis in favour of H~1~, as smartphone use significantly predicted wellbeing and this relationship differed between boys and girls. The analysis was sufficiently powered to detect this effect.\n\n\n\n\n## [Test your knowledge]{style=\"color: #F39C12; text-transform: uppercase;\"} {.unnumbered}\n\n#### Question 1 {.unnumbered}\n\n**What is the main purpose of a multiple regression analysis?**\n\n<div class='webex-radiogroup' id='radio_NOLLQTOZRD'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NOLLQTOZRD\" value=\"answer\"></input> <span>To predict or explain changes in an outcome variable based on multiple predictor variables.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NOLLQTOZRD\" value=\"x\"></input> <span>To determine whether there is an association between two variables, without assuming causality.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NOLLQTOZRD\" value=\"x\"></input> <span>To test whether one predictor variable explains the outcome variable while ignoring other potential influences.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_NOLLQTOZRD\" value=\"x\"></input> <span>To compare means between two groups and determine if they are significantly different.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nMultiple regression extends simple regression by including multiple predictors to explain variance in the outcome variable. This allows researchers to assess the unique contribution of each predictor while controlling for others.\n\n* One incorrect option describes correlation rather than regression.\n* Another option describes a t-test, which compares means rather than predicting an outcome.\n* The final incorrect option incorrectly implies that multiple regression ignores other predictors, when in fact it accounts for them.\n\n:::\n\n#### Question 2 {.unnumbered}\n\n**A researcher investigates whether a student’s exam performance can be predicted by their hours of study and test anxiety levels.**\n\n**Which of the following correctly specifies the multiple regression model in R?**\n\n<div class='webex-radiogroup' id='radio_HRUXZKVUYL'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HRUXZKVUYL\" value=\"answer\"></input> <span>lm(Exam_Score ~ Study_Hours + Test_Anxiety, data = student_data)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HRUXZKVUYL\" value=\"x\"></input> <span>lm(Study_Hours ~ Exam_Score + Test_Anxiety, data = student_data)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HRUXZKVUYL\" value=\"x\"></input> <span>lm(Exam_Score ~ Study_Hours * Test_Anxiety, data = student_data)</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_HRUXZKVUYL\" value=\"x\"></input> <span>lm(Test_Anxiety ~ Study_Hours + Exam_Score, data = student_data)</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nIn multiple regression, the **dependent variable (outcome)** is placed first, followed by the predictor variables (independent variables) after the tilde (~). Since we are predicting exam scores, this must be the first variable in the formula.\n\n* One incorrect option includes an interaction term (`*`), which was not specified in the task. A basic multiple regression only includes main effects (`+`).\n* Another incorrect option swaps the predictor and outcome, which would lead to an incorrect model specification.\n* The last incorrect option incorrectly treats test anxiety as the outcome, when it is actually a predictor in the model.\n:::\n\n\n#### Question 3 {.unnumbered}\n\n**A multiple regression model is used to predict life satisfaction based on sleep quality and daily screen time. The output includes the following regression equation:**\n\n$Life Satisfaction = 50.2 + 1.8 * Sleep Quality − 0.9 * ScreenTime$\n\n**How should the coefficient for Sleep Quality (1.8) be interpreted??**\n\n<div class='webex-radiogroup' id='radio_XWXMTGVXQL'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWXMTGVXQL\" value=\"answer\"></input> <span>For each one-unit increase in sleep quality, life satisfaction is expected to increase by 1.8, holding screen time constant.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWXMTGVXQL\" value=\"x\"></input> <span>A one-unit increase in sleep quality always leads to a 1.8-point increase in life satisfaction.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWXMTGVXQL\" value=\"x\"></input> <span>A one-unit increase in sleep quality may lead to a decrease in life satisfaction, depending on screen time.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_XWXMTGVXQL\" value=\"x\"></input> <span>For each one-unit increase in sleep quality, life satisfaction is expected to increase by 1.8, regardless of screen time.</span></label></div>\n\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nIn multiple regression, the coefficient represents the expected change in the outcome variable (life satisfaction) for a one-unit increase in the predictor (sleep quality), holding all other predictors constant.\n\nWhy are the other options incorrect?\n\n* One option ignores the need to hold other predictors constant, which is a key feature of multiple regression.\n* Another option implies a deterministic relationship, incorrectly stating that the increase always occurs.\n* The final incorrect option incorrectly suggests that sleep quality could have a negative effect on life satisfaction, when the model shows a clear positive relationship.\n\n:::\n\n\n\n#### Question 4 {.unnumbered}\n\n**A multiple regression model predicts self-esteem based on social support and stress levels. The output includes an interaction term for social support and stress with a p-value of .007. What does this suggest?**\n\n<div class='webex-radiogroup' id='radio_BYOEFRPYEK'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BYOEFRPYEK\" value=\"answer\"></input> <span>The relationship between stress and self-esteem depends on social support.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BYOEFRPYEK\" value=\"x\"></input> <span>Social support and stress both influence self-esteem, but they do not interact.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BYOEFRPYEK\" value=\"x\"></input> <span>The interaction term suggests that social support and stress are highly correlated and should be removed from the model.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BYOEFRPYEK\" value=\"x\"></input> <span>Social support directly improves self-esteem, so the interaction term is unnecessary.</span></label></div>\n\n\n::: {.callout-caution collapse=\"true\" icon=\"false\"}\n\n## Explain this answer\n\nA significant interaction term $(p = .007)$ means that the effect of stress on self-esteem is different at different levels of social support.\n\nWhy are the other options incorrect?\n\n* One option ignores the interaction effect, treating the predictors as independent influences.\n* Another incorrectly assumes that social support’s direct effect makes the interaction term unnecessary, when in reality, interactions test whether one predictor alters another’s effect.\n* The last incorrect option confuses interaction effects with multicollinearity. High correlation between predictors does not automatically mean an interaction term should be removed.\n\n:::\n\n\n\n",
    "supporting": [
      "11-multiple-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}