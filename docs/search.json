[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysis",
    "section": "",
    "text": "Overview\nThis course covers data skills R Markdown, data wrangling, and data visualisation. This book also introduces learners to the most common statistical analyses such as t-test, correlations, regressions, and ANOVAs. The main idea of this book is being reproducible in our data analysis approach.\n\nHow To Use This Book\nThe INDIVIDUAL WALKTHROUGH CHAPTERS contain an individual walkthrough section, followed by some questions to test your own knowledge:\n\nIndividual walkthrough: Complete this section at your own pace. Take your time to complete the guided activities. Plan for time pockets in your week to work through this section.\nTest your knowledge: At the end of each chapter is a short quiz that assesses your knowledge and skills covered in the chapter.\n\nThe IN-LAB: PAIR-CODING part contains lab materials. During the lab we are reserving time for you to work through activities with a peer. If you get stuck, try to solve the issue. A GTA and your tutor will be available to help you, too. At the start of each page, you can find the chapter the pair coding tasks relate to.\nTo support you to work through the book chapters continuously, we have scheduled each chapter so that it aligns as well as possible with the stats lectures and the lab content. We also made sure that no chapters are scheduled during busy assessment times (such as during the run-up to the research report deadline).\nIf you get stuck, seek help during your lab, GTA or PAL support sessions, and/or by posting on the Data Skills and R channel on Teams.\n\n\nStatement on use of AI\nChatGPT 4.0 was used to assist in the writing of these materials in the following ways:\n\nTo suggest multiple-choice questions in the “Test your knowledge and challenge yourself” section\nTo proof-read and check for typos\nTo suggest improvements to the text\n\nAny information provided by ChatGPT was verified, for example, where code was used, the syntax and output was checked to ensure it was correct and where theoretical or conceptual information was provided, only that which the author could verify from their pre-existing expertise was included.\nNote & Contact: This book is currently being updated which means that chapters are being published on a rolling basis. We regularly check and update for improvements. If you have any feedback or suggestions, please submit them to our Analysis R Book Improvement form. For people outwith University of Glasgow: You are welcome to share feedback by emailing Gaby Mahrholz.\nAcknowledgement of previous versions: This version of the book was adapted from a previous version written by Phil McAleer, Carolina E. Kuepper-Tetzel, & Helena M. Paterson\nR Version: This book has been written with R version 4.5.1 (2025-06-13 ucrt) (Great Square Root) and RStudio version 2024.12.1+563 (“Kousa Dogwood”).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "01-basics.html",
    "href": "01-basics.html",
    "title": "1  Projects and R Markdown",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter, you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#intended-learning-outcomes",
    "href": "01-basics.html#intended-learning-outcomes",
    "title": "1  Projects and R Markdown",
    "section": "",
    "text": "Re-familiarise yourself with setting up projects\nRe-familiarise yourself with RMarkdown documents\nRecap and apply data wrangling procedures to analyse data",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#individual-walkthrough",
    "href": "01-basics.html#individual-walkthrough",
    "title": "1  Projects and R Markdown",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#r-and-r-studio",
    "href": "01-basics.html#r-and-r-studio",
    "title": "1  Projects and R Markdown",
    "section": "1.1 R and R Studio",
    "text": "1.1 R and R Studio\nRemember, R is a programming language that you will write code in and RStudio is an Integrated Development Environment (IDE) which makes working with R easier as it’s more user friendly. You need both components for this course.\nIf this is not ringing any bells yet, have a quick browse through the materials from year 1 to refresh your memory.\n\n1.1.1 R server\nUse the server only if you are unable to install R and RStudio on your computer (e.g., if you are using a Chromebook) or if you encounter issues while installing R on your own machine. Otherwise, you should install R and RStudio directly on your own computer. R and RStudio are already installed on the R server.\nYou will find the link to the server on Moodle.\n\n\n1.1.2 Installing R and RStudio on your computer\nThe RSetGo book provides detailed instructions on how to install R and RStudio on your computer. It also includes links to walkthroughs for installing R on different types of computers and operating systems.\nIf you had R and RStudio installed on your computer last year, we recommend updating to the latest versions. In fact, it’s a good practice to update them at the start of each academic year. Detailed guidance can be found in Appendix B.\nOnce you have installed or updated R and RStudio, return to this chapter.\n\n\n1.1.3 Settings for Reproducibility\nBy now, you should be aware that the Psychology department at the University of Glasgow places a strong emphasis on reproducibility, open science, and raising awareness about questionable research practices (QRPs) and how to avoid them. Therefore, it’s important that you work in a reproducible manner so that others (and your future self) can understand and check your work. This also makes it easier for you to reuse your work in the future.\nAlways start with a clear workspace. If your Global Environment contains anything from a previous session, you can’t be certain whether your current code is working as intended or if it’s using objects created earlier.\nTo ensure a clean and reproducible workflow, there are a few settings you should adjust immediately after installing or updating RStudio. In Tools &gt; Global Options… General tab\n\nUncheck the box labelled Restore .RData into workspace at startup to make sure no data from a previous session is loaded into the environment\nset Save workspace to .RData on exit to Never to prevent your workspace from being saved when you exit RStudio.\n\n\n\n\nReproducibility settings in Global Options\n\n\n\n\n\n\n\n\nTip for keeping taps on parentheses\n\n\n\n\n\nR has included rainbow parentheses to help with keeping count on the brackets.\nTo enable the feature, go to Tools &gt; Global Options… Code tab &gt; Display tab and tick the last checkbox “Use rainbow parentheses”\n\n\n\nEnable Rainbow parenthesis\n\n\n\n\n\n\n\n1.1.4 RStudio panes\nRStudio has four main panes each in a quadrant of your screen:\n\nSource pane\nEnvironment pane\nConsole pane\nOutput pane\n\n\n\n\n\n\n\nYour Turn\n\n\n\nAre you ready for a quick quiz to see what you remember about the RStudio panes from last year? Click on Quiz to see the questions.\n\n\n\n\n\n\nQuiz\n\n\n\n\n\nWhat is their purpose?\nThe Source pane…\n\n allows users to view and edit various code-related files, such as .Rmd files contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function provides an area to interactively execute code\n\nThe Environment pane…\n\n allows users to view and edit various code-related files, such as .Rmd files contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function provides an area to interactively execute code\n\nThe Console pane…\n\n allows users to view and edit various code-related files, such as .Rmd files contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function provides an area to interactively execute code\n\nThe Output pane…\n\n allows users to view and edit various code-related files, such as .Rmd files contains the Files, Plots, R Packages, Help, Tutorial, Viewer, and Presentation tabs includes the Environment tab that displays currently saved objects, and the History tab that displays the commands that were executed in the current session along a search function provides an area to interactively execute code\n\nWhere are these panes located by default?\n\nThe Source pane is located? top leftbottom lefttop rightbottom right\nThe Environment pane is located? bottom rightbottom lefttop righttop left\nThe Console pane is located? bottom leftbottom righttop lefttop right\nThe Output pane is located? bottom righttop righttop leftbottom left\n\n\n\n\n\n\nIf you were not quite sure about one/any of the panes, check out the materials from Level 1. If you want to know more about them, there is the RStudio guide on posit",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-project",
    "href": "01-basics.html#sec-project",
    "title": "1  Projects and R Markdown",
    "section": "1.2 Activity 1: Creating a new project",
    "text": "1.2 Activity 1: Creating a new project\nIt’s important to create a new RStudio project whenever you start a new project. This practice makes it easier to work in multiple contexts, such as when analysing different datasets simultaneously. Each RStudio project has its own folder location, workspace, and working directories, which keeps all your data and RMarkdown documents organised in one place.\nLast year, you learnt how to create projects on the server, so you already know the steps. If cannot quite recall how that was done, go back to the Level 1 materials.\nOn your own computer, open RStudio, and complete the following steps in this order:\n\nClick on File &gt; New Project…\nThen, click on “New Directory”\nThen, click on “New Project”\nName the directory something meaningful (e.g., “2A_chapter1”), and save it in a location that makes sense, for example, a dedicated folder you have for your level 2 Psychology labs - you can either select a folder you have already in place or create a new one (e.g., I named my new folder “Level 2 labs”)\nClick “Create Project”. RStudio will restart itself and open with this new project directory as the working directory. If you accidentally close it, you can open it by double-clicking on the project icon in your folder\nYou can also check in your folder structure that everything was created as intended\n\n\n\n\nCreating a new project\n\n\n\n\n\n\n\n\nWhy is the Colour scheme in the gif different to my version?\n\n\n\n\n\nIn case anyone is wondering why my colour scheme in the gif above looks different to yours, I’ve set mine to “Pastel On Dark” in Tools &gt; Global Options… &gt; Appearances. And my computer lives in “dark mode”.\n\n\n\n\n\n\n\n\n\nDon’t nest projects\n\n\n\nDon’t ever save a new project inside another project directory. This can cause some hard-to-resolve problems.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-rmd",
    "href": "01-basics.html#sec-rmd",
    "title": "1  Projects and R Markdown",
    "section": "1.3 Activity 2: Create a new R Markdown file",
    "text": "1.3 Activity 2: Create a new R Markdown file\n\nOpen a new R Markdown document: click File &gt; New File &gt; R Markdown or click on the little page icon with a green plus sign (top left).\nGive it a meaningful Title (e.g., Level 2 chapter 1) - you can also change the title later. Feel free to add your name or GUID in the Author field author name. Keep the Default Output Format as HTML.\nOnce the .Rmd opened, you need to save the file.\nTo save it, click File &gt; Save As… or click on the little disc icon. Name it something meaningful (e.g., “chapter_01.Rmd”, “01_intro.Rmd”). Make sure there are no spaces in the name - R is not very fond of spaces… This file will automatically be saved in your project folder (i.e., your working directory) so you should now see this file appear in your file viewer pane.\n\n\n\n\nCreating a new .Rmd file\n\n\nRemember, an R Markdown document or .Rmd has “white space” (i.e., the markdown for formatted text) and “grey parts” (i.e., code chunks) in the default colour scheme (see Figure 1.1). R Markdown is a powerful tool for creating dynamic documents because it allows you to integrate code and regular text seamlessly. You can then knit your .Rmd using the knitr package to create a final document as either a webpage (HTML), a PDF, or a Word document (.docx). We’ll only knit to HTML documents in this course.\n\n\n\nR markdown anatomy (image from https://intro2r.com/r-markdown-anatomy.html)\n\n\n\n1.3.1 Markdown\nThe markdown space in an .Rmd is ideal for writing notes that explain your code and document your thought process. Use this space to clarify what your code is doing, why certain decisions were made, and any insights or conclusions you have drawn along the way. These notes are invaluable when revisiting your work later, helping you (or others) understand the rationale behind key decisions, such as setting inclusion/exclusion criteria or interpreting the results of assumption tests. Effectively documenting your work in the markdown space enhances both the clarity and reproducibility of your analysis.\nThe markdown space offers a variety of formatting options to help you organise and present your notes effectively. Here are a few of them that can enhance your documentation:\n\nHeading levels\nThere is a variety of heading levels to make use of, using the # symbol.\n\n\n\nYou would incorporate this into your text as:\n# Heading level 1\n## Heading level 2\n### Heading level 3\n#### Heading level 4\n##### Heading level 5\n###### Heading level 6\n\n\n\nAnd it will be displayed in your knitted html file as:\n\n\n\n\n\n\n\n\n\n\nERROR: My heading levels don’t render properly when knitting\n\n\n\n\n\nYou need a space between the # and the first letter. If the space is missing, the heading will be displayed in the HTML file as …\n#Heading 1\n\n\n\n\n\nUnordered and ordered lists\nYou can also include unordered lists and ordered lists. Click on the tabs below to see how they are incorporated\n\nunordered listsordered listsordered lists magic\n\n\nYou can add bullet points using either *, - or + and they will turn into:\n\nbullet point (created with *)\nbullet point (created with -)\nbullet point (created with +)\n\nor use bullet points of different levels using 1 tab key press or 2 spaces (for sub-item 1) or 2 tabs/4 spaces (for sub-sub-item 1):\n\nbullet point item 1\n\nsub-item 1\n\nsub-sub-item 1\nsub-sub-item 2\n\n\nbullet point item 2\n\n\n\n\n\n\n\nERROR: My bullet points don’t render properly when knitting\n\n\n\n\n\nYou need an empty row before your bullet points start. If I delete the empty row before the bullet points, they will be displayed in the HTML as …\nText without the empty row: * bullet point created with * - bullet point created with - + bullet point created with +\n\n\n\n\n\nStart the line with 1., 2., etc. When you want to include sub-items, either use the tab key twice or add 4 spaces. Same goes for the sub-sub-item: include either 2 tabs (or 4 manual spaces) from the last item or 4 tabs/ 8 spaces from the start of the line.\n\nlist item 1\nlist item 2\n\nsub-item 1 (with 4 spaces) A. sub-sub-item 1 (with an additional 4 spaces from the last indent)\n\n\n\n\n\n\n\n\nMy list items don’t render properly when knitting\n\n\n\n\n\nIf you don’t leave enough spaces, the list won’t be recognised, and your output looks like this:\n\nlist item 3\n\n\nsub-item 1 (with only 2 spaces) A. sub-sub-item 1 (with an additional 2 spaces from the last indent)\n\n\n\n\n\n\nThe great thing though is that you don’t need to know your alphabet or number sequences. R markdown will fix that for you\nIf I type into my .Rmd…\n\n…it will be rendered in the knitted HTML output as…\n\nlist item 3\nlist item 1\n\nsub-item labelled “a)”\nsub-item labelled “i)”\n\nsub-item labelled “C)”\nsub-item labelled “Z)”\n\n\nlist item 7\n\n\n\n\n\n\n\nERROR: The labels of the sub-items are not what I thought they would be. You said they are fixing themselves…\n\n\n\n\n\nYes, they do but you need to label your sub-item lists accordingly. The first label you list in each level is set as the baseline. If they are labelled 1) instead of i) or A., the output will show as follows, but the automatic-item-fixing still works:\n\nlist item 7\n\nlist item “1)” with 4 spaces\n\nlist item “1)” with 8 spaces\nthis is an item labelled “6)” (magically corrected to “2.”)\n\n\n\n\n\n\n\n\n\n\n\nEmphasis\nInclude emphasis to draw attention to keywords in your text:\n\n\n\nR markdown syntax\nDisplayed in the knitted HTML file\n\n\n\n\n**bold text**\nbold text\n\n\n*italic text*\nitalic text\n\n\n***bold and italic***\nbold and italic\n\n\n\nOther examples can be found in the R Markdown Cheat Sheet\n\n\n\n1.3.2 Code chunks\nEverything you write inside the code chunks will be interpreted as code and executed by R. Code chunks start with ``` followed by an {r} which specifies the coding language R, some space for code, and ends with ```. If you accidentally delete one of those backticks, your code won’t run and/or your text parts will be interpreted as part of the code chunks or vice versa. This should be evident from the colour change - more white than expected typically indicates missing starting backticks, whilst too much grey/not enough white suggests missing ending backticks. But no need to fret if that happens - just add the missing backticks manually.\nYou can insert a new code chunk in several ways:\n\nClick the Insert a new code chunk button in the RStudio Toolbar (green icon at the top right corner of the Source pane).\nSelect Code &gt; Insert Chunk from the menu.\nUsing the shortcut Ctrl + Alt + I for Windows or Cmd + Option + I on MacOSX.\nType ```{r} and ``` manually\n\n\n\n\n\n\n\n\n\nFigure 1.1: Default .Rmd with highlighting - names in pink and knitr display options in purple\n\n\n\n\n\nWithin the curly brackets of a code chunk, you can specify a name for the code chunk (see pink highlighting in Figure 1.1). The chunk name is not necessarily required; however, it is good practice to give each chunk a unique name to support more advanced knitting approaches. It also makes it easier to reference and manage chunks.\nWithin the curly brackets, you can also place rules and arguments (see purple highlighting in Figure 1.1) to control how your code is executed and what is displayed in your final HTML output. The most common knitr display options include:\n\n\n\n\n\n\n\n\n\nCode\nDoes code run\nDoes code show\nDo results show\n\n\n\n\neval=FALSE\nNO\nYES\nNO\n\n\necho=TRUE (default)\nYES\nYES\nYES\n\n\necho=FALSE\nYES\nNO\nYES\n\n\nresults=‘hide’\nYES\nYES\nNO\n\n\ninclude=FALSE\nYES\nNO\nNO\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe table above will be incredibly important for the data skills homework II. When solving error mode items you will need to pay attention to the first one eval = FALSE.\n\n\nOne last thing: In your newly created .Rmd file, delete everything below line 12 (keep the set-up code chunk) and save your .Rmd by clicking on the disc symbol.\n\n\n\nDelete everything below line 12\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nThat was quite a long section about what Markdown can do. I promise, we’ll practice that more later. For the minute, we want you to create a new level 2 heading on line 12 and give it a meaningful heading title (something like “Loading packages and reading in data” or “Chapter 1”).\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOn line 12, you should have typed ## Loading packages and reading in data (or whatever meaningful title you chose). This will create level 2 heading once we knit the .Rmd.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-download_data_ch1",
    "href": "01-basics.html#sec-download_data_ch1",
    "title": "1  Projects and R Markdown",
    "section": "1.4 Activity 3: Download the data",
    "text": "1.4 Activity 3: Download the data\nThe data for chapters 1-3. Download it here: data_ch1.zip. There are 2 csv files contained in a zip folder. One is the data file we are going to use today prp_data_reduced.csv and the other is an Excel file prp_codebook that explains the variables in the data.\nThe first step is to unzip the zip folder so that the files are placed within the same folder as your project.\n\nPlace the zip folder within your 2A_chapter1 folder\nRight mouse click –&gt; Extract All...\nCheck the folder location is the one to extract the files to\nCheck the extracted files are placed next to the project icon\nFiles and project should be visible in the Output pane in RStudio\n\n\n\n\n\n\n\nScreenshots for “unzipping a zip folder”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnzipping a zip folder\n\n\n\n\n\n\nThe paper by Pownall et al. was a registered report published in 2023, and the original data can be found on OSF (https://osf.io/5qshg/).\nCitation\n\nPownall, M., Pennington, C. R., Norris, E., Juanchich, M., Smailes, D., Russell, S., Gooch, D., Evans, T. R., Persson, S., Mak, M. H. C., Tzavella, L., Monk, R., Gough, T., Benwell, C. S. Y., Elsherif, M., Farran, E., Gallagher-Mitchell, T., Kendrick, L. T., Bahnmueller, J., . . . Clark, K. (2023). Evaluating the Pedagogical Effectiveness of Study Preregistration in the Undergraduate Dissertation. Advances in Methods and Practices in Psychological Science, 6(4). https://doi.org/10.1177/25152459231202724\n\nAbstract\n\nResearch shows that questionable research practices (QRPs) are present in undergraduate final-year dissertation projects. One entry-level Open Science practice proposed to mitigate QRPs is “study preregistration,” through which researchers outline their research questions, design, method, and analysis plans before data collection and/or analysis. In this study, we aimed to empirically test the effectiveness of preregistration as a pedagogic tool in undergraduate dissertations using a quasi-experimental design. A total of 89 UK psychology students were recruited, including students who preregistered their empirical quantitative dissertation (n = 52; experimental group) and students who did not (n = 37; control group). Attitudes toward statistics, acceptance of QRPs, and perceived understanding of Open Science were measured both before and after dissertation completion. Exploratory measures included capability, opportunity, and motivation to engage with preregistration, measured at Time 1 only. This study was conducted as a Registered Report; Stage 1 protocol: https://osf.io/9hjbw (date of in-principle acceptance: September 21, 2021). Study preregistration did not significantly affect attitudes toward statistics or acceptance of QRPs. However, students who preregistered reported greater perceived understanding of Open Science concepts from Time 1 to Time 2 compared with students who did not preregister. Exploratory analyses indicated that students who preregistered reported significantly greater capability, opportunity, and motivation to preregister. Qualitative responses revealed that preregistration was perceived to improve clarity and organization of the dissertation, prevent QRPs, and promote rigor. Disadvantages and barriers included time, perceived rigidity, and need for training. These results contribute to discussions surrounding embedding Open Science principles into research training.\n\nChanges made to the dataset\nWe made some changes to the dataset for the purpose of increasing difficulty for data wrangling (Chapter 2 and Chapter 3) and data visualisation (Chapter 4 and Chapter 5). This will ensure some “teachable moments”. The changes are as follows:\n\nWe removed some of the variables to make the data more manageable for teaching purposes.\nWe recoded some values from numeric responses to labels (e.g., understanding).\nWe added the word “years” to one of the Age entries.\nWe tidied a messy column Ethnicity but introduced a similar but easier-to-solve “messiness pattern” when recoding the understanding data.\nThe scores in the original file were already corrected from reverse-coded responses. We reversed that process to present raw data here.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#activity-4-installing-packages-loading-packages-and-reading-in-data",
    "href": "01-basics.html#activity-4-installing-packages-loading-packages-and-reading-in-data",
    "title": "1  Projects and R Markdown",
    "section": "1.5 Activity 4: Installing packages, loading packages, and reading in data",
    "text": "1.5 Activity 4: Installing packages, loading packages, and reading in data\n\n1.5.1 Installing packages\nWhen you install R and RStudio for the first time (or after an update), most of the packages we will be using won’t be pre-installed. Before you can load new packages like tidyverse, you will need to install them.\nIf you try to load a package that has not been installed yet, you will receive an error message that looks something like this: Error in library(tidyverse) : there is no package called 'tidyverse'.\nTo fix this, simply install the package first. In the console, type the command install.packages(\"tidyverse\"). This only needs to be done once after a fresh installation. After that, you will be able to load the tidyverse package into your library whenever you open RStudio.\n\n\n\n\n\n\nInstall packages from the console only\n\n\n\nNever include install.packages() in the Rmd. Only install packages from the console pane or the packages tab of the lower right pane!!!\n\n\nNote, there will be other packages used in later chapters that will also need to be installed before their first use, so this error is not limited to tidyverse.\n\n\n1.5.2 Loading packages and reading in data\nThe first step is to load in the packages we need and read in the data. Today, we’ll only be using tidyverse, and read_csv() will help us store the data from prp_data_reduced.csv in an object called data_prp.\nCopy the code into a code chunk in your .Rmd file and run it. You can either click the green error to run the entire code chunk, or use the shortcut Ctrl + Enter (Windows) or Cmd + Enter (Mac) to run a line of code/ pipe from the Rmd.\n\nlibrary(tidyverse)\ndata_prp &lt;- read_csv(\"prp_data_reduced.csv\")\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRows: 89 Columns: 91\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (17): Code, Age, Ethnicity, Opptional_mod_1_TEXT, Research_exp_1_TEXT, U...\ndbl (74): Gender, Secondyeargrade, Opptional_mod, Research_exp, Plan_prereg,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#sec-familiarise",
    "href": "01-basics.html#sec-familiarise",
    "title": "1  Projects and R Markdown",
    "section": "1.6 Activity 5: Familiarise yourself with the data",
    "text": "1.6 Activity 5: Familiarise yourself with the data\n\nLook at the Codebook to get a feel of the variables in the dataset and how they have been measured. Note that some of the columns were deleted in the dataset you have been given.\nYou’ll notice that some questionnaire data was collected at 2 different time points (i.e., SATS28, QRPs, Understanding_OS)\nsome of the data was only collected at one time point (i.e., supervisor judgements, OS_behav items, and Included_prereg variables are t2-only variables)\n\n\n1.6.1 First glimpse at the data\nBefore you start wrangling your data, it is important to understand what kind of data you’re working with and what the format of your dataframe looks like.\nAs you may have noticed, read_csv() provides a message listing the data types in your dataset and how many columns are of each type. Plus, it shows a few examples columns for each data type.\nTo obtain more detailed information about your data, you have several options. Click on the individual tabs to see the different options available. Test them out in your own .Rmd file and use whichever method you prefer (but do it).\n\n\n\n\n\n\nWarning\n\n\n\nSome of the output is a bit long because we do have quite a few variables in the data file.\n\n\n\nvisual inspection 1glimpse()spec()visual inspection 2\n\n\nIn the Global Environment, click the blue arrow icon next to the object name data_prp. This action will expand the object, revealing details about its columns. The $ symbol is commonly used in Base R to access a specific column within your dataframe.\n\n\n\nVisual inspection of the data\n\n\nCon: When you have quite a few variables, not all of them are shown.\n\n\nUse glimpse() if you want a more detailed overview you can see on your screen. The output will display rows and column numbers, and some examples of the first couple of observations for each variable.\n\nglimpse(data_prp)\n\nRows: 89\nColumns: 91\n$ Code                                  &lt;chr&gt; \"Tr10\", \"Bi07\", \"SK03\", \"SM95\", …\n$ Gender                                &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2,…\n$ Age                                   &lt;chr&gt; \"22\", \"20\", \"22\", \"26\", \"22\", \"2…\n$ Ethnicity                             &lt;chr&gt; \"White European\", \"White British…\n$ Secondyeargrade                       &lt;dbl&gt; 2, 3, 1, 2, 2, 2, 2, 2, 1, 1, 1,…\n$ Opptional_mod                         &lt;dbl&gt; 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,…\n$ Opptional_mod_1_TEXT                  &lt;chr&gt; \"Research methods in first year\"…\n$ Research_exp                          &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ Research_exp_1_TEXT                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Plan_prereg                           &lt;dbl&gt; 1, 3, 1, 2, 1, 1, 3, 3, 2, 2, 2,…\n$ SATS28_1_Affect_Time1                 &lt;dbl&gt; 4, 5, 5, 6, 2, 1, 6, 3, 2, 5, 2,…\n$ SATS28_2_Affect_Time1                 &lt;dbl&gt; 5, 6, 3, 3, 6, 1, 2, 2, 7, 3, 4,…\n$ SATS28_3_Affect_Time1                 &lt;dbl&gt; 3, 2, 5, 2, 6, 7, 2, 6, 6, 5, 2,…\n$ SATS28_4_Affect_Time1                 &lt;dbl&gt; 4, 5, 2, 2, 6, 6, 5, 5, 5, 5, 2,…\n$ SATS28_5_Affect_Time1                 &lt;dbl&gt; 5, 5, 5, 6, 1, 1, 5, 1, 2, 5, 2,…\n$ SATS28_6_Affect_Time1                 &lt;dbl&gt; 5, 6, 2, 5, 6, 7, 4, 5, 5, 3, 5,…\n$ SATS28_7_CognitiveCompetence_Time1    &lt;dbl&gt; 4, 2, 2, 5, 6, 7, 2, 5, 5, 2, 2,…\n$ SATS28_8_CognitiveCompetence_Time1    &lt;dbl&gt; 2, 2, 2, 1, 6, 7, 2, 5, 3, 2, 3,…\n$ SATS28_9_CognitiveCompetence_Time1    &lt;dbl&gt; 2, 2, 2, 3, 3, 7, 2, 6, 3, 3, 1,…\n$ SATS28_10_CognitiveCompetence_Time1   &lt;dbl&gt; 6, 7, 6, 6, 4, 2, 6, 4, 5, 6, 5,…\n$ SATS28_11_CognitiveCompetence_Time1   &lt;dbl&gt; 4, 3, 5, 5, 3, 1, 6, 2, 5, 6, 5,…\n$ SATS28_12_CognitiveCompetence_Time1   &lt;dbl&gt; 3, 5, 3, 5, 5, 7, 3, 4, 7, 2, 3,…\n$ SATS28_13_Value_Time1                 &lt;dbl&gt; 1, 1, 2, 1, 3, 7, 1, 2, 1, 2, 4,…\n$ SATS28_14_Value_Time1                 &lt;dbl&gt; 7, 7, 6, 6, 5, 1, 6, 5, 7, 6, 2,…\n$ SATS28_15_Value_Time1                 &lt;dbl&gt; 7, 7, 6, 6, 3, 5, 6, 6, 6, 5, 5,…\n$ SATS28_16_Value_Time1                 &lt;dbl&gt; 2, 1, 3, 2, 6, 5, 3, 7, 2, 2, 2,…\n$ SATS28_17_Value_Time1                 &lt;dbl&gt; 1, 1, 3, 3, 7, 7, 2, 7, 2, 2, 5,…\n$ SATS28_18_Value_Time1                 &lt;dbl&gt; 3, 6, 5, 3, 1, 1, 5, 1, 5, 2, 2,…\n$ SATS28_19_Value_Time1                 &lt;dbl&gt; 3, 3, 3, 3, 7, 7, 4, 5, 3, 5, 6,…\n$ SATS28_20_Value_Time1                 &lt;dbl&gt; 2, 1, 4, 2, 7, 7, 2, 4, 2, 2, 7,…\n$ SATS28_21_Value_Time1                 &lt;dbl&gt; 2, 1, 3, 2, 6, 7, 2, 5, 1, 3, 5,…\n$ SATS28_22_Difficulty_Time1            &lt;dbl&gt; 3, 2, 5, 3, 2, 1, 4, 2, 2, 5, 3,…\n$ SATS28_23_Difficulty_Time1            &lt;dbl&gt; 5, 6, 5, 6, 6, 7, 4, 6, 7, 5, 6,…\n$ SATS28_24_Difficulty_Time1            &lt;dbl&gt; 2, 2, 2, 3, 1, 4, 4, 2, 2, 2, 2,…\n$ SATS28_25_Difficulty_Time1            &lt;dbl&gt; 6, 7, 5, 5, 6, 7, 5, 6, 5, 5, 5,…\n$ SATS28_26_Difficulty_Time1            &lt;dbl&gt; 4, 2, 2, 2, 6, 7, 4, 5, 3, 5, 3,…\n$ SATS28_27_Difficulty_Time1            &lt;dbl&gt; 4, 5, 5, 3, 6, 7, 4, 3, 5, 3, 6,…\n$ SATS28_28_Difficulty_Time1            &lt;dbl&gt; 1, 7, 5, 5, 6, 6, 5, 4, 4, 4, 2,…\n$ QRPs_1_Time1                          &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 6, 2, 7, 6, 7,…\n$ QRPs_2_Time1                          &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 6, 7, 7, 7, 5,…\n$ QRPs_3_Time1                          &lt;dbl&gt; 5, 2, 6, 2, 6, 4, 6, 3, 7, 3, 3,…\n$ QRPs_4_Time1                          &lt;dbl&gt; 7, 7, 6, 6, 7, 4, 6, 7, 7, 7, 6,…\n$ QRPs_5_Time1                          &lt;dbl&gt; 3, 3, 7, 7, 2, 7, 4, 6, 7, 3, 2,…\n$ QRPs_6_Time1                          &lt;dbl&gt; 4, 7, 6, 5, 7, 4, 4, 5, 7, 6, 5,…\n$ QRPs_7_Time1                          &lt;dbl&gt; 5, 7, 7, 7, 7, 4, 5, 6, 7, 7, 5,…\n$ QRPs_8_Time1                          &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 2, 7,…\n$ QRPs_9_Time1                          &lt;dbl&gt; 6, 7, 7, 4, 7, 7, 3, 7, 6, 6, 2,…\n$ QRPs_10_Time1                         &lt;dbl&gt; 7, 6, 5, 2, 5, 4, 2, 6, 7, 7, 2,…\n$ QRPs_11_Time1                         &lt;dbl&gt; 7, 7, 7, 4, 7, 7, 4, 6, 7, 7, 5,…\n$ QRPs_12NotQRP_Time1                   &lt;dbl&gt; 2, 2, 1, 4, 1, 4, 2, 4, 2, 2, 1,…\n$ QRPs_13NotQRP_Time1                   &lt;dbl&gt; 1, 1, 1, 1, 1, 4, 2, 4, 1, 1, 1,…\n$ QRPs_14NotQRP_Time1                   &lt;dbl&gt; 1, 4, 3, 4, 1, 4, 2, 3, 3, 4, 3,…\n$ QRPs_15NotQRP_Time1                   &lt;dbl&gt; 2, 4, 2, 2, 1, 4, 2, 1, 4, 4, 2,…\n$ Understanding_OS_1_Time1              &lt;chr&gt; \"2\", \"2\", \"6\", \"2\", \"6\", \"Not at…\n$ Understanding_OS_2_Time1              &lt;chr&gt; \"2\", \"Not at all confident\", \"2\"…\n$ Understanding_OS_3_Time1              &lt;chr&gt; \"2\", \"Not at all confident\", \"3\"…\n$ Understanding_OS_4_Time1              &lt;chr&gt; \"6\", \"Not at all confident\", \"6\"…\n$ Understanding_OS_5_Time1              &lt;chr&gt; \"Entirely confident\", \"6\", \"6\", …\n$ Understanding_OS_6_Time1              &lt;chr&gt; \"Entirely confident\", \"Entirely …\n$ Understanding_OS_7_Time1              &lt;chr&gt; \"6\", \"Not at all confident\", \"2\"…\n$ Understanding_OS_8_Time1              &lt;chr&gt; \"6\", \"3\", \"5\", \"3\", \"5\", \"Not at…\n$ Understanding_OS_9_Time1              &lt;chr&gt; \"Entirely confident\", \"6\", \"5\", …\n$ Understanding_OS_10_Time1             &lt;chr&gt; \"Entirely confident\", \"6\", \"5\", …\n$ Understanding_OS_11_Time1             &lt;chr&gt; \"Entirely confident\", \"2\", \"4\", …\n$ Understanding_OS_12_Time1             &lt;chr&gt; \"Entirely confident\", \"2\", \"5\", …\n$ Pre_reg_group                         &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2,…\n$ Other_OS_behav_2                      &lt;dbl&gt; 1, NA, NA, NA, 1, NA, NA, 1, NA,…\n$ Other_OS_behav_4                      &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, NA, N…\n$ Other_OS_behav_5                      &lt;dbl&gt; NA, NA, NA, NA, 1, 1, NA, NA, NA…\n$ Closely_follow                        &lt;dbl&gt; 2, 2, 2, NA, 3, 3, 3, NA, NA, 2,…\n$ SATS28_Affect_Time2_mean              &lt;dbl&gt; 3.500000, 3.166667, 4.833333, 4.…\n$ SATS28_CognitiveCompetence_Time2_mean &lt;dbl&gt; 4.166667, 4.666667, 6.166667, 5.…\n$ SATS28_Value_Time2_mean               &lt;dbl&gt; 3.000000, 6.222222, 6.000000, 4.…\n$ SATS28_Difficulty_Time2_mean          &lt;dbl&gt; 2.857143, 2.857143, 4.000000, 2.…\n$ QRPs_Acceptance_Time2_mean            &lt;dbl&gt; 5.636364, 5.454545, 6.272727, 5.…\n$ Time2_Understanding_OS                &lt;dbl&gt; 5.583333, 3.333333, 5.416667, 4.…\n$ Supervisor_1                          &lt;dbl&gt; 5, 7, 7, 1, 7, 1, 7, 6, 7, 5, 6,…\n$ Supervisor_2                          &lt;dbl&gt; 5, 6, 7, 4, 6, 2, 7, 5, 6, 5, 5,…\n$ Supervisor_3                          &lt;dbl&gt; 6, 7, 7, 1, 7, 1, 7, 5, 6, 6, 7,…\n$ Supervisor_4                          &lt;dbl&gt; 6, 7, 7, 1, 7, 1, 7, 6, 7, 6, 6,…\n$ Supervisor_5                          &lt;dbl&gt; 5, 7, 7, 4, 7, 3, 7, 7, 6, 6, 6,…\n$ Supervisor_6                          &lt;dbl&gt; 5, 7, 7, 4, 6, 3, 7, 6, 7, 6, 6,…\n$ Supervisor_7                          &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Supervisor_8                          &lt;dbl&gt; 5, 5, 7, 1, 7, 1, 7, 5, 7, 5, 6,…\n$ Supervisor_9                          &lt;dbl&gt; 6, 7, 7, 4, 7, 3, 7, 5, 7, 6, 7,…\n$ Supervisor_10                         &lt;dbl&gt; 5, 7, 7, 1, 7, 1, 7, 6, 7, 6, 6,…\n$ Supervisor_11                         &lt;dbl&gt; NA, 7, 7, NA, 7, 1, 7, 5, 7, 6, …\n$ Supervisor_12                         &lt;dbl&gt; 4, 5, 7, 1, 4, 1, 7, 3, 6, 6, 5,…\n$ Supervisor_13                         &lt;dbl&gt; 4, 2, 5, 1, 2, 1, 6, 3, 5, 6, 5,…\n$ Supervisor_14                         &lt;dbl&gt; 5, 7, 7, 1, 7, 1, 7, 5, 7, 6, 6,…\n$ Supervisor_15_R                       &lt;dbl&gt; 1, 1, 1, 4, 1, 7, 1, 2, 1, 2, 1,…\n\n\n\n\nYou can also use spec() as suggested in the message above and then it shows you a list of the data type in every single column. But it doesn’t show you the number of rows and columns.\n\nspec(data_prp)\n\ncols(\n  Code = col_character(),\n  Gender = col_double(),\n  Age = col_character(),\n  Ethnicity = col_character(),\n  Secondyeargrade = col_double(),\n  Opptional_mod = col_double(),\n  Opptional_mod_1_TEXT = col_character(),\n  Research_exp = col_double(),\n  Research_exp_1_TEXT = col_character(),\n  Plan_prereg = col_double(),\n  SATS28_1_Affect_Time1 = col_double(),\n  SATS28_2_Affect_Time1 = col_double(),\n  SATS28_3_Affect_Time1 = col_double(),\n  SATS28_4_Affect_Time1 = col_double(),\n  SATS28_5_Affect_Time1 = col_double(),\n  SATS28_6_Affect_Time1 = col_double(),\n  SATS28_7_CognitiveCompetence_Time1 = col_double(),\n  SATS28_8_CognitiveCompetence_Time1 = col_double(),\n  SATS28_9_CognitiveCompetence_Time1 = col_double(),\n  SATS28_10_CognitiveCompetence_Time1 = col_double(),\n  SATS28_11_CognitiveCompetence_Time1 = col_double(),\n  SATS28_12_CognitiveCompetence_Time1 = col_double(),\n  SATS28_13_Value_Time1 = col_double(),\n  SATS28_14_Value_Time1 = col_double(),\n  SATS28_15_Value_Time1 = col_double(),\n  SATS28_16_Value_Time1 = col_double(),\n  SATS28_17_Value_Time1 = col_double(),\n  SATS28_18_Value_Time1 = col_double(),\n  SATS28_19_Value_Time1 = col_double(),\n  SATS28_20_Value_Time1 = col_double(),\n  SATS28_21_Value_Time1 = col_double(),\n  SATS28_22_Difficulty_Time1 = col_double(),\n  SATS28_23_Difficulty_Time1 = col_double(),\n  SATS28_24_Difficulty_Time1 = col_double(),\n  SATS28_25_Difficulty_Time1 = col_double(),\n  SATS28_26_Difficulty_Time1 = col_double(),\n  SATS28_27_Difficulty_Time1 = col_double(),\n  SATS28_28_Difficulty_Time1 = col_double(),\n  QRPs_1_Time1 = col_double(),\n  QRPs_2_Time1 = col_double(),\n  QRPs_3_Time1 = col_double(),\n  QRPs_4_Time1 = col_double(),\n  QRPs_5_Time1 = col_double(),\n  QRPs_6_Time1 = col_double(),\n  QRPs_7_Time1 = col_double(),\n  QRPs_8_Time1 = col_double(),\n  QRPs_9_Time1 = col_double(),\n  QRPs_10_Time1 = col_double(),\n  QRPs_11_Time1 = col_double(),\n  QRPs_12NotQRP_Time1 = col_double(),\n  QRPs_13NotQRP_Time1 = col_double(),\n  QRPs_14NotQRP_Time1 = col_double(),\n  QRPs_15NotQRP_Time1 = col_double(),\n  Understanding_OS_1_Time1 = col_character(),\n  Understanding_OS_2_Time1 = col_character(),\n  Understanding_OS_3_Time1 = col_character(),\n  Understanding_OS_4_Time1 = col_character(),\n  Understanding_OS_5_Time1 = col_character(),\n  Understanding_OS_6_Time1 = col_character(),\n  Understanding_OS_7_Time1 = col_character(),\n  Understanding_OS_8_Time1 = col_character(),\n  Understanding_OS_9_Time1 = col_character(),\n  Understanding_OS_10_Time1 = col_character(),\n  Understanding_OS_11_Time1 = col_character(),\n  Understanding_OS_12_Time1 = col_character(),\n  Pre_reg_group = col_double(),\n  Other_OS_behav_2 = col_double(),\n  Other_OS_behav_4 = col_double(),\n  Other_OS_behav_5 = col_double(),\n  Closely_follow = col_double(),\n  SATS28_Affect_Time2_mean = col_double(),\n  SATS28_CognitiveCompetence_Time2_mean = col_double(),\n  SATS28_Value_Time2_mean = col_double(),\n  SATS28_Difficulty_Time2_mean = col_double(),\n  QRPs_Acceptance_Time2_mean = col_double(),\n  Time2_Understanding_OS = col_double(),\n  Supervisor_1 = col_double(),\n  Supervisor_2 = col_double(),\n  Supervisor_3 = col_double(),\n  Supervisor_4 = col_double(),\n  Supervisor_5 = col_double(),\n  Supervisor_6 = col_double(),\n  Supervisor_7 = col_double(),\n  Supervisor_8 = col_double(),\n  Supervisor_9 = col_double(),\n  Supervisor_10 = col_double(),\n  Supervisor_11 = col_double(),\n  Supervisor_12 = col_double(),\n  Supervisor_13 = col_double(),\n  Supervisor_14 = col_double(),\n  Supervisor_15_R = col_double()\n)\n\n\n\n\nIn the Global Environment, click on the object name data_prp. This action will open the data in a new tab. Hovering over the column headings with your mouse will also reveal their data type. However, it seems to be a fairly tedious process when you have loads of columns.\n\n\n\n\n\n\nHang on, where is the rest of my data? Why do I only see 50 columns?\n\n\n\n\n\nOne common source of confusion is not seeing all your columns when you open up a data object as a tab. This is because RStudio shows you a maximum of 50 columns at a time. If you have more than 50 columns, navigate with the arrows to see the remaining columns.\n\n\n\nShowing 50 columns at a time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nNow that you have tested out all the options in your own .Rmd file, you can probably answer the following questions:\n\nHow many observations? \nHow many variables? \nHow many columns are col_character or chr data type? \nHow many columns are col_double or dbl data type? \n\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe visual inspections shows you the number of observations and variables. glimpse() also gives you that information but calls them rows and columns respectively.\nThe data type information actually comes from the output when using the read_csv() function. Did you notice the information on Column specification (see screenshot below)?\n\n\n\nmessage from read_csv() when reading in the data\n\n\nWhilst spec() is quite useful for data type information per individual column, it doesn’t give you the total count of each data type. So it doesn’t really help with answering the questions here - unless you want to count manually from its extremely long output.\n\n\n\nIn your .Rmd, include a new heading level 2 called “Information about the data” (or something equally meaningful) and jot down some notes about data_prp. You could include the citation and/or the abstract, and whatever information you think you should note about this dataset (e.g., any observations from looking at the codebook?). You could also include some notes on the functions used so far and what they do. Try to incorporate some bold, italic or bold and italic emphasis and perhaps a bullet point or two.\n\n\n\n\n\n\nPossible solution\n\n\n\n\n\n## Information about the data\nThe data is from Pownall et al. (2023), and I can find the paper here: https://doi.org/10.1177/25152459231202724.\nI’ve noticed in the prp codebook that the SATS-28 questionnaire has quite a few *reverse-coded items*, and the supervisor support questionnaire also has a reverse-coded item.\nSo far, I think I prefer **glimpse()** to show me some more detail about the data. Specs() is too text-heavy for me which makes it hard to read.\nThings to keep in mind:\n\n**don’t forget to load in tidyverse first!!!**\nalways read in the data with **read_csv**, ***never ever use read.csv***!!!\n\n\n\n\nThe output rendered in a knitted html file\n\n\n\n\n\n\n\n\n\n1.6.2 Data types\nEach variable has a data type, such as numeric (numbers), character (text), and logical (TRUE/FALSE values), or a special class of factor. As you have just seen, our data_prp only has character and numeric columns (so far).\nNumeric data can be double (dbl) or integer (int). Doubles can have decimal places (e.g., 1.1). Integers are the whole numbers (e.g., 1, 2, -1) and are displayed with the suffix L (e.g., 1L). This is not overly important but might leave you less puzzled the next time you see an L after a number.\nCharacters (also called “strings”) is anything written between quotation marks. This is usually text, but in special circumstances, a number can be a character if it placed within quotation marks. This can happen when you are recoding variables. It might not be too obvious at the time, but you won’t be able to calculate anything if the number is a character\n\nExample data typesnumeric computationcharacter computation\n\n\n\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"1\")\n\n[1] \"character\"\n\ntypeof(\"text\")\n\n[1] \"character\"\n\n\n\n\nNo problems here…\n\n1+1\n\n[1] 2\n\n\n\n\nWhen the data type is incorrect, you won’t be able to compute anything, despite your numbers being shown as numeric values in the dataframe. The error message tells you exactly what’s wrong with it, i.e., that you have non-numeric arguments.\n\n\"1\"+\"1\" # ERROR\n\nError in \"1\" + \"1\": non-numeric argument to binary operator\n\n\n\n\n\nLogical data (also sometimes called “Boolean” values) are one of two values: TRUE or FALSE (written in uppercase). They become really important when we use filter() or mutate() with conditional statements such as case_when(). More about those in Chapter 3.\nSome commonly used logical operators:\n\n\n\noperator\ndescription\n\n\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n==\nequal to\n\n\n!=\nnot equal to\n\n\n%in%\nTRUE if any element is in the following vector\n\n\n\nA factor is a specific type of integer or character that lets you assign the order of the categories. This becomes useful when you want to display certain categories in “the correct order” either in a dataframe (see arrange) or when plotting (see Chapter 4/ Chapter 5).\n\n\n1.6.3 Variable types\nYou’ve already encountered them in Level 1 but let’s refresh. Variables can be classified as continuous (numbers) or categorical (labels).\nCategorical variables are properties you can count. They can be nominal, where the categories don’t have an order (e.g., gender) or ordinal (e.g., Likert scales either with numeric values 1-7 or with character labels such as “agree”, “neither agree nor disagree”, “disagree”). Categorical data may also be factors rather than characters.\nContinuous variables are properties you can measure and calculate sums/ means/ etc. They may be rounded to the nearest whole number, but it should make sense to have a value between them. Continuous variables always have a numeric data type (i.e. integer or double).\n\n\n\n\n\n\nWhy is this important you may ask?\n\n\n\nKnowing your variable and data types will help later on when deciding on an appropriate plot (see Chapter 4 and Chapter 5) or which inferential test to run (Chapter 6 to Chapter 13).\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nAs we’ve seen earlier, data_prp only had character and numeric variables which hardly tests your understanding to see if you can identify a variety of data types and variable types. So, for this little quiz, we’ve spiced it up a bit. We’ve selected a few columns, shortened some of the column names, and modified some of the data types. Here you can see the first few rows of the new object data_quiz. You can find the code with explanations at the end of this section.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nAge\nGender\nEthnicity\nSecondyeargrade\nQRP_item\nQRPs_mean\nUnderstanding_item\nQRP_item &gt; 4\n\n\n\n\nTr10\n22\n2\nWhite European\n60-69% (2:1 grade)\n5\n5.636364\n2\nTRUE\n\n\nBi07\n20\n2\nWhite British\n50-59% (2:2 grade)\n2\n5.454546\n2\nFALSE\n\n\nSK03\n22\n2\nWhite British\n≥ 70% (1st class grade)\n6\n6.272727\n6\nTRUE\n\n\nSM95\n26\n2\nWhite British\n60-69% (2:1 grade)\n2\n5.000000\n2\nFALSE\n\n\nSt01\n22\n2\nWhite British\n60-69% (2:1 grade)\n6\n5.545454\n6\nTRUE\n\n\n\n\n\n\n\nglimpse(data_quiz)\n\nRows: 89\nColumns: 9\n$ Code               &lt;chr&gt; \"Tr10\", \"Bi07\", \"SK03\", \"SM95\", \"St01\", \"St10\", \"Wa…\n$ Age                &lt;chr&gt; \"22\", \"20\", \"22\", \"26\", \"22\", \"20\", \"21\", \"21\", \"22…\n$ Gender             &lt;fct&gt; 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ Ethnicity          &lt;chr&gt; \"White European\", \"White British\", \"White British\",…\n$ Secondyeargrade    &lt;fct&gt; 60-69% (2:1 grade), 50-59% (2:2 grade), ≥ 70% (1st …\n$ QRP_item           &lt;dbl&gt; 5, 2, 6, 2, 6, 4, 6, 3, 7, 3, 3, 4, 4, 4, 4, 6, 3, …\n$ QRPs_mean          &lt;dbl&gt; 5.636364, 5.454545, 6.272727, 5.000000, 5.545455, 6…\n$ Understanding_item &lt;chr&gt; \"2\", \"2\", \"6\", \"2\", \"6\", \"Not at all confident\", \"4…\n$ `QRP_item &gt; 4`     &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE,…\n\n\nSelect from the dropdown menu the variable type and their data types for each of the columns.\n\n\n\n\n\n\n\n\nColumn\nVariable type\nData type\n\n\n\n\nAge\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nGender\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nEthinicity\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nSecondyeargrade\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nQRP_item\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nQRPs_mean\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nUnderstanding_item\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nQRP_item &gt; 4\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\n\n\n\n\n\n\n\n\n\nRevealing the mystery code that created data_quiz\n\n\n\n\n\nThe code might look a bit complex for the minute despite the line-by-line explanations below. Come back to it after completing chapter 2.\n\ndata_quiz &lt;- data_prp %&gt;% \n  select(Code, Age, Gender, Ethnicity, Secondyeargrade, QRP_item = QRPs_3_Time1, QRPs_mean = QRPs_Acceptance_Time2_mean, Understanding_item = Understanding_OS_1_Time1) %&gt;% \n  mutate(Gender = factor(Gender),\n         Secondyeargrade = factor(Secondyeargrade,\n                                  levels = c(1, 2, 3, 4, 5),\n                                  labels = c(\"≥ 70% (1st class grade)\", \"60-69% (2:1 grade)\", \"50-59% (2:2 grade)\", \"40-49% (3rd class)\", \"&lt; 40%\")),\n         `QRP_item &gt; 4` = case_when(\n           QRP_item &gt; 4 ~ TRUE, \n           .default = FALSE))\n\nLets go through this line by line:\n\nline 1: creates a new object called data_quiz and it is based on the already existing data object data_prp\nline 2: we are selecting a few variables of interest, such as Code, Age etc. Some of those variables were renamed in the process according to the structure new_name = old_name, for example QRP item 3 at time point 1 got renamed as QRP_item.\n\nline 3: The function mutate() is used to create a new column called Gender that turns the existing column Gender from a numeric value into a factor. R simply overwrites the existing column of the same name. If we had named the new column Gender_factor, we would have been able to retain the original Gender column and Gender_factor would have been added as the last column.\nline 4-6: See how the line starts with an indent which indicates we are still within the mutate() function. You can also see this by counting brackets - in line 3 there are 2 opening brackets but only 1 closes.\n\nSimilar to Gender, we are replacing the “old” Secondyeargrade with the new Secondyeargrade column that is now a factor.\nTurning our variable Secondyeargrade into a factor, spot the difference between this attempt and the one we used for Gender? Here we are using a lot more arguments in that factor function, namely levels and labels. Levels describes the unique values we have for that column, and in labels we want to define how these levels will be shown in the data object. If you don’t add the levels and labels argument, the labels will be the labels (as you can see in the Gender column in which we kept the numbers).\n\nline 7: Doesn’t start with a function name and has an indent, which means we are still within the mutate() function - count the opening and closing brackets to confirm.\n\nHere, we are creating a new column called QRP_item &gt; 4. Notice the two backticks we have to use to make this weird column name work? This is because it has spaces (and we did mention that R doesn’t like spaces). So the backticks help R to group it as a unit/ a single name.\nNext we have a case_when() function which helps executing conditional statements. We are using it to check whether a statement is TRUE or FALSE. Here, we ask whether the QRP item (column QRP_item) is larger than 4 (midpoint of the scale) using the Boolean operator &gt;. If the statement is TRUE, the label TRUE should appear in column QRP_item &gt; 4. Otherwise, if the value is equal to 4 or smaller, the label should read FALSE. We will come back to conditional statements in Chapter 2. But long story short, this Boolean expression created the only logical data type in data_quiz.\n\n\n\n\n\nAnd with this, we are done with the individual walkthrough. Well done :)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "01-basics.html#test-your-knowledge",
    "href": "01-basics.html#test-your-knowledge",
    "title": "1  Projects and R Markdown",
    "section": "Test your knowledge",
    "text": "Test your knowledge\nAre you ready for some knowledge check questions to test your understanding of the chapter? We also have some faulty codes. See if you can spot what’s wrong with them.\n\nKnowledge check\n\nQuestion 1\nOne of the key first steps when we open RStudio is to:\n\n put on some music as we will be here a while open an existing project or create a new one make a coffee check out the news\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nOpening an existing project (e.g., when coming back to the same dataset) or creating a new project (e.g., for a new task or new dataset) ensures that subsequent .Rmd files, any output, figures, etc are saved within the same folder on your computer (i.e., the working directory). If the.Rmd files or data is not in the same folder as “the project icon”, things can get messy and code might not run.\n\n\n\n\n\nQuestion 2\nWhen using the default environment colour settings for RStudio, what colour would the background of a code chunk be in R Markdown? redwhitegreengrey\nWhen using the default environment colour settings for RStudio, what colour would the background of normal text be in R Markdown? redwhitegreengrey\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nAssuming you have not changed any of the settings in RStudio, code chunks will tend to have a grey background and normal text will tend to have a white background. This is a good way to check that you have closed and opened code chunks correctly.\n\n\n\n\n\nQuestion 3\nCode chunks start and end with:\n\n three single quotes three backticks three double quotes three single asterisks\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCode chunks always take the same general format of three backticks followed by curly parentheses and a lower case r inside the parentheses ({r}). People often mistake these backticks for single quotes but that will not work. If you have set your code chunk correctly using backticks, the background colour should change to grey from white.\n\n\n\n\n\nQuestion 4\nWhat is the correct way to include a code chunk in RMarkdown that will be executed but neither the code nor its output will be shown in the final HTML document? {r, echo=FALSE}{r, eval=FALSE}{r, include=FALSE}{r, results=‘hide’}\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCheck the table of knitr display options in Section 1.3.2.\n\n{r, echo=FALSE} also executes the code and does not show the code, but it does display the result in the knitted html file. (matches 2/3 criteria)\n{r, eval=FALSE} does not show the results but does not execute the code and it does show it in the knitted file. (matches 1/3 criteria)\n{r, results=“hide”} executes the code and does not show results, however, it does include the code in the knitted html document. (matches 2/3 criteria)\n\n\n\n\n\n\n\nError mode\nSome of these codes have mistakes in them, other code chunks are not quite producing what was aimed for. Your task is to spot anything faulty, explain why the things happened, and perhaps try to fix them.\n\nQuestion 5\nYou want to read in data with the read_csv() function. You have just stated R, created a new .Rmd file, and typed the following code into your code chunk.\n\ndata &lt;- read_csv(\"data.csv\")\n\nHowever, R gives you an error message: could not find function \"read_csv\". What could be the reason?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\n“Could not find function” is an indication that you have forgotten to load in tidyverse. Because read_csv() is a function in the tidyverse collection, R cannot find it.\nFIX: Add library(tidyverse) prior to reading in the data and run the code chunk again.\n\n\n\n\n\nQuestion 6\nYou want to read in data with the read_csv() function. This time, you are certain you have loaded in tidyverse first. The code is as follows:\n\nlibrary(tidyverse)\ndata &lt;- read_csv(\"data.csv\")\n\nThe error message shows 'data.csv' does not exist in current working directory. You check your folder and it looks like this:\n\nWhy is there an error message?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nR is looking for a csv file that is called data which is currently not in the working directory. We may assume it’s in the data folder. Perhaps that happened when unzipping the zip file. So instead of placing the csv file on the same level as the project icon, it was unzipped into a folder named data.\nFIX - option 1: Take the data.csv out of the data folder and place it next to the project icon and the .Rmd file.\nFIX - option 2: Modify your R code to tell R that the data is in a separate folder called data, e.g., …\n\nlibrary(tidyverse)\ndata &lt;- read_csv(\"data/data.csv\")\n\n\n\n\n\n\nQuestion 7\nYou want to load tidyverse into the library. The code is as follows:\n\nlibrary(tidyverse)\n\nThe error message says: Error in library(tidyverse) : there is no package called ‘tidyverse’\nWhy is there an error message and how can we fix this?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nIf R says there is no package called tidyverse, means you haven’t installed the package yet. This could be an error message you receive either after switching computers or a fresh install of R and RStudio.\nFIX: Type install.packages(\"tidyverse\") into your Console.\n\n\n\n\n\nQuestion 8\nYou knitted your .Rmd into a html but the output is not as expected. You see the following:\n\nWhy did the file not knit properly?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThere is a backtick missing in the code chunk. If you check your .Rmd file, you can see that the code chunk does not show up in grey which means it’s one of the 3 backticks at the beginning of the chunk.\n\nFIX: Add a single backtick manually where it’s missing.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Projects and R Markdown</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html",
    "href": "02-wrangling.html",
    "title": "2  Data wrangling I",
    "section": "",
    "text": "Intended Learning Outcomes\nIn the next two chapters, we will build on the data wrangling skills from level 1. We will revisit all the functions you have already encountered (and might have forgotten over the summer break) and introduce 2 or 3 new functions. These two chapters will provide an opportunity to revise and apply the functions to a novel dataset.\nBy the end of this chapter, you should be able to:\nThe main purpose of this chapter and Chapter 3 is to wrangle your data into shape for data visualisation (Chapter 4 and Chapter 5). For the two chapters, we will:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#intended-learning-outcomes",
    "href": "02-wrangling.html#intended-learning-outcomes",
    "title": "2  Data wrangling I",
    "section": "",
    "text": "apply familiar data wrangling functions to novel datasets\nread and interpret error messages\nrealise there are several ways of getting to the results\nexport data objects as csv files\n\n\n\ncalculate demographics\ntidy 3 different questionnaires with varying degrees of complexity\nsolve an error mode problem\njoin all data objects together",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#individual-walkthrough",
    "href": "02-wrangling.html#individual-walkthrough",
    "title": "2  Data wrangling I",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough\nBefore we start, we need to set up some things.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#activity-1-setup",
    "href": "02-wrangling.html#activity-1-setup",
    "title": "2  Data wrangling I",
    "section": "2.1 Activity 1: Setup",
    "text": "2.1 Activity 1: Setup\n\nWe will be working on the dataset by Pownall et al. (2023) again, which means we can still use the project we created last week. The data files will already be there, so no need to download them again.\nTo open the project in RStudio, go to the folder in which you stored the project and the data last time, and double click on the project icon.\nCreate a new .Rmd file for chapter 2 and save it to your project folder. Name it something meaningful (e.g., “chapter_02.Rmd”, “02_data_wrangling.Rmd”). See Section 1.3 if you need some guidance.\nIn your newly created .Rmd file, delete everything below line 12 (after the set-up code chunk).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#activity-2-load-in-the-libraries-and-read-in-the-data",
    "href": "02-wrangling.html#activity-2-load-in-the-libraries-and-read-in-the-data",
    "title": "2  Data wrangling I",
    "section": "2.2 Activity 2: Load in the libraries and read in the data",
    "text": "2.2 Activity 2: Load in the libraries and read in the data\nWe will use tidyverse today, and we want to create a data object data_prp that stores the data from the file prp_data_reduced.csv.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nlibrary(???)\ndata_prp &lt;- read_csv(\"???\")\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\ndata_prp &lt;- read_csv(\"prp_data_reduced.csv\")\n\n\n\n\nIf you need a quick reminder what the dataset was about, have a look at the abstract in Section 1.4. We also addressed the changes we made to the dataset there.\nAnd remember to have a quick glimpse() at your data.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#activity-3-calculating-demographics",
    "href": "02-wrangling.html#activity-3-calculating-demographics",
    "title": "2  Data wrangling I",
    "section": "2.3 Activity 3: Calculating demographics",
    "text": "2.3 Activity 3: Calculating demographics\nLet’s start with some simple data-wrangling steps to compute demographics for our original dataset, data_prp. First, we want to determine how many participants took part in the study by Pownall et al. (2023) and compute the mean age and the standard deviation of age for the sample.\n\n2.3.1 … for the full sample using summarise()\nThe summarise() function is part of the “Wickham Six” alongside group_by(), select(), filter(), mutate(), and arrange(). You used them plenty of times last year.\nWithin summarise(), we can use the n() function, which calculates the number of rows in the dataset. Since each row corresponds to a unique participant, this gives us the total number of participants.\nTo calculate the mean age and the standard deviation of age, we need to use the functions mean() and sd() on the column Age respectively.\n\ndemo_total &lt;- data_prp %&gt;% \n  summarise(n = n(), # participant number\n            mean_age = mean(Age), # mean age\n            sd_age = sd(Age)) # standard deviation of age\n\nWarning: There were 2 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `mean_age = mean(Age)`.\nCaused by warning in `mean.default()`:\n! argument is not numeric or logical: returning NA\nℹ Run `dplyr::last_dplyr_warnings()` to see the 1 remaining warning.\n\ndemo_total\n\n\n\n\n\nn\nmean_age\nsd_age\n\n\n\n\n89\nNA\nNA\n\n\n\n\n\n\nR did not give us an error message per se, but the output is not quite as expected either. There are NA values in the mean_age and sd_age columns. Looking at the warning message and at Age, can you explain what happened?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe warning message says: argument is not numeric or logical: returning NA If we look at the Age column more closely, we can see that it’s a character data type.\n\n\n\n\nFixing Age\nMight be wise to look at the unique answers in column Age to determine what is wrong. We can do that with the function distinct().\n\nage_distinct &lt;- data_prp %&gt;% \n  distinct(Age)\n\nage_distinct\n\n\n\n\n\n\n\nShow the unique values of Age.\n\n\n\n\n\n\n\n\n\n\n\nAge\n\n\n\n\n22\n\n\n20\n\n\n26\n\n\n21\n\n\n29\n\n\n23\n\n\n39\n\n\nNA\n\n\n24\n\n\n43\n\n\n31\n\n\n25 years\n\n\n\n\n\n\n\n\n\n\n\nAha! One cell has the string “years” added to their number 25, which has converted the entire column into a character column.\nWe can easily fix this by extracting only the numbers from the column and converting it into a numeric data type. The parse_number() function, which is part of the tidyverse package, handles both steps in one go (so there’s no need to load additional packages).\nWe will combine this with the mutate() function to create a new column called Age (containing those numeric values), effectively replacing the old Age column (which had the character values).\n\n\n\n\nparse_number() illustration by Allison Horst (see https://allisonhorst.com/r-packages-functions)\n\n\n\n\n\ndata_prp &lt;- data_prp %&gt;% \n  mutate(Age = parse_number(Age))\n\ntypeof(data_prp$Age) # fixed\n\n[1] \"double\"\n\n\n\n\nComputing summary stats\nExcellent. Now that the numbers are in a numeric format, let’s try calculating the demographics for the total sample again.\n\ndemo_total &lt;- data_prp %&gt;% \n  summarise(n = n(), # participant number\n            mean_age = mean(Age), # mean age\n            sd_age = sd(Age)) # standard deviation of age\n\ndemo_total\n\n\n\n\n\nn\nmean_age\nsd_age\n\n\n\n\n89\nNA\nNA\n\n\n\n\n\n\nEven though there’s no error or warning, the table still shows NA values for mean_age and sd_age. So, what could possibly be wrong now?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nDid you notice that the Age column in age_distinct contains some missing values (NA)? To be honest, it’s easier to spot this issue in the actual R output than in the printed HTML page.\n\n\n\n\n\nComputing summary stats - third attempt\nTo ensure R ignores missing values during calculations, we need to add the extra argument na.rm = TRUE to the mean() and sd() functions.\n\ndemo_total &lt;- data_prp %&gt;% \n  summarise(n = n(), # participant number\n            mean_age = mean(Age, na.rm = TRUE), # mean age\n            sd_age = sd(Age, na.rm = TRUE)) # standard deviation of age\n\ndemo_total\n\n\n\n\n\nn\nmean_age\nsd_age\n\n\n\n\n89\n21.88506\n3.485603\n\n\n\n\n\n\nFinally, we’ve got it! 🥳 Third time’s the charm!\n\n\n\n2.3.2 … per gender using summarise() and group_by()\nNow we want to compute the summary statistics for each gender. The code inside the summarise() function remains unchanged; we just need to use the group_by() function beforehand to tell R that we want to compute the summary statistics for each group separately. It’s also a good practice to use ungroup() afterwards, so you are not taking groupings forward unintentionally.\n\ndemo_by_gender &lt;- data_prp %&gt;% \n  group_by(Gender) %&gt;% # split data up into groups (here Gender)\n  summarise(n = n(), # participant number \n            mean_age = mean(Age, na.rm = TRUE), # mean age \n            sd_age = sd(Age, na.rm = TRUE)) %&gt;%  # standard deviation of age\n  ungroup()\n\ndemo_by_gender\n\n\n\n\n\nGender\nn\nmean_age\nsd_age\n\n\n\n\n1\n17\n23.31250\n5.770254\n\n\n2\n69\n21.57353\n2.738973\n\n\n3\n3\n21.33333\n1.154700\n\n\n\n\n\n\n\n\n2.3.3 Adding percentages\nSometimes, it may be useful to calculate percentages, such as for the gender split. You can do this by adding a line within the summarise() function to perform the calculation. All we need to do is take the number of female, male, and non-binary participants (stored in the n column of demo_by_gender), divide it by the total number of participants (stored in the n column of demo_total), and multiply by 100. Let’s add percentage to the summarise() function of demo_by_gender. Make sure that the code for percentages is placed after the value for n has been computed.\nAccessing the value of n for the different gender categories is straightforward because we can refer back to it directly. However, since the total number of participants is stored in a different data object, we need to use a base R function to access it – specifically the $ operator. To do this, you simply type the name of the data object (in this case, demo_total), followed by the $ symbol (with no spaces), and then the name of the column you want to retrieve (in this case, n). The general pattern is data$column.\n\ndemo_by_gender &lt;- data_prp %&gt;% \n  group_by(Gender) %&gt;% \n  summarise(n = n(), \n            # n from the line above divided by n from demo_total *100\n            percentage = n/demo_total$n *100, \n            mean_age = mean(Age, na.rm = TRUE), \n            sd_age = sd(Age, na.rm = TRUE)) %&gt;% \n  ungroup()\n\ndemo_by_gender\n\n\n\n\n\nGender\nn\npercentage\nmean_age\nsd_age\n\n\n\n\n1\n17\n19.101124\n23.31250\n5.770254\n\n\n2\n69\n77.528090\n21.57353\n2.738973\n\n\n3\n3\n3.370786\n21.33333\n1.154700\n\n\n\n\n\n\n\n\n\n\n\n\nTip for decimal places - use round()\n\n\n\n\n\nNot super important, because you could round the values by yourself when writing up your reports, but if you wanted to tidy up the decimal places in the output, you can do that using the round() function. You would need to “wrap” it around your computations and specify how many decimal places you want to display (for example mean(Age) would turn into round(mean(Age), 1)). It may look odd for percentage, just make sure the number that specifies the decimal places is placed within the round function. The default value is 0 (meaning no decimal spaces).\n\ndemo_by_gender &lt;- data_prp %&gt;% \n  group_by(Gender) %&gt;% \n  summarise(n = n(), \n            percentage = round(n/demo_total$n *100, 2), # percentage with 2 decimal places\n            mean_age = round(mean(Age, na.rm = TRUE), 1), # mean Age with 1 decimal place\n            sd_age = round(sd(Age, na.rm = TRUE), 3)) %&gt;% # sd Age with 3 decimal places\n  ungroup()\n\ndemo_by_gender\n\n\n\n\n\nGender\nn\npercentage\nmean_age\nsd_age\n\n\n\n\n1\n17\n19.10\n23.3\n5.770\n\n\n2\n69\n77.53\n21.6\n2.739\n\n\n3\n3\n3.37\n21.3\n1.155\n\n\n\n\n\n\n\n\n\n\n\n2.3.4 filter() gender\nI know you used filter() plenty of times last year, so let’s just do a quick recap. Imagine we want to calculate summary statistics only for gender category 3. In this case, we need the Boolean expression ==.\n\ndemo_gender3 &lt;- data_prp %&gt;% \n  filter(Gender == 3) %&gt;% \n  summarise(n = n(), \n            mean_age = mean(Age, na.rm = TRUE), \n            sd_age = sd(Age, na.rm = TRUE)) %&gt;%  \n  ungroup()\n\ndemo_gender3\n\n\n\n\n\nn\nmean_age\nsd_age\n\n\n\n\n3\n21.33333\n1.1547\n\n\n\n\n\n\nIf we want to focus on more than one gender category, we use the Boolean operator %in% along with the c() function (which combines values into a vector).\n\ndemo_gender12 &lt;- data_prp %&gt;% \n  filter(Gender %in% c(1,2)) %&gt;% \n  group_by(Gender) %&gt;% \n  summarise(n = n(), \n            mean_age = mean(Age, na.rm = TRUE), \n            sd_age = sd(Age, na.rm = TRUE)) %&gt;%  \n  ungroup()\n\ndemo_gender12\n\n\n\n\n\nGender\nn\nmean_age\nsd_age\n\n\n\n\n1\n17\n23.31250\n5.770254\n\n\n2\n69\n21.57353\n2.738973\n\n\n\n\n\n\n\n\n\n\n\n\nCharacter values instead of numbers?\n\n\n\nHere, the gender categories are coded with numbers. If your data used character values instead, you’d need quotation marks around the labels, for example:\n\nfilter(Gender == \"Non-binary/third gender\")\n\nOR\n\nfilter(Gender %in% c(\"Male\",\"Female\"))",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#sec-ch2_act4",
    "href": "02-wrangling.html#sec-ch2_act4",
    "title": "2  Data wrangling I",
    "section": "2.4 Activity 4: Questionable Research Practices (QRPs)",
    "text": "2.4 Activity 4: Questionable Research Practices (QRPs)\n\nThe main goal is to compute the mean QRP score per participant for time point 1.\nAt the moment, the data is in wide format. The table below shows data from the first 3 participants:\n\nhead(data_prp, n = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nGender\nAge\nEthnicity\nSecondyeargrade\nOpptional_mod\nOpptional_mod_1_TEXT\nResearch_exp\nResearch_exp_1_TEXT\nPlan_prereg\nSATS28_1_Affect_Time1\nSATS28_2_Affect_Time1\nSATS28_3_Affect_Time1\nSATS28_4_Affect_Time1\nSATS28_5_Affect_Time1\nSATS28_6_Affect_Time1\nSATS28_7_CognitiveCompetence_Time1\nSATS28_8_CognitiveCompetence_Time1\nSATS28_9_CognitiveCompetence_Time1\nSATS28_10_CognitiveCompetence_Time1\nSATS28_11_CognitiveCompetence_Time1\nSATS28_12_CognitiveCompetence_Time1\nSATS28_13_Value_Time1\nSATS28_14_Value_Time1\nSATS28_15_Value_Time1\nSATS28_16_Value_Time1\nSATS28_17_Value_Time1\nSATS28_18_Value_Time1\nSATS28_19_Value_Time1\nSATS28_20_Value_Time1\nSATS28_21_Value_Time1\nSATS28_22_Difficulty_Time1\nSATS28_23_Difficulty_Time1\nSATS28_24_Difficulty_Time1\nSATS28_25_Difficulty_Time1\nSATS28_26_Difficulty_Time1\nSATS28_27_Difficulty_Time1\nSATS28_28_Difficulty_Time1\nQRPs_1_Time1\nQRPs_2_Time1\nQRPs_3_Time1\nQRPs_4_Time1\nQRPs_5_Time1\nQRPs_6_Time1\nQRPs_7_Time1\nQRPs_8_Time1\nQRPs_9_Time1\nQRPs_10_Time1\nQRPs_11_Time1\nQRPs_12NotQRP_Time1\nQRPs_13NotQRP_Time1\nQRPs_14NotQRP_Time1\nQRPs_15NotQRP_Time1\nUnderstanding_OS_1_Time1\nUnderstanding_OS_2_Time1\nUnderstanding_OS_3_Time1\nUnderstanding_OS_4_Time1\nUnderstanding_OS_5_Time1\nUnderstanding_OS_6_Time1\nUnderstanding_OS_7_Time1\nUnderstanding_OS_8_Time1\nUnderstanding_OS_9_Time1\nUnderstanding_OS_10_Time1\nUnderstanding_OS_11_Time1\nUnderstanding_OS_12_Time1\nPre_reg_group\nOther_OS_behav_2\nOther_OS_behav_4\nOther_OS_behav_5\nClosely_follow\nSATS28_Affect_Time2_mean\nSATS28_CognitiveCompetence_Time2_mean\nSATS28_Value_Time2_mean\nSATS28_Difficulty_Time2_mean\nQRPs_Acceptance_Time2_mean\nTime2_Understanding_OS\nSupervisor_1\nSupervisor_2\nSupervisor_3\nSupervisor_4\nSupervisor_5\nSupervisor_6\nSupervisor_7\nSupervisor_8\nSupervisor_9\nSupervisor_10\nSupervisor_11\nSupervisor_12\nSupervisor_13\nSupervisor_14\nSupervisor_15_R\n\n\n\n\nTr10\n2\n22\nWhite European\n2\n1\nResearch methods in first year\n2\nNA\n1\n4\n5\n3\n4\n5\n5\n4\n2\n2\n6\n4\n3\n1\n7\n7\n2\n1\n3\n3\n2\n2\n3\n5\n2\n6\n4\n4\n1\n7\n7\n5\n7\n3\n4\n5\n7\n6\n7\n7\n2\n1\n1\n2\n2\n2\n2\n6\nEntirely confident\nEntirely confident\n6\n6\nEntirely confident\nEntirely confident\nEntirely confident\nEntirely confident\n1\n1\n1\nNA\n2\n3.500000\n4.166667\n3.000000\n2.857143\n5.636364\n5.583333\n5\n5\n6\n6\n5\n5\n1\n5\n6\n5\nNA\n4\n4\n5\n1\n\n\nBi07\n2\n20\nWhite British\n3\n2\nNA\n2\nNA\n3\n5\n6\n2\n5\n5\n6\n2\n2\n2\n7\n3\n5\n1\n7\n7\n1\n1\n6\n3\n1\n1\n2\n6\n2\n7\n2\n5\n7\n7\n7\n2\n7\n3\n7\n7\n7\n7\n6\n7\n2\n1\n4\n4\n2\nNot at all confident\nNot at all confident\nNot at all confident\n6\nEntirely confident\nNot at all confident\n3\n6\n6\n2\n2\n1\nNA\nNA\nNA\n2\n3.166667\n4.666667\n6.222222\n2.857143\n5.454546\n3.333333\n7\n6\n7\n7\n7\n7\n1\n5\n7\n7\n7\n5\n2\n7\n1\n\n\nSK03\n2\n22\nWhite British\n1\n2\nNA\n2\nNA\n1\n5\n3\n5\n2\n5\n2\n2\n2\n2\n6\n5\n3\n2\n6\n6\n3\n3\n5\n3\n4\n3\n5\n5\n2\n5\n2\n5\n5\n7\n7\n6\n6\n7\n6\n7\n7\n7\n5\n7\n1\n1\n3\n2\n6\n2\n3\n6\n6\n5\n2\n5\n5\n5\n4\n5\n1\nNA\nNA\nNA\n2\n4.833333\n6.166667\n6.000000\n4.000000\n6.272727\n5.416667\n7\n7\n7\n7\n7\n7\n1\n7\n7\n7\n7\n7\n5\n7\n1\n\n\n\n\n\n\n\n\nLooking at the QRP data at time point 1, you determine that\n\nindividual item columns are numericcharacter, and\naccording to the codebook, there are nosome reverse-coded items in this questionnaire.\n\nAccording to the codebook and the data table above, we just have to compute the average score for QRP items  to , since items  to  are distractor items. Seems quite straightforward.\nHowever, as you can see in the table above, each item is in a separate column, meaning the data is in wide format. It would be much easier to calculate the mean scores if the items were arranged in long format.\nLet’s tackle this problem step by step. It’s best to create a separate data object for this. If we tried to compute it within data_prp, it could quickly become messy.\n\nStep 1: Select the relevant columns Code, and QRPs_1_Time1 to QRPs_11_Time1 and store them in an object called qrp_t1\nStep 2: Pivot the data from wide format to long format using pivot_longer() so we can calculate the average score more easily (in step 3)\nStep 3: Calculate the average QRP score (QRPs_Acceptance_Time1_mean) per participant using group_by() and summarise()\n\n\nqrp_t1 &lt;- data_prp %&gt;% \n  #Step 1\n  select(Code, QRPs_1_Time1:QRPs_11_Time1) %&gt;%\n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Scores\") %&gt;% \n  # Step 3\n  group_by(Code) %&gt;% # grouping by participant id\n  summarise(QRPs_Acceptance_Time1_mean = mean(Scores)) %&gt;% # calculating the average Score\n  ungroup() # just make it a habit\n\n\n\n\n\n\n\nExplain the individual functions\n\n\n\n\n\n\nselect ()pivot_longer()group_by() and summarise()\n\n\nThe select function allows to include or exclude certain variables (columns). Here we want to focus on the participant ID column (i.e., Code) and the QRP items at time point 1. We can either list them all individually, i.e., Code, QRPs_1_Time1, QRPs_2_Time1, QRPs_3_Time1, and so forth (you get the gist), but that would take forever to type.\nA shortcut is to use the colon operator :. It allows us to select all columns that fall within the range of first_column_name to last_column_name. We can apply this here since the QRP items (1 to 11) are sequentially listed in data_prp.\n\nqrp_step1 &lt;- data_prp %&gt;% \n  select(Code, QRPs_1_Time1:QRPs_11_Time1)\n\n# show first 5 rows of qrp_step1\nhead(qrp_step1, n = 5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nQRPs_1_Time1\nQRPs_2_Time1\nQRPs_3_Time1\nQRPs_4_Time1\nQRPs_5_Time1\nQRPs_6_Time1\nQRPs_7_Time1\nQRPs_8_Time1\nQRPs_9_Time1\nQRPs_10_Time1\nQRPs_11_Time1\n\n\n\n\nTr10\n7\n7\n5\n7\n3\n4\n5\n7\n6\n7\n7\n\n\nBi07\n7\n7\n2\n7\n3\n7\n7\n7\n7\n6\n7\n\n\nSK03\n7\n7\n6\n6\n7\n6\n7\n7\n7\n5\n7\n\n\nSM95\n7\n7\n2\n6\n7\n5\n7\n7\n4\n2\n4\n\n\nSt01\n7\n7\n6\n7\n2\n7\n7\n7\n7\n5\n7\n\n\n\n\n\n\nHow many rows/observations and columns/variables do we have in qrp_step1?\n\nrows/observations: \ncolumns/variables: \n\n\n\nAs you can see, the table we got from Step 1 is in wide format. To get it into wide format, we need to define:\n\nthe columns that need to be reshuffled from wide into long format (col argument). Here we selected “everything except the Code column”, as indicated by -Code [minus Code]. However, QRPs_1_Time1:QRPs_11_Time1 would also work and give you the exact same result.\nthe names_to argument. R is creating a new column in which all the column names from the columns you selected in col will be stored in. Here we are naming this column “Items” but you could pick something equally sensible if you like.\nthe values_to argument. R creates this second column to store all responses the participants gave to the individual questions, i.e., all the numbers in this case. We named it “Scores” here, but you could have called it something different, like “Responses”\n\n\nqrp_step2 &lt;- qrp_step1 %&gt;% \n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Scores\")\n\n# show first 15 rows of qrp_step2\nhead(qrp_step2, n = 15)\n\n\n\n\n\nCode\nItems\nScores\n\n\n\n\nTr10\nQRPs_1_Time1\n7\n\n\nTr10\nQRPs_2_Time1\n7\n\n\nTr10\nQRPs_3_Time1\n5\n\n\nTr10\nQRPs_4_Time1\n7\n\n\nTr10\nQRPs_5_Time1\n3\n\n\nTr10\nQRPs_6_Time1\n4\n\n\nTr10\nQRPs_7_Time1\n5\n\n\nTr10\nQRPs_8_Time1\n7\n\n\nTr10\nQRPs_9_Time1\n6\n\n\nTr10\nQRPs_10_Time1\n7\n\n\nTr10\nQRPs_11_Time1\n7\n\n\nBi07\nQRPs_1_Time1\n7\n\n\nBi07\nQRPs_2_Time1\n7\n\n\nBi07\nQRPs_3_Time1\n2\n\n\nBi07\nQRPs_4_Time1\n7\n\n\n\n\n\n\nNow, have a look at qrp_step2. In total, we now have  rows/observations,  per participant, and  columns/variables.\n\n\nThis follows exactly the same sequence we used when calculating descriptive statistics by gender. The only difference is that we are now grouping the data by the participant’s Code instead of Gender.\nsummarise() works exactly the same way: summarise(new_column_name = function_to_calculate_something(column_name_of_numeric_values))\nThe function_to_calculate_something can be mean(), sd() or sum() for mean scores, standard deviations, or summed-up scores respectively. You could also use min() or max() if you wanted to determine the lowest or the highest score for each participant.\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou could rename the columns whilst selecting them. The pattern would be select(new_name = old_name). For example, if we wanted to select variable Code and rename it as Participant_ID, we could do that.\n\nrenaming_col &lt;- data_prp %&gt;% \n  select(Participant_ID = Code)\n\nhead(renaming_col, n = 5)\n\n\n\n\n\nParticipant_ID\n\n\n\n\nTr10\n\n\nBi07\n\n\nSK03\n\n\nSM95\n\n\nSt01",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#activity-5-knitting",
    "href": "02-wrangling.html#activity-5-knitting",
    "title": "2  Data wrangling I",
    "section": "2.5 Activity 5: Knitting",
    "text": "2.5 Activity 5: Knitting\nOnce you’ve completed your R Markdown file, the final step is to “knit” it, which converts the .Rmd file into a HTML file. Knitting combines your code, text, and output (like tables and plots) into a single cohesive document. This is a really good way to check your code is working.\nTo knit the file, click the Knit button at the top of your RStudio window. The document will be generated and, depending on your setting, automatically opened in the viewer in the Output pane or an external browser window.\nIf any errors occur during knitting, RStudio will show you an error message with details to help you troubleshoot.\nIf you want to intentionally keep any errors we tackled today to keep a reference on how you solved them, you could add error=TRUE or eval=FALSE to the code chunk that isn’t running.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#activity-6-export-a-data-object-as-a-csv",
    "href": "02-wrangling.html#activity-6-export-a-data-object-as-a-csv",
    "title": "2  Data wrangling I",
    "section": "2.6 Activity 6: Export a data object as a csv",
    "text": "2.6 Activity 6: Export a data object as a csv\nTo avoid having to repeat the same steps in the next chapter, it’s a good idea to save the data objects you’ve created today as csv files. You can do this by using the write_csv() function from the readr package. The csv files will appear in your project folder.\nThe basic syntax is:\n\nwrite_csv(data_object, \"filename.csv\")\n\nNow, let’s export the objects data_prp and qrp_t1.\n\nwrite_csv(data_prp, \"data_prp_for_ch3.csv\")\n\nHere we named the file data_prp_for_ch3.csv, so we wouldn’t override the original data csv file prp_data_reduced.csv. However, feel free to choose a name that makes sense to you.\n\n\n\n\n\n\nYour Turn\n\n\n\nExport qrp_t1.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwrite_csv(qrp_t1, \"qrp_t1.csv\")\n\n\n\n\n\n\nCheck that your csv files have appeared in your project folder, and you’re all set!\nThat’s it for Chapter 2: Individual Walkthrough.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "02-wrangling.html#test-your-knowledge-and-challenge-yourself",
    "href": "02-wrangling.html#test-your-knowledge-and-challenge-yourself",
    "title": "2  Data wrangling I",
    "section": "Test your knowledge and challenge yourself",
    "text": "Test your knowledge and challenge yourself\n\nKnowledge check\n\nQuestion 1\nWhich function of the Wickham Six would you use to include or exclude certain variables (columns)? select()filter()mutate()arrange()group_by()summarise()\n\n\nQuestion 2\nWhich function of the Wickham Six would you use to create new columns or modify existing columns in a dataframe? select()filter()mutate()arrange()group_by()summarise()\n\n\nQuestion 3\nWhich function of the Wickham Six would you use to organise data into groups based on one or more columns? select()filter()mutate()arrange()group_by()summarise()\n\n\nQuestion 4\nWhich function of the Wickham Six would you use to sort the rows of a dataframe based on the values in one or more columns? select()filter()mutate()arrange()group_by()summarise()\n\n\nQuestion 5\nWhich function of the Wickham Six would NOT modify the original dataframe? select()filter()mutate()arrange()group_by()summarise()\n\n\n\n\n\n\nExplain these answers\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nselect()\nInclude or exclude certain variables/columns\n\n\nfilter()\nInclude or exclude certain observations/rows\n\n\nmutate()\nCreates new columns or modifies existing ones\n\n\narrange()\nChanges the order of the rows\n\n\ngroup_by()\nSplit data into groups based on one or more variables\n\n\nsummarise()\nCreates a new dataframe returning one row for each combination of grouping variables\n\n\n\nTechnically, the first five functions operate on the existing data object, making adjustments like sorting the data (e.g., with arrange()), reducing the number of rows (e.g., with filter()), reducing the number of columns (e.g., with select()), or adding new columns (e.g., with mutate()). In contrast, summarise() fundamentally alters the structure of the original dataframe by generating a completely new dataframe that contains only summary statistics, rather than retaining the original rows and columns.\n\n\n\n\n\n\nError mode\nSome of the code chunks contain mistakes and result in errors, while others do not produce the expected results. Your task is to identify any issues, explain why they occurred, and, if possible, fix them.\nWe will use a few built-in datasets, such as billboard and starwars, to help you replicate the errors in your own R environment. You can view the data either by typing the dataset name directly into your console or by storing the data as a separate object in your Global Environment.\n\nbillboard\n\nstarwars_data = starwars\n\n\nQuestion 6\nCurrently, the weekly song rankings for Billboard Top 100 in 2000 are in wide format, with each week in a separate column. The following code is supposed to transpose the wide-format billboard data into long format:\n\nlong_data &lt;- billboard %&gt;% \n  pivot_longer(names_to = \"weeks\", values_to = \"rank\")\n\nError in `pivot_longer()`:\n! `cols` must select at least one column.\n\n\nWhat does this error message mean and how do you fix it?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe error message indicates that the cols argument is missing in the function. This means the function doesn’t know which columns to transpose from wide format to long format.\nFIX: Add cols = wk1:wk76 to the function to select columns from wk1 to wk76. Alternatively, cols = starts_with(\"wk\") would also work since all columns start with the letter combination “wk”.\n\nlong_data &lt;- billboard %&gt;% \n  pivot_longer(cols = wk1:wk76, names_to = \"weeks\", values_to = \"rank\")\n# OR\nlong_data &lt;- billboard %&gt;% \n  pivot_longer(cols = starts_with(\"wk\"), names_to = \"weeks\", values_to = \"rank\")\n\n\n\n\n\n\nQuestion 7\nThe following code is intended to calculate the mean height of all the characters in the built-in starwars dataset, grouped by their gender.\n\nsummary_data &lt;- starwars %&gt;%\n  group_by(gender) %&gt;%\n  summarise(mean_height = height)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\nThe code runs, but it’s giving us some weird warning and the output is also not as expected. What steps should we take to fix this?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe aggregation function mean() is missing from within summarise(). Without it, the function does not perform any aggregation and returns all rows with only the columns for gender and height.\nFIX: Wrap the mean() function around the variable you want to aggregate, here height.\n\nsummary_data &lt;- starwars %&gt;%\n  group_by(gender) %&gt;%\n  summarise(mean_height = mean(height))\n\n\n\n\n\n\nQuestion 8\nFollowing up on Question 7, we now have summary_data that looks approximately correct - it has the expected rows and column numbers, however, the cell values are “weird”.\n\nsummary_data\n\n\n\n\n\ngender\nmean_height\n\n\n\n\nfeminine\nNA\n\n\nmasculine\nNA\n\n\nNA\n175\n\n\n\n\n\n\nCan you explain what is happening here? And how can we modify the code to fix this?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nLook at the original starwars data. You will notice that some of the characters with feminine and masculine gender entries have missing height values. However, all four characters without a specified gender have provided their height.\nFIX: We need to add na.rm = TRUE to the mean() function to ensure that R ignores missing values before aggregating the data.\n\nsummary_data &lt;- starwars %&gt;%\n  group_by(gender) %&gt;%\n  summarise(mean_height = mean(height, na.rm = TRUE))\n\nsummary_data\n\n\n\n\n\ngender\nmean_height\n\n\n\n\nfeminine\n166.5333\n\n\nmasculine\n176.5323\n\n\nNA\n175.0000\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge yourself\nIf you want to challenge yourself and further apply the skills from Chapter 2, you can wrangle the data from dog_data_raw for additional questionnaires from either the pre- and/or post-intervention stages:\n\nCalculate the mean score for flourishing_post for each participant.\nCalculate the mean score for the PANAS (Positive and/or Negative Affect) per participant\nCalculate the mean score for happiness (SHS) per participant\n\nThe 3 steps are equivalent for those questionnaires - select, pivot, group_by and summarise; you just have to “replace” the questionnaire items involved.\n\n\n\n\n\n\nSolution for Challenge yourself\n\n\n\n\n\nFlourishing post-intervention\n\n## flourishing_post\nflourishing_post &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, starts_with(\"F2\")) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(Flourishing_post = mean(Response)) %&gt;% \n  ungroup()\n\nThe PANAS could be solved more concisely with the skills we learn in Chapter 3, but for now, you would have solved it this way:\n\n# PANAS - positive affect pre\nPANAS_PA_pre &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, PN1_3, PN1_5, PN1_7, PN1_8, PN1_10) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(PANAS_PA_pre = mean(Scores)) %&gt;% \n  ungroup()\n\n# PANAS - positive affect post\nPANAS_PA_post &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, PN2_3, PN2_5, PN2_7, PN2_8, PN2_10) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(PANAS_PA_post = mean(Scores)) %&gt;% \n  ungroup()\n\n# PANAS - negative affect pre\nPANAS_NA_pre &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, PN1_1, PN1_2, PN1_4, PN1_6, PN1_9) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(PANAS_NA_pre = mean(Scores)) %&gt;% \n  ungroup()\n\n# PANAS - negative affect post\nPANAS_NA_post &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, PN2_1, PN2_2, PN2_4, PN2_6, PN2_9) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(PANAS_NA_post = mean(Scores)) %&gt;% \n  ungroup()\n\nHappiness scale\n\n# happiness_pre\nhappiness_pre &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, HA1_1, HA1_2, HA1_3) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Item\", values_to = \"Score\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(SHS_pre = mean(Score)) %&gt;% \n  ungroup()\n\n#happiness_post\nhappiness_post &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, HA2_1, HA2_2, HA2_3) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Item\", values_to = \"Score\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(SHS_post = mean(Score)) %&gt;% \n  ungroup()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data wrangling I</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html",
    "href": "03-wrangling2.html",
    "title": "3  Data wrangling II",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter, you should be able to:\nIn this chapter, we will pick up where we left off in Chapter 2. We will calculate average scores for two of the questionnaires, address an error mode problem, and finally, join all data objects together. This will finalise our data for the upcoming data visualization sections (Chapter 4 and Chapter 5).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#intended-learning-outcomes",
    "href": "03-wrangling2.html#intended-learning-outcomes",
    "title": "3  Data wrangling II",
    "section": "",
    "text": "apply familiar data wrangling functions to novel datasets\nread and interpret error messages\nrealise there are several ways of getting to the results",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#individual-walkthrough",
    "href": "03-wrangling2.html#individual-walkthrough",
    "title": "3  Data wrangling II",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#activity-1-setup",
    "href": "03-wrangling2.html#activity-1-setup",
    "title": "3  Data wrangling II",
    "section": "3.1 Activity 1: Setup",
    "text": "3.1 Activity 1: Setup\n\nGo to the project folder we have been using in the last two weeks and double-click on the project icon to open the project in RStudio\nEither Create a new .Rmd file for chapter 3 and save it to your project folder or continue the one from last week. See Section 1.3 if you need some guidance.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#activity-2-load-in-the-libraries-and-read-in-the-data",
    "href": "03-wrangling2.html#activity-2-load-in-the-libraries-and-read-in-the-data",
    "title": "3  Data wrangling II",
    "section": "3.2 Activity 2: Load in the libraries and read in the data",
    "text": "3.2 Activity 2: Load in the libraries and read in the data\nToday, we will be using tidyverse along with the two csv files created at the end of the last chapter: data_prp_for_ch3.csv and qrp_t1.csv. If you need to download them again for any reason, click on the following links: data_prp_for_ch3.csv and qrp_t1.csv.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nlibrary(???)\ndata_prp &lt;- read_csv(\"???\")\nqrp_t1 &lt;- read_csv(\"???\")\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\ndata_prp &lt;- read_csv(\"prp_data_reduced.csv\")\nqrp_t1 &lt;- read_csv(\"qrp_t1.csv\")\n\n\n\n\nIf you need a quick reminder what the dataset was about, have a look at the abstract in Section 1.4. We also addressed the changes we made to the dataset there.\nAnd remember to have a quick glimpse() at your data.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#sec-wrangling2_act3",
    "href": "03-wrangling2.html#sec-wrangling2_act3",
    "title": "3  Data wrangling II",
    "section": "3.3 Activity 3: Confidence in understanding Open Science practices",
    "text": "3.3 Activity 3: Confidence in understanding Open Science practices\n\nThe main goal is to compute the mean Understanding score per participant.\nThe mean Understanding score for time point 2 has already been calculated (in the Time2_Understanding_OS column), but we still need to compute it for time point 1.\nLooking at the Understanding data at time point 1, you determine that\n\nindividual item columns are numericcharacter, and\naccording to the codebook, there are nosome reverse-coded items in this questionnaire.\n\nThe steps are quite similar to those for QRP, but we need to add an extra step: converting the character labels into numbers.\nAgain, let’s do this step by step:\n\nStep 1: Select the relevant columns Code, and every Understanding column from time point 1 (e.g., from Understanding_OS_1_Time1 to Understanding_OS_12_Time1) and store them in an object called understanding_t1\nStep 2: Pivot the data from wide format to long format using pivot_longer() so we can recode the labels into values (step 3) and calculate the average score (in step 4) more easily\nStep 3: Recode the values “Not at all confident” as 1 and “Entirely confident” as 7. All other values are already numbers. We can use functions mutate() in combination with case_match() for that\nStep 4: Calculate the average Understanding Open Science score (Time1_Understanding_OS) per participant using group_by() and summarise()\n\n\n\nSteps 1 and 2: Select and pivot\nHow about you try the first 2 steps yourself using the code from Chapter 2 Activity 4 (Section 2.4) as a template?\n\nunderstanding_t1 &lt;- data_prp %&gt;% \n  select(???) %&gt;% # Step 1\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\") # Step 2\n\n\n\n\n\n\n\nSolution for steps 1 and 2\n\n\n\n\n\n\nunderstanding_t1 &lt;- data_prp %&gt;% \n  # Step 1\n  select(Code, Understanding_OS_1_Time1:Understanding_OS_12_Time1) %&gt;% \n  # Step 2 - I picked different column labels this time for some variety\n  pivot_longer(cols = Understanding_OS_1_Time1:Understanding_OS_12_Time1, names_to = \"Understanding_Qs\", values_to = \"Responses\") \n\n\n\n\n\n\nStep 3: recoding the values\nOK, we now want to recode the values in the Responses column (or whatever name you picked for your column that has some of the numbers in it) so that “Not at all confident” = 1 and “Entirely confident” = 7. We want to keep all other values as they are (2-6 look already quite “numeric”).\nLet’s create a new column Responses_corrected that stores the new values with mutate(). Then we can combine that with the case_match() function.\n\nThe first argument in case_match() is the column name of the variable you want to recode.\nThen you can start recoding the values in the way of CurrentValue ~ NewValue (~ is a tilde). Make sure you use the ~ and not =!\nLastly, the .default argument tells R what to do with values that are neither “Not at all confident” nor “Entirely confident”. Here, we want to replace them with the original value of the Responses column. In other datasets, you may want to set the default to NA for missing values, a character string or a number, and case_match() is happy to oblige.\n\n\nunderstanding_t1 &lt;- understanding_t1 %&gt;% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = Responses # all other values taken from column Responses\n  ))\n\nError in `mutate()`:\nℹ In argument: `Responses_corrected = case_match(...)`.\nCaused by error in `case_match()`:\n! Can't combine `..1 (right)` &lt;double&gt; and `.default` &lt;character&gt;.\n\n\n\n\n\n\n\n\nError!!! Can you explain what is happening here?\n\n\n\n\n\nHave a look at the error message. It’s pretty helpful this time. It says Can't combine ..1 (right) &lt;double&gt; and .default &lt;character&gt;. It means that the replacement values are expected to be data type character since the original column type was type character.\n\n\n\nSo how do we fix this? Actually, there are several ways this could be done. Click on the tabs below to check out 3 possible solutions.\n\nFix option 1Fix option 2Fix option 3\n\n\nOne option is to modify the .default argument Responses so that the values are copied over from the original column but as a number rather than the original character value. The function as.numeric() does the conversion.\n\nunderstanding_t1_step3_v1 &lt;- understanding_t1 %&gt;% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  ))\n\n\n\nChange the numeric values on the right side of the ~ to character. Then in a second step, we would need to turn the character column into a numeric type. Again, we have several options to do so. We could either use the parse_number() function we encountered earlier during the demographics wrangling or the as.numeric() function.\n\nV1: Responses_corrected = parse_number(Responses_corrected)\nV2: Responses_corrected = as.numeric(Responses_corrected)\n\nJust pay attention that you are still working within the mutate() function.\n\nunderstanding_t1_step3_v2 &lt;- understanding_t1 %&gt;% \n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ \"1\",\n                                          \"Entirely confident\" ~ \"7\",\n                                          .default = Responses # all other values taken from column Responses (character)\n  ),\n  Responses_corrected = parse_number(Responses_corrected)) # turning Responses_corrected into a numeric column\n\n\n\nIf you recode all the labels into numbers (e.g., “2” into 2, “3” into 3, etc.) from the start, you won’t need to perform any additional conversions later.\n\nunderstanding_t1_step3_v2 &lt;- understanding_t1 %&gt;% \n  mutate(Responses_recoded = case_match(Responses, # column of the values to recode\n                                        \"Not at all confident\" ~ 1, # recode all of them\n                                        \"2\" ~ 2,\n                                        \"3\" ~ 3,\n                                        \"4\" ~ 4,\n                                        \"5\" ~ 5,\n                                        \"6\" ~ 6,\n                                        \"Entirely confident\" ~ 7))\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nChoose the option that works best for you to modify the code of understanding_t1 above that didn’t work/ gave you an error message. Once you do that, you should be able to calculate the mean Understanding Score per participant. Store the average scores in a variable called Time1_Understanding_OS. If you need help, refer to the hint below or use Chapter 2 Activity 4 (Section 2.4) as guidance.\n\n\n\n\n\n\nOne solution for Steps 3 and 4\n\n\n\n\n\n\nunderstanding_t1 &lt;- understanding_t1 %&gt;% \n  # Step 3\n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  )) %&gt;% \n  # Step 4: calculating averages per participant\n  group_by(Code) %&gt;%\n  summarise(Time1_Understanding_OS = mean(Responses_corrected)) %&gt;%\n  ungroup()\n\n\n\n\n\n\nOf course, this could have been written up as a single pipe.\n\n\n\n\n\n\nSingle pipe of activity 3\n\n\n\n\n\n\nunderstanding_t1 &lt;- data_prp %&gt;% \n  # Step 1\n  select(Code, Understanding_OS_1_Time1:Understanding_OS_12_Time1) %&gt;% \n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Understanding_Qs\", values_to = \"Responses\") %&gt;% \n  # Step 3\n  mutate(Responses_corrected = case_match(Responses, # column of the values to recode\n                                          \"Not at all confident\" ~ 1, # values to recode\n                                          \"Entirely confident\" ~ 7,\n                                          .default = as.numeric(Responses) # all other values taken from column Responses but as numeric data type \n  )) %&gt;% \n  # Step 4\n  group_by(Code) %&gt;%\n  summarise(Time1_Understanding_OS = mean(Responses_corrected)) %&gt;%\n  ungroup()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#sec-wrangling2_act4",
    "href": "03-wrangling2.html#sec-wrangling2_act4",
    "title": "3  Data wrangling II",
    "section": "3.4 Activity 4: Survey of Attitudes Toward Statistics (SATS-28)",
    "text": "3.4 Activity 4: Survey of Attitudes Toward Statistics (SATS-28)\n\nThe main goal is to compute the mean SATS-28 score for each of the 4 subscales per participant for time point 1.\nLooking at the SATS data at time point 1, you determine that\n\nindividual item columns are numericcharacter, and\naccording to the codebook, there are nosome reverse-coded items in this questionnaire.\nAdditionally, we are looking to compute the means for the 4 different subscales of the SAT-28 which are , , , and .\n\nThis scenario is slightly more tricky than the previous ones due to the reverse-coding and the 4 subscales. So, let’s tackle this step by step again:\n\nStep 1: Select the relevant columns Code, and every SATS28 column from time point 1 (e.g., from SATS28_1_Affect_Time1 to SATS28_28_Difficulty_Time1) and store them in an object called sats_t1\nStep 2: Pivot the data from wide format to long format using pivot_longer() so we can recode the labels into values (step 3) and calculate the average score (in step 4) more easily\nStep 3: We need to know which items belong to which subscale - fortunately, we have that information in the variable name and can use the separate() function to access it.\nStep 4: We need to know which items are reverse-coded and then reverse-score them - unfortunately, the info is only in the codebook and we need to find a work-around. case_when() can help identify and re-score the reverse-coded items.\nStep 5: Calculate the average SATS score per participant and subscale using group_by() and summarise()\nStep 6: use pivot_wider() to spread out the dataframe into wide format and rename() to tidy up the column names\n\n\n\nSteps 1 and 2: select and pivot\nThe selecting and pivoting are exactly the same way as we already practiced in the other 2 questionnaires. Apply them here to this questionnaire.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nsats_t1 &lt;- data_prp %&gt;% \n  select(???) %&gt;% # Step 1\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\") # Step 2\n\n\n\n\n\n\n\nSolution for steps 1 and 2\n\n\n\n\n\n\nsats_t1 &lt;- data_prp %&gt;% \n  select(Code, SATS28_1_Affect_Time1:SATS28_28_Difficulty_Time1) %&gt;% # Step 1\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Response\") # Step 2\n\n\n\n\n\n\n\n\n\nStep 3: separate Subscale information\nIf you look at the Items column more closely, you can see that there is information on the Questionnaire, the Item_number, the Subscale, and the Timepoint the data was collected at.\nWe can separate the information into separate columns using the separate() function. The function’s first argument is the column to separate, then define into which columns you want the original column to split up, and lastly, define the separator sep (here an underscore). For our example, we would write:\n\nV1: separate(Items, into = c(\"SATS\", \"Item_number\", \"Subscale\", \"Time\"), sep = \"_\")\n\nHowever, we don’t need all of those columns, so we could just drop the ones we are not interested in by replacing them with NA.\n\nV2: separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\")\n\nWe might also add an extra argument of convert = TRUE to have numeric columns (i.e., Item_number) converted to numeric as opposed to keeping them as characters. Saves us typing a few quotation marks later in Step 4.\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  # Step 3\n  separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\", convert = TRUE)\n\n\n\nStep 4: identifying reverse-coded items and then correct them\nWe can use case_when() within the mutate() function here to create a new column FW_RV that stores information on whether the item is a reverse-coded item or not.\ncase_when() works similarly to case_match(), however case_match() only allows us to “recode” values (i.e., replace one value with another), whereas case_when() is more flexible. It allows us to use conditional statements on the left side of the tilde which is useful when you want to change only some of the data based on specific conditions.\nLooking at the codebook, it seems that items 2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, and 28 are reverse-coded. The rest are forward-coded.\nWe want to tell R now, that\n\nif the Item_number is any of those numbers listed above, R should write “Reverse” into the new column FW_RV we are creating. Since we have a few possible matches for Item_number, we need the Boolean expression %in% rather than ==.\nif Item_number is none of those numbers, then we would like the word “Forward” in the FW_RV column to appear. We can achieve that by specifying a .default argument again, but this time we want a “word” rather than a value from another column.\n\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  mutate(FW_RV = case_when(\n    Item_number %in% c(2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28) ~ \"Reverse\",\n    .default = \"Forward\"\n  ))\n\nMoving on to correcting the scores: Once again, we can use case_when () within the mutate() function to create another conditional statement. This time, the condition is:\n\nif FW_RV column has a value of “Reverse” then we would like to turn all 1 into 7, 2 into 6, etc.\nif FW_RV column has a value of “Forward” then we would like to keep the score from the Response column\n\nThere is a quick way and a not-so-quick way to achieve the actual reverse-coding.\n\nOption 1 (quick): The easiest way to reverse-code scores is to take the maximum value of the scale, add 1 unit, and subtract the original value. For example, on a 5-point Likert scale, it would be 6 minus the original rating; for a 7-point Likert scale, 8 minus the original rating, etc. (see Option 1 tab).\nOption 2 (not so quick): This involves using two conditional statements (see Option 2 tab).\n\nUse the one you find more intuitive.\n\nOption 1Option 2\n\n\nHere we are using a Boolean expression to check if the string “Reverse” is present in the FW_RV column. If this condition is TRUE, the value in the new column we’re creating, Scores_corrected, will be calculated as 8 minus the value from the Response column. If the condition is FALSE (handled by the .default argument), the original values from the Response column will be retained.\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  mutate(Scores_corrected = case_when(\n    FW_RV == \"Reverse\" ~ 8-Response,\n    .default = Response\n  ))\n\n\n\nAs stated above, the longer approach involves using two conditional statements. The first condition checks if the value in the FW_RV column is “Reverse”, while the second condition checks if the value in the Response column equals a specific number. When both conditions are met, the corresponding value on the right side of the tilde is placed in the newly created Scores_corrected_v2 column.\nFor example, line 3 would read: if the value in the FW_RV column is “Reverse” AND the value in the Response column is 1, then assign a value of 7 to the Scores_corrected_v2 column.\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  mutate(Scores_corrected_v2 = case_when(\n    FW_RV == \"Reverse\" & Response == 1 ~ 7,\n    FW_RV == \"Reverse\" & Response == 2 ~ 6,\n    FW_RV == \"Reverse\" & Response == 3 ~ 5,\n    # no need to recode 4 as 4\n    FW_RV == \"Reverse\" & Response == 5 ~ 3,\n    FW_RV == \"Reverse\" & Response == 6 ~ 2,\n    FW_RV == \"Reverse\" & Response == 7 ~ 1,\n    .default = Response\n  ))\n\nAs you can see now in sats_t1, both columns Scores_corrected and Scores_corrected_v2 are identical.\n\n\n\nOne way to check whether our reverse-coding worked is by examining the distinct values in the original Response column and comparing them with the Scores_corrected. We should also retain the FW_RV column to observe how the reverse-coding applied.\nTo see the patterns more clearly, we can use arrange() to sort the values in a meaningful order. Remember, the default sorting order is ascending, so if you want to sort values in descending order, you’ll need to wrap your variable in the desc() function.\n\ncheck_coding &lt;- sats_t1 %&gt;% \n  distinct(FW_RV, Response, Scores_corrected) %&gt;% \n  arrange(desc(FW_RV), Response)\n\n\n\n\n\n\n\nShow check_coding output\n\n\n\n\n\n\ncheck_coding\n\n\n\n\n\nFW_RV\nResponse\nScores_corrected\n\n\n\n\nReverse\n1\n7\n\n\nReverse\n2\n6\n\n\nReverse\n3\n5\n\n\nReverse\n4\n4\n\n\nReverse\n5\n3\n\n\nReverse\n6\n2\n\n\nReverse\n7\n1\n\n\nForward\n1\n1\n\n\nForward\n2\n2\n\n\nForward\n3\n3\n\n\nForward\n4\n4\n\n\nForward\n5\n5\n\n\nForward\n6\n6\n\n\nForward\n7\n7\n\n\n\n\n\n\n\n\n\n\n\nStep 5\nNow that we know everything worked out as intended, we can calculate the mean scores of each subscale for each participant in sats_t1.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  group_by(???, ???) %&gt;% \n  summarise(mean_score = ???(???)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  group_by(Code, Subscale) %&gt;% \n  summarise(mean_score = mean(Scores_corrected)) %&gt;% \n  ungroup()\n\n`summarise()` has grouped output by 'Code'. You can override using the\n`.groups` argument.\n\n\n\n\n\n\n\n\n\n\nStep 6\nThe final step is to transform the data back into wide format, ensuring that each subscale has its own column. This will make it easier to join the data objects later on. In pivot_wider(), the first argument, names_from, specifies the column you want to use for your new column headings. The second argument, values_from, tells R which column should provide the cell values.\nWe should also rename the column names to match those in the codebook. Conveniently, we can use a function called rename() that works exactly like select() (following the pattern new_name = old_name), but it keeps all other column names the same rather than reducing the number of columns.\n\nsats_t1 &lt;- sats_t1 %&gt;% \n  pivot_wider(names_from = Subscale, values_from = mean_score) %&gt;% \n  rename(SATS28_Affect_Time1_mean = Affect,\n         SATS28_CognitiveCompetence_Time1_mean = CognitiveCompetence,\n         SATS28_Value_Time1_mean = Value,\n         SATS28_Difficulty_Time1_mean = Difficulty)\n\n\n\n\n\n\n\nShow final sats_t1 output\n\n\n\n\n\n\nhead(sats_t1, n = 5)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nSATS28_Affect_Time1_mean\nSATS28_CognitiveCompetence_Time1_mean\nSATS28_Difficulty_Time1_mean\nSATS28_Value_Time1_mean\n\n\n\n\nAD03\n2.333333\n3.833333\n3.428571\n5.555556\n\n\nAD05\n3.500000\n5.000000\n2.142857\n4.777778\n\n\nAb01\n5.166667\n5.666667\n4.142857\n5.444444\n\n\nAl05\n2.166667\n2.666667\n2.857143\n3.777778\n\n\nAm05\n4.166667\n5.666667\n5.571429\n4.888889\n\n\n\n\n\n\n\n\n\nAgain, this could have been written up as a single pipe.\n\n\n\n\n\n\nSingle pipe of activity 4\n\n\n\n\n\n\nsats_t1 &lt;- data_prp %&gt;% \n  # Step 1\n  select(Code, SATS28_1_Affect_Time1:SATS28_28_Difficulty_Time1) %&gt;% \n  # Step 2\n  pivot_longer(cols = -Code, names_to = \"Items\", values_to = \"Response\") %&gt;% \n  # Step 3\n  separate(Items, into = c(NA, \"Item_number\", \"Subscale\", NA), sep = \"_\", convert = TRUE) %&gt;% \n  # step 4\n  mutate(FW_RV = case_when(\n    Item_number %in% c(2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 19, 20, 21, 23, 25, 26, 27, 28) ~ \"Reverse\",\n    .default = \"Forward\"\n  ),\n    Scores_corrected = case_when(\n      FW_RV == \"Reverse\" ~ 8-Response,\n      .default = Response\n  )) %&gt;% \n  # step 5\n  group_by(Code, Subscale) %&gt;% \n  summarise(mean_score = mean(Scores_corrected)) %&gt;% \n  ungroup() %&gt;% \n  # step 6\n  pivot_wider(names_from = Subscale, values_from = mean_score) %&gt;% \n  rename(SATS28_Affect_Time1_mean = Affect,\n         SATS28_CognitiveCompetence_Time1_mean = CognitiveCompetence,\n         SATS28_Value_Time1_mean = Value,\n         SATS28_Difficulty_Time1_mean = Difficulty)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#activity-5-error-mode-perceptions-of-supervisory-support",
    "href": "03-wrangling2.html#activity-5-error-mode-perceptions-of-supervisory-support",
    "title": "3  Data wrangling II",
    "section": "3.5 Activity 5 (Error Mode): Perceptions of supervisory support",
    "text": "3.5 Activity 5 (Error Mode): Perceptions of supervisory support\n\nThe main goal is to compute the mean score for perceived supervisory support per participant.\nLooking at the supervisory support data, you determine that\n\nindividual item columns are numericcharacter, and\naccording to the codebook, there are nosome reverse-coded items in this questionnaire.\n\nI have outlined my steps as follows:\n\nStep 1: Reverse-code the single column first because that’s less hassle than having to do that with conditional statements (Supervisor_15_R). mutate() is my friend.\nStep 2: I want to filter out everyone who failed the attention check in Supervisor_7. I can do this with a Boolean expression within the filter() function. The correct response was “completely disagree” which is 1.\nStep 3: Select their id from time point 2 and all the columns that start with the word “super”, apart from Supervisor_7 and the original Supervisor_15_R column\nStep 4: pivot into long format so I can calculate the averages better\nStep 5: calculate the average scores per participant\n\nI’ve started coding but there are some errors in my code. Help me find and fix all of them. Try to go through the code line by line and read the error messages.\n\nsuper &lt;- data_ppr %&gt;% \n  mutate(Supervisor_15 = 9-supervisor_15_R) %&gt;% \n  filter(Supervisor_7 = 1) %&gt;% \n  select(Code, starts_with(\"Super\"), -Supervisor_7, -Supervisor_15_R) \npivot_wider(cols = -Code, names_to = \"Item\", values_to = \"Response\") %&gt;% \n  group_by(Time2_Code) %&gt;% \n  summarise(Mean_Supervisor_Support = mean(Score_corrected, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\nHow many mistakes am I supposed to find?\n\n\n\n\n\nThere are 8 mistakes in the code.\n\n\n\n\n\n\n\n\n\nReveal solution\n\n\n\n\n\nDid you spot all 8 mistakes? Let’s go through them line by line.\n\nsuper &lt;- data_prp %&gt;% # spelling mistake in data object\n  mutate(Supervisor_15 = 8-Supervisor_15_R) %&gt;% # semantic error: 8 minus response for a 7-point scale and supervisor_15_R needs a capital S\n  filter(Supervisor_7 == 1) %&gt;% # needs a Boolean expression == instead of =\n  select(Code, starts_with(\"Super\"), -Supervisor_7, -Supervisor_15_R) %&gt;% # no pipe at the end, the rest is actually legit\n  pivot_longer(cols = -Code, names_to = \"Item\", values_to = \"Response\") %&gt;% # pivot_longer instead of pivot_wider\n  group_by(Code) %&gt;% # Code rather than Time2_Code - the reduced dataset does not contain Time2_Code\n  summarise(Mean_Supervisor_Support = mean(Response, na.rm = TRUE)) %&gt;% # Score_corrected doesn't exist; needs to be Response\n  ungroup()\n\n\nNote that the semantic error in line 2 will not give you an error message.\nWere you thrown off by the starts_with(\"Super\") expression in line 4? starts_with() and ends_with() are great alternatives to selecting columns via : But, using select(Code, Supervisor_1:Supervisor_6, Supervisor_8:Supervisor_14) would have given us the same result. [I admit, that one was perhaps a bit mean]",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#activity-6-join-everything-together-with-_join",
    "href": "03-wrangling2.html#activity-6-join-everything-together-with-_join",
    "title": "3  Data wrangling II",
    "section": "3.6 Activity 6: Join everything together with ???_join()",
    "text": "3.6 Activity 6: Join everything together with ???_join()\nTime to join all the relevant data files into a single dataframe, which will be used in the next chapters on data visualization. There are four ways to join data: inner_join(), left_join(), right_join(), and full_join(). Each function behaves differently in terms of what information is retained from the two data objects. Here is a quick overview:\n\n\n\n\n\n\nInfo on mutating joins\n\n\n\nYou have 4 types of join functions you could make use of. Click on the panels to know more\n\ninner_join()left_join()right_join()full_join()\n\n\ninner_join() returns only the rows where the values in the column specified in the by = statement match in both tables.\n\n\n\ninner_join(): gif by Garrick Aden-Buie\n\n\n\n\nleft_join() retains the complete first (left) table and adds values from the second (right) table that have matching values in the column specified in the by = statement. Rows in the left table with no match in the right table will have missing values (NA) in the new columns.\n\n\n\nleft_join(): gif by Garrick Aden-Buie\n\n\n\n\nright_join() retains the complete second (right) table and adds values from the first (left) table that have matching values in the column specified in the by = statement. Rows in the right table with no match in the left table will have missing values (NA) in the new columns.\n\n\n\nright_join(): gif by Garrick Aden-Buie\n\n\n\n\nfull_join() returns all rows and all columns from both tables. NA values fill unmatched rows.\n\n\n\nfull_join(): gif by Garrick Aden-Buie\n\n\n\n\n\n\n\nFrom our original data_prp, we need to select demographics data and all summarised questionnaire data from time point 2. Next, we will join this with all other aggregated datasets from time point 1 which are currently stored in separate data objects in the Global Environment.\nWhile you may be familiar with inner_join() from last year, for this task, we want to retain all data from all the data objects. Therefore, we will use full_join(). Keep in mind, you can only join two data objects at a time, so the upcoming code chunk will involve a fair bit of piping and joining.\nNote: Since I (Gaby) like my columns arranged in a meaningful way, I will use select() at the end to order them better.\n\ndata_prp_final &lt;- data_prp %&gt;% \n  select(Code:Plan_prereg, Pre_reg_group:Time2_Understanding_OS) %&gt;% \n  full_join(qrp_t1) %&gt;% \n  full_join(understanding_t1) %&gt;% \n  full_join(sats_t1) %&gt;% \n  full_join(super) %&gt;% \n  select(Code:Plan_prereg, Pre_reg_group, SATS28_Affect_Time1_mean, SATS28_CognitiveCompetence_Time1_mean, SATS28_Value_Time1_mean, SATS28_Difficulty_Time1_mean, QRPs_Acceptance_Time1_mean, Time1_Understanding_OS, Other_OS_behav_2:Time2_Understanding_OS, Mean_Supervisor_Support)\n\n\n\n\n\n\n\nNo by argument in the code above?\n\n\n\nNote how I didn’t include a by argument in the code above. If you leave by = out, R will join the 2 data objects by ALL columns that have the same name.\nSpecial case 1: matching column names but different values\nIf you want more control, you should include the by argument; for example, if both data objects include a column age but data was recorded at 2 different time points. In that case, the information from both age columns should be retained and the by argument would not include age.\nSpecial case 2: different column names but matching values\nAnother special case presents when both data objects contain identical information but the variable names don’t match. Let’s say, both data objects contain gender information, but in one data object the variable is named gender and in the other one gender_label. In that case, your by argument needs to be modified as: by = join_by(gender == gender_label).\nMore info on joins can be found https://www.tidyverse.org/blog/2023/01/dplyr-1-1-0-joins/\n\n\nAnd this is basically the dataset we need for Chapter 4 and Chapter 5.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#activity-7-knit-and-export",
    "href": "03-wrangling2.html#activity-7-knit-and-export",
    "title": "3  Data wrangling II",
    "section": "3.7 Activity 7: Knit and export",
    "text": "3.7 Activity 7: Knit and export\nKnit the .Rmd file to ensure everything runs as expected. Once it does, export the data object data_prp_final as a csv for use in the Chapter 4. Name it something meaningful, something like data_prp_for_ch4.csv.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwrite_csv(data_prp_final, \"data_prp_for_ch4.csv\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "03-wrangling2.html#test-your-knowledge-and-challenge-yourself",
    "href": "03-wrangling2.html#test-your-knowledge-and-challenge-yourself",
    "title": "3  Data wrangling II",
    "section": "Test your knowledge and challenge yourself",
    "text": "Test your knowledge and challenge yourself\n\nKnowledge check\n\nQuestion 1\nWhen using mutate(), which additional function could you use to recode an existing variable? arrange()filter()case_match()case_when()\n\n\nQuestion 2\nWhen using mutate(), which additional function could you use to create a new variable based on one or multiple conditional statements? arrange()filter()case_match()case_when()\n\n\nQuestion 3\nWhich of the following functions would you use if you wanted to join two data sets by their shared identifier? inner_join()left_join()right_join()full_join()\n\n\nQuestion 4\nYour data object contains a column Score with numbers, but they have been read in incorrectly as a character datatype. Which of the following functions would not work for fixing this issue? parse_number()factor(Score)mutate(Score = as.numeric(Score))as.numeric()\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n\nparse_number() from the readr package extracts numeric values from strings, so this would work.\nfactor(Score): This would not work as expected because it converts the column into a factor, not a numeric datatype, leading to incorrect results if numeric operations are needed.\nmutate(Score = as.numeric(Score)): This would work too because mutate() can be used in combination with as.numeric() to create a new numeric column or override the existing character column.\nas.numeric(): This would also work to convert a character column to numeric. Without mutate, you could use it in a BaseR way, e.g., data$Score &lt;- as.numeric(data$Score) (shudder, BaseR!!! But effective)\n\n\n\n\n\n\n\nChallenge yourself\nIf you want to challenge yourself and further apply the skills from Chapter 3, you could wrangle the data from dog_data_raw (lab data) for one of the other questionnaires. There are plenty of options to choose from:\n\n\n\n\n\n\nDifficulty level: easy\n\n\n\n\n\n\nrecode column Live_Pets so the values read yes and no rather than 1 and 2\nrecode Year_of_Study so they have the labels from the codebook rather than the numbers\nreverse-code the Homesickness scale for _pre and _post\nrenaming the columns of the other one-item scales as Stress_pre, Stress_post, Engagement_pre and Engagement_post\n\nAny of these tasks should be doable in one step. No need to select or pivot anything. You could just modify dog_data_raw.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nFor the recoding tasks, you need to work out which function to use to recode one value as another - just plain replacing, no conditional statements\nThe reverse-coding might sound daunting to do in one step, but it is only a single value that needs to be recoded. Take some inspiration from Activity 5 (error mode).\nFor the renaming tasks, check how you would change column names without reducing the number of columns overall\n\n\n\n\n\n\n\n\n\n\nSolution for Challenge yourself - easy\n\n\n\n\n\n\n## Live_Pets\ndog_data_raw &lt;- dog_data_raw %&gt;%\n  mutate(Live_Pets = case_match(Live_Pets,\n                                1 ~ \"yes\",\n                                2 ~ \"no\"))\n\n\n## Year of Study\ndog_data_raw &lt;- dog_data_raw %&gt;%\n  mutate(Year_of_Study = case_match(Year_of_Study,\n                                    1 ~ \"First\",\n                                    2 ~ \"Second\",\n                                    3 ~ \"Third\",\n                                    4 ~ \"Fourth\",\n                                    5 ~ \"Fifth or above\"))\n\n\n## Reverse-coding of homesickness pre and post. It's a 5-point scale, hence you'd calculate 6-the original response column\ndog_data_raw &lt;- dog_data_raw %&gt;% \n  mutate(Homesick_pre = 6-HO1_1,\n         Homesick_post = 6-HO2_1)\n\n\n## Renaming of Stress and Engagement\ndog_data_raw &lt;- dog_data_raw %&gt;% \n  rename(Stress_pre = S1_1, Stress_post = S2_1, Engagement_pre = HO1_2, Engagement_post = HO2_2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifficulty level: medium\n\n\n\n\n\n\nreverse-code the Social connectedness scale (pre-intervention) and compute a mean score per participant\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nThis task would take 4 steps to complete. These are the exact same steps we applied to Loneliness_pre in the lab activity. You would just need to figure out which items are related to the Social connectedness scale (pre-intervention) and which ones of those are reverse-coded. The codebook has all the answers.\n\n\n\n\n\n\n\n\n\nSolution for Challenge yourself - medium\n\n\n\n\n\n\n## SCS pre\nscs_pre &lt;- dog_data_raw %&gt;% \n  select(RID, starts_with(\"SC1\")) %&gt;% \n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %&gt;% \n  mutate(Score_corrected = case_when(\n    Names %in% c(\"SC1_3\", \"SC1_6\", \"SC1_7\", \"SC1_9\", \"SC1_11\", \"SC1_13\", \"SC1_15\", \"SC1_17\", \"SC1_18\", \"SC1_20\") ~ 7-Response,\n    .default = Response\n    )) %&gt;% \n  group_by(RID) %&gt;% \n  summarise(SCS_pre = mean(Score_corrected, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifficulty level: hard\n\n\n\n\n\n\nreverse-code the Loneliness scale (post-intervention) and compute a mean score per participant\nreverse-code the Social connectedness scale (post-intervention) and compute a mean score per participant\n\nBoth activities are similar to Activity 3 from the individual walkthrough and would take about 5 steps to complete. Start by mapping out the steps.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nStep 1: Select all relevant columns, such as participant ID and all the items that belong to the questionnaire that participants completed after the intervention\nStep 2: Pivot the data from wide format to long format so we can reverse-score and calculate the average score more easily\nStep 3: Recode the initial responses so that the new column has numbers instead of labels\nStep 4: Reverse-score the items that are labelled as “Reverse” in the codebook and then reverse-score them\nStep 5: Group by and summarise to calculate the mean Score\n\n\n\n\n\n\n\n\n\n\nSolution for Challenge yourself - hard\n\n\n\n\n\n\n## loneliness post\nlonely_post &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, starts_with(\"L2\")) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %&gt;% \n  # Step 3\n  mutate(Score = case_match(Response,\n                            \"never\" ~ 1,\n                            \"rarely\" ~ 2,\n                            \"sometimes\" ~ 3,\n                            \"often\" ~ 4,\n                            .default = NA\n  ),\n  # Step 4 - we are still in the same mutate function (count the brackets)\n        Score_corrected = case_when(\n          Names %in% c(\"L2_1\", \"L2_5\", \"L2_6\", \"L2_9\", \"L2_10\", \"L2_15\", \"L2_16\", \"L2_19\", \"L2_20\") ~ 5-Score,\n          .default = Score\n  )) %&gt;% \n  # Step 5\n  group_by(RID) %&gt;% \n  summarise(Loneliness_post = mean(Score_corrected, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n## SCS post\nscs_post &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, starts_with(\"SC2\")) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Names\", values_to = \"Response\") %&gt;% \n  # Step 3\n  mutate(Response = case_match(Response,\n                               \"strongly disagree\" ~ \"1\",\n                               \"strongly agree\" ~ \"6\",\n                               .default = Response),\n         Response = parse_number(Response),\n  # Step 4 - we are still in the same mutate function (count the brackets)\n         Score_corrected = case_when(\n           Names %in% c(\"SC2_3\", \"SC2_6\", \"SC2_7\", \"SC2_9\", \"SC2_11\", \"SC2_13\", \"SC2_15\", \"SC2_17\", \"SC2_18\", \"SC2_20\") ~ 7-Response,\n           .default = Response\n         )) %&gt;% \n  # Step 5\n  group_by(RID) %&gt;% \n  summarise(SCS_post = mean(Score_corrected, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDifficulty level: extra hard\n\n\n\n\n\n\nPANAS: positive and negative affect of pre- and post-intervention in a single pipe rather than in 4 different data objects (see last week’s)\n\nThis task would take about 7 steps to get it from\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRID\nPN1_1\nPN1_2\nPN1_3\nPN1_4\nPN1_5\nPN1_6\nPN1_7\nPN1_8\nPN1_9\nPN1_10\nPN2_1\nPN2_2\nPN2_3\nPN2_4\nPN2_5\nPN2_6\nPN2_7\nPN2_8\nPN2_9\nPN2_10\n\n\n\n\n1\n1\n1\n1\n1\n4\n1\n4\n3\n1\n4\n2\n1\n3\n1\n4\n1\n4\n4\n1\n4\n\n\n2\n1\n2\n3\n2\n1\n3\n3\n4\n1\n4\n1\n1\n2\n1\n3\n1\n3\n4\n1\n4\n\n\n3\n1\n1\n3\n1\n2\n4\n4\n3\n1\n2\n2\n2\n3\n1\n3\n2\n4\n3\n1\n2\n\n\n4\n1\n1\n5\n1\n4\n3\n5\n5\n3\n2\n1\n1\n5\n1\n4\n3\n4\n4\n2\n2\n\n\n5\n2\n3\n5\n2\n3\n2\n3\n4\n2\n2\n1\n2\n5\n2\n3\n2\n4\n5\n1\n3\n\n\n\n\n\n\nto\n\n\n\n\n\n\nRID\nStage\nPANAS_NA\nPANAS_PA\n\n\n\n\n1\npost\n1.2\n3.8\n\n\n1\npre\n1.0\n3.2\n\n\n2\npost\n1.0\n3.2\n\n\n2\npre\n1.8\n3.0\n\n\n3\npost\n1.6\n3.0\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\nStart by mapping out the steps\n\nStep 1: select all relevant columns, such as participant ID and all the items that belong to PANAs scale (pos, neg, pre, and post)\nStep 2: pivot the data from wide format to long format. You want to do that for ALL columns that are not the participant id. The data object should have 3 columns and 5680 observations, i.e. each participant has 20 rows.\nStep 3: All of the items will have the structure PN1_1. Use separate to split the information across 2 columns. First column has information about the Stage, second column should turn into an Item_number and it should convert into a numeric column in the process to save you typing quotation marks in Step 5.\n\nStep 4: recode the Stage column you just created so that everything that starts with PN1 relates to “pre” and PN2 as post.\nStep 5: identify the subscales positive affect (PA) and negative affect (NA) by item number and recode them. This requires a conditional statement.\nStep 6: group by and summarise to calculate the mean Score\nStep 7: pivot, so that you have the 2 PANAS subscales presented in separate columns (see table above). You might need an extra step if the columns aren’t labelled exactly as shown in the table above.\n\n\n\n\n\n\n\n\n\n\nSolution for Challenge yourself - extra hard\n\n\n\n\n\n\nPANAS &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, starts_with(\"PN\")) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Items\", values_to = \"Scores\") %&gt;% \n  # Step 3\n  separate(Items, into = c(\"Stage\", \"Item_number\"), sep = \"_\", convert = TRUE) %&gt;% \n  # Step 4 recode Stage\n  mutate(Stage = case_match(Stage,\n                            \"PN1\" ~ \"pre\",\n                            \"PN2\" ~ \"post\")) %&gt;% \n  # Step 5 identify subscales by item number\n  mutate(Subscales = case_when(\n    Item_number %in% c(3, 5, 7, 8, 10) ~ \"PANAS_PA\",\n    .default = \"PANAS_NA\"\n  )) %&gt;% \n  # Step 6 \n  group_by(RID, Stage, Subscales) %&gt;% \n  summarise(Score = mean(Scores)) %&gt;% \n  ungroup() %&gt;% \n  # Step 7 - to make the data look like the data in `dog_data_clean_long.csv`\n  pivot_wider(names_from = Subscales, values_from = Score)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data wrangling II</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html",
    "href": "04-dataviz.html",
    "title": "4  Data viz I",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter, you should be able to:\nIt is time to think about selecting the most appropriate plot for your data. Different types of variables call for different kinds of plots, which depends on how many variables you’re aiming to plot and what their data types are. In this chapter, we will focus on plots for categorical data. Next week, we will explore plots for continuous variables and learn which plots work best when combining continuous and categorical data.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#intended-learning-outcomes",
    "href": "04-dataviz.html#intended-learning-outcomes",
    "title": "4  Data viz I",
    "section": "",
    "text": "explain the layered grammar of graphics\nchoose an appropriate plot for categorical variables\ncreate a basic version of an appropriate plot\napply additional layers to modify the appearance of the plot",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#individual-walkthrough",
    "href": "04-dataviz.html#individual-walkthrough",
    "title": "4  Data viz I",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#building-plots",
    "href": "04-dataviz.html#building-plots",
    "title": "4  Data viz I",
    "section": "Building plots",
    "text": "Building plots\nWe are using the package ggplot2 to create data visualisations. It’s part of the tidyverse package. Actually, most people call th package ggplot but it’s official name is ggplot2.\nWe’ll be using the ggplot2 package to create data visualisations. It’s part of the tidyverse suite of packages. Although many people refer to it simply as ggplot, its official name is ggplot2.\n\n\nggplot2 uses a layered grammar of graphics, where plots are constructed through a series of layers. You start with a base layer (by calling ggplot), then add data and aesthetics, followed by selecting the appropriate geometries for the plot.\nThese first 3 layers will give you the most simple version of a complete plot. However, you can enhance the plot’s clarity and appearance by adding additional layers such as scales, facets, coordinates, labels and themes.\n\n\n\n\n\ngg layers (Presentation by Ryan Safner)\n\n\n\n\nTo give you a brief overview of the layering system, we will use the palmerpenguins package (https://allisonhorst.github.io/palmerpenguins/). This dataset contains information about penguins, including bill length and depth, flipper length, body mass, and more.\n\nhead(penguins)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\nAdelie\nTorgersen\n39.1\n18.7\n181\n3750\nmale\n2007\n\n\nAdelie\nTorgersen\n39.5\n17.4\n186\n3800\nfemale\n2007\n\n\nAdelie\nTorgersen\n40.3\n18.0\n195\n3250\nfemale\n2007\n\n\nAdelie\nTorgersen\nNA\nNA\nNA\nNA\nNA\n2007\n\n\nAdelie\nTorgersen\n36.7\n19.3\n193\n3450\nfemale\n2007\n\n\nAdelie\nTorgersen\n39.3\n20.6\n190\n3650\nmale\n2007\n\n\n\n\n\n\nLet’s build a basic scatterplot to show the relationship between flipper_length and body_mass. We will customise plots further later on in the individual plots. This is just a quick overview of the different layers.\nLet’s build a basic scatterplot to show the relationship between flipper_length and body_mass. We will further customise the plots in subsequent sections, but for now, this will provide a quick overview of the different layers.\n\nLayer 1 creates the base plot that we build upon.\nLayer 2 adds the data and some aesthetics:\n\nThe data is passed as the first argument.\nAesthetics are added via the mapping argument, where you define your variables (e.g., x or both x and y). This also allows you to specify general properties, like the color for grouping variables, etc.\n\nLayer 3 adds geometries, or geom_? for short. This tells ggplot how to display the data points. Remember to add these layers with a +, rather than using a pipe (%&gt;%). You can also add multiple geoms if needed, for example, combining a violin plot with a boxplot.\nLayer 4 includes scale_? functions, which let you customise aesthetics like color. You can do much more with scales, but we’ll explore later.\nLayer 5 introduces facets, such as facet_wrap(), allowing you to add an extra dimension to your plot by showing the relationship you are interested in for each level of a categorical variable.\nLayer 6 involves coordinates, where coord_cartesian() controls the limits for the x- and y-axes (xlim and ylim), enabling you to zoom in or out of the plot.\nLayer 7 helps you modify axis labels.\nLayer 8 controls the overall style of the plot, including background color, text size, and borders. R provides several predefined themes, such as theme_classic, theme_bw, theme_minimal, and theme_light.\n\nClick on the tabs below to see how each layer contributes to refining the plot.\n\nLayer 1Layer 2Layer 3Layer 4Layer 5Layer 6Layer 7Layer 8\n\n\n\nggplot()\n\n\n\n\n\n\n\n\nThere’s not much to see at this stage - this is basically an empty plot layer.\n\n\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm))\n\n\n\n\n\n\n\n\nYou won’t see any data points yet because we haven’t specified how to display them. However, we have mapped the aesthetics, indicating that we want to plot body_mass on the x-axis and flipper_length on the y-axis. This also sets the axis titles, as well as the axis values and breakpoints.\n\n\n\n\n\n\nTip\n\n\n\nYou won’t need to add data = or mapping = if you keep those arguments in exactly that order. Likewise, the first column name you enter within the aes() function will always be interpreted as x, and the second as y, so you could omit them if you wish.\nYou don’t need to include data = or mapping = if you keep those arguments in the default order. Similarly, the first column name you enter in the aes() function will automatically be interpreted as the x variable, and the second as y, so you can omit specifying x and y if you prefer.\n\nggplot(penguins, aes(body_mass_g, flipper_length_mm))\n\nwill give you the same output as the code above.\n\n\n\n\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm, colour = sex)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHere we are telling ggplot to add a scatterplot. You may notice a warning indicating that some rows were removed due to missing values.\nThe colour argument adds colour to the points based on a grouping variable (in this case, sex). If you want all the points to be black — representing only two dimensions rather than three — simply omit the colour argument.\n\n\n\nggplot(data = penguins, mapping = aes(x = body_mass_g, y = flipper_length_mm, colour = sex)) +\n  geom_point() +\n  # changes colour palette\n  scale_colour_brewer(palette = \"Dark2\") + \n  # add breaks from 2500 to 6500 in increasing steps of 500\n  scale_x_continuous(breaks = seq(from = 2500, to = 6500, by = 500)) \n\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe scale_? functions allow us to modify the color palette of the plot, adjust axis breaks, and more. You could change the axis labels within scale_x_continuous() as well or leave it for Layer 7.\n\n\n\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  # split main plot up into different subplots by species \n  facet_wrap(~ species) \n\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIn this step, we’re using faceting to split the plot by species.\n\n\n\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  facet_wrap(~ species) +\n  # limits the range of the y axis\n  coord_cartesian(ylim = c(0, 250)) \n\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nHere we adjust the limits of the y-axis to zoom out of the plot. If you want to zoom in or out of the x-axis, you can add the xlim argument to the coord_cartesian() function.\n\n\n\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  facet_wrap(~ species) +\n  labs(x = \"Body Mass (in g)\", # labels the x axis\n       y = \"Flipper length (in mm)\", # labels the y axis\n       colour = \"Sex\") # labels the grouping variable in the legend\n\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nYou can change the axis labels using the labs() function, or you can modify them when adjusting the scales (e.g., within the scale_x_continuous() function).\n\n\n\nggplot(data = penguins, mapping = aes(x=body_mass_g, y=flipper_length_mm, colour=sex)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\") + \n  facet_wrap(~ species) +\n  labs(x = \"Body Mass (in g)\", \n       y = \"Flipper length (in mm)\",\n       colour = \"Sex\") +\n  # add a theme\n  theme_classic()\n\nWarning: Removed 11 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe theme_classic() function is applied to change the overall appearance of the plot.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nYou need to stick to the first three layers to create your base plot. Everything else is optional, meaning you don’t need to use all eight layers. Additionally, layers 4-8 can be added in any order (more or less), whereas layers 1-3 must follow a fixed sequence.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#activity-1-set-up-and-data-for-today",
    "href": "04-dataviz.html#activity-1-set-up-and-data-for-today",
    "title": "4  Data viz I",
    "section": "4.1 Activity 1: Set-up and data for today",
    "text": "4.1 Activity 1: Set-up and data for today\n\nWe are still working with the data from Pownall et al. (2023), so open your project.\nHowever, let’s start with a fresh R Markdown file: Create a new .Rmd file and save it in your project folder. Give it a meaningful name (e.g., “chapter_04.Rmd” or “04_data_viz.Rmd”). If you need guidance, refer to Section 1.3. Delete everything below line 12, but keep the setup code chunk.\nWe previously aggregated the data in Chapter 2 and Chapter 3. If you want a fresh copy, download the data here: data_prp_for_ch4.csv. Make sure to place the csv file in the project folder.\nIf you need a reminder about the data and variables, check the codebook or refer back to Section 1.4.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#activity-2-load-in-libraries-read-in-data-and-adjust-data-types",
    "href": "04-dataviz.html#activity-2-load-in-libraries-read-in-data-and-adjust-data-types",
    "title": "4  Data viz I",
    "section": "4.2 Activity 2: Load in libraries, read in data, and adjust data types",
    "text": "4.2 Activity 2: Load in libraries, read in data, and adjust data types\nToday, we will be using the tidyverse package and the dataset data_prp_for_ch4.csv.\n\n## packages \n???\n\n## data\ndata_prp_viz &lt;- read_csv(???)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\ndata_prp_viz &lt;- read_csv(\"data_prp_for_ch4.csv\")\n\n\n\n\nAs mentioned in Section 1.6, it is always a good idea to take a glimpse at the data to see how many variables and observations are in the dataset, as well as the data types.\n\n\n\n\n\n\nglimpse output\n\n\n\n\n\n\nglimpse(data_prp_viz)\n\nRows: 89\nColumns: 28\n$ Code                                  &lt;chr&gt; \"Tr10\", \"Bi07\", \"SK03\", \"SM95\", …\n$ Gender                                &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2,…\n$ Age                                   &lt;dbl&gt; 22, 20, 22, 26, 22, 20, 21, 21, …\n$ Ethnicity                             &lt;chr&gt; \"White European\", \"White British…\n$ Secondyeargrade                       &lt;dbl&gt; 2, 3, 1, 2, 2, 2, 2, 2, 1, 1, 1,…\n$ Opptional_mod                         &lt;dbl&gt; 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,…\n$ Opptional_mod_1_TEXT                  &lt;chr&gt; \"Research methods in first year\"…\n$ Research_exp                          &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,…\n$ Research_exp_1_TEXT                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Plan_prereg                           &lt;dbl&gt; 1, 3, 1, 2, 1, 1, 3, 3, 2, 2, 2,…\n$ Pre_reg_group                         &lt;dbl&gt; 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2,…\n$ SATS28_Affect_Time1_mean              &lt;dbl&gt; 4.000000, 3.833333, 5.000000, 5.…\n$ SATS28_CognitiveCompetence_Time1_mean &lt;dbl&gt; 5.166667, 5.166667, 5.666667, 4.…\n$ SATS28_Value_Time1_mean               &lt;dbl&gt; 6.000000, 6.666667, 5.222222, 5.…\n$ SATS28_Difficulty_Time1_mean          &lt;dbl&gt; 3.571429, 2.428571, 3.571429, 3.…\n$ QRPs_Acceptance_Time1_mean            &lt;dbl&gt; 5.909091, 6.090909, 6.545455, 5.…\n$ Time1_Understanding_OS                &lt;dbl&gt; 5.500000, 3.166667, 4.500000, 3.…\n$ Other_OS_behav_2                      &lt;dbl&gt; 1, NA, NA, NA, 1, NA, NA, 1, NA,…\n$ Other_OS_behav_4                      &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, NA, N…\n$ Other_OS_behav_5                      &lt;dbl&gt; NA, NA, NA, NA, 1, 1, NA, NA, NA…\n$ Closely_follow                        &lt;dbl&gt; 2, 2, 2, NA, 3, 3, 3, NA, NA, 2,…\n$ SATS28_Affect_Time2_mean              &lt;dbl&gt; 3.500000, 3.166667, 4.833333, 4.…\n$ SATS28_CognitiveCompetence_Time2_mean &lt;dbl&gt; 4.166667, 4.666667, 6.166667, 5.…\n$ SATS28_Value_Time2_mean               &lt;dbl&gt; 3.000000, 6.222222, 6.000000, 4.…\n$ SATS28_Difficulty_Time2_mean          &lt;dbl&gt; 2.857143, 2.857143, 4.000000, 2.…\n$ QRPs_Acceptance_Time2_mean            &lt;dbl&gt; 5.636364, 5.454545, 6.272727, 5.…\n$ Time2_Understanding_OS                &lt;dbl&gt; 5.583333, 3.333333, 5.416667, 4.…\n$ Mean_Supervisor_Support               &lt;dbl&gt; 5.230769, 6.285714, 6.857143, 2.…\n\n\n\n\n\nWe can see that some of the categorical data in data_prp_viz was read in as numeric variables which makes them continuous. This will haunt us big time when building the plots. We would be better off addressing these changes in the dataset before we start plotting (and potentially getting frustrated with R and data viz in general).\nLet’s convert some of the categorical variables into factors. We’ll use the factor() function, which requires the variable to convert, the levels (where we can re-order them as needed), and the corresponding labels.\n\ndata_prp_viz &lt;- data_prp_viz %&gt;% \n  mutate(Gender = factor(Gender,\n                         levels = c(2, 1, 3),\n                         labels = c(\"females\", \"males\", \"non-binary\")),\n         Secondyeargrade = factor(Secondyeargrade,\n                                  levels = c(1, 2, 3, 4, 5),\n                                  labels = c(\"≥ 70% (1st class grade)\", \"60-69% (2:1 grade)\", \"50-59% (2:2 grade)\", \"40-49% (3rd class)\", \"&lt; 40%\")),\n         Plan_prereg = factor(Plan_prereg,\n                              levels = c(1, 3, 2),\n                              labels = c(\"Yes\", \"Unsure\", \"No\")),\n         Closely_follow = factor(Closely_follow,\n                                 levels = c(2, 3),\n                                 labels = c(\"Followed it somewhat\", \"Followed it exactly\")),\n         Research_exp = factor(Research_exp),\n         Pre_reg_group = factor(Pre_reg_group))",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#activity-3-barchart-geom_bar",
    "href": "04-dataviz.html#activity-3-barchart-geom_bar",
    "title": "4  Data viz I",
    "section": "4.3 Activity 3: Barchart (geom_bar())",
    "text": "4.3 Activity 3: Barchart (geom_bar())\nA barchart is the best choice when you want to plot a single categorical variable.\nFor example, let’s say we want to count some demographic data, such as gender. To visualise the gender counts, we would use a barplot. This is done with geom_bar() in the third layer. Since the counting is done automatically in the background, the aes() function only requires an x value (i.e., the name of your variable).\n\nggplot(data_prp_viz, aes(x = Gender)) +\n  geom_bar() \n\n\n\n\n\n\n\nFigure 4.1: Default barchart\n\n\n\n\n\nThis is the base plot done. You can customise it by adding different layers. For example, the labels could be clearer, or you might want to add a splash colour. Click on the tabs below to see examples of additional customisations, and try applying them to your base plot in your own .Rmd file.\n\nColourAxes labels & marginsLegendThemes\n\n\nWe can change the colour by adding a fill argument in the aes(). If we want to modify these colours further, we would add a scale_fill_? argument. If you have specific colours in mind, you would use scale_fill_manual(), or if you prefer to stick with pre-defined options like viridis, you can use scale_fill_viridis_d().\n\nggplot(data_prp_viz, aes(x = Gender, fill = Gender)) +\n  geom_bar() +\n  # customise colour\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\n\nThe x-axis label is fine, but the categories need to be relabelled. You can achieve this with the scale_x_discrete() function and the labels = argument. Just make sure to order the labels according to the order in the dataframe.\nThere is also a gap between the bottom of the chart and the bars that looks a bit odd. You can remove it by using the expansion() function.\n\nggplot(data_prp_viz, aes(x = Gender, fill = Gender)) +\n  geom_bar() +\n  scale_fill_viridis_d() +\n  # changing group labels on the breaks of the x axis\n  scale_x_discrete(labels = c(\"Female\", \"Male\", \"Non-Binary\")) + \n  scale_y_continuous(\n    # changing name of the y axis\n    name = \"Count\",\n    # remove the space below the bars (first number), but keep a tiny bit (5%) above (second number)\n    expand = expansion(mult = c(0, 0.05))\n  )\n\n\n\n\n\n\n\n\n\n\nThe legend does not add any useful information because the labels are already provided on the x-axis. We can remove the legend by adding the argument guide = \"none\" to the scale_fill function.\n\nggplot(data_prp_viz, aes(x = Gender, fill = Gender)) +\n  geom_bar() +\n  scale_fill_viridis_d(\n    # remove the legend\n    guide = \"none\") +\n  scale_x_discrete(labels = c(\"Female\", \"Male\", \"Non-Binary\")) +\n  scale_y_continuous(\n    name = \"Count\",\n    expand = expansion(mult = c(0, 0.05))\n  )\n\n\n\n\n\n\n\n\n\n\nLet’s experiment with the themes. For this plot we have chosen theme_minimal().\n\nggplot(data_prp_viz, aes(x = Gender, fill = Gender)) +\n  geom_bar() +\n  scale_fill_viridis_d(\n    guide = \"none\") +\n  scale_x_discrete(labels = c(\"Female\", \"Male\", \"Non-Binary\")) +\n  scale_y_continuous(\n    name = \"Count\",\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  # pick a theme\n  theme_minimal()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#activity-4-column-plot-geom_col",
    "href": "04-dataviz.html#activity-4-column-plot-geom_col",
    "title": "4  Data viz I",
    "section": "4.4 Activity 4: Column plot (geom_col())",
    "text": "4.4 Activity 4: Column plot (geom_col())\nIf the counts had already been summarised for you, geom_bar() would not work. Instead, you’d need to use geom_col() to display the pre-aggregated data.\n\ngender_count &lt;- data_prp_viz %&gt;% \n  count(Gender)\n\ngender_count\n\n\n\n\n\nGender\nn\n\n\n\n\nfemales\n69\n\n\nmales\n17\n\n\nnon-binary\n3\n\n\n\n\n\n\nThe mapping for geom_col() requires both x and y aesthetics. In this example, x would represent the categorical variable (e.g., Gender), while y would refer to the column storing the summarised values (e.g., n). Notice how the axis title now reflects n instead of count in the base version.\n\nggplot(gender_count, aes(x = Gender, y = n, fill = Gender)) +\n  geom_col()\n\n\n\n\n\n\n\nFigure 4.2: Column plot with different coloured bars\n\n\n\n\n\n\n\n\n\n\n\nYour Turn: Make the column plot pretty\n\n\n\nThe other layers to change the colour scheme, axes labels and margins, removing the legend and altering the theme require exactly the same functions as with the boxplot above. Test yourself to see if you can…\n\nchange the colour scheme (e.g., viridis or any other colour palettes)\nremove the legend\nchange the titles of the x and y axes\nmake the bars start directly on the x-axis\nadd a theme of your liking\n\n\n\n\n\n\n\nPossible solution code for the column plot (with a different colour palette and a different theme)\n\n\n\n\n\n\nggplot(gender_count, aes(x = Gender, y = n, fill = Gender)) +\n  geom_col() +\n  # replaced vidiris with the brewer palette\n  scale_fill_brewer(\n    palette = \"Set1\", # try \"Set2\" or \"Dark2\" for some variety\n    guide = \"none\") + # legend removed\n  # labels of the categories changed\n  scale_x_discrete(labels = c(\"Male\", \"Female\", \"Non-Binary\")) + \n  scale_y_continuous(\n    # change y axis label\n    name = \"Count\",\n    # starts bars on x axis without any gaps but leaves some space at the top (this time 10%)\n    expand = expansion(mult = c(0, 0.1)) \n  ) +\n  # different theme\n  theme_light()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#sec-adv_bar",
    "href": "04-dataviz.html#sec-adv_bar",
    "title": "4  Data viz I",
    "section": "4.5 Activity 5: Stacked, Percent Stacked, and Grouped Barchart",
    "text": "4.5 Activity 5: Stacked, Percent Stacked, and Grouped Barchart\nWhen dealing with two categorical variables, you have three options for displaying stacked barcharts: the “normal” Stacked Barchart (the default option), a Percent Stacked Barchart, or a Grouped Barchart.\nFor this activity, we will explore the variable Plan_prereg, which measures whether students planned to pre-register their undergraduate dissertation at time point 1, and Pre_reg_group, which tracks whether they actually followed through with a pre-registration for their dissertation.\nOne way to display this data is by creating either a Stacked Barchart (the default) or a Percent Stacked Barchart. In both cases, the subgroups are displayed on top of each other. To make comparison easier, we will place the two plots side by side and move the legend to the bottom of the chart.\n\n## Stacked barchart\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Pre_reg_group)) +\n  geom_bar() + # no position argument added\n  theme(legend.position = \"bottom\") # move legend to the bottom\n\n## Percent stacked barchart\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Pre_reg_group)) +\n  geom_bar(position = \"fill\") + # add position argument here\n  theme(legend.position = \"bottom\") # move legend to the bottom\n\n\n\n\n\n\n\n\n\nFigure 4.3: Stacked barchart (left), and Percent stacked barchart (right)\n\n\n\n\n\nIn the stacked barchart (Figure 4.3, left plot), you can display participant numbers. From this, we can see that the highest number of students were unsure whether they wanted to pre-register their dissertation, followed closely by those who answered “yes.” We also see that the number of students who did not end up with a pre-registered dissertation (blue category) is the same for both those who had planned to pre-register and those who did not want to. However, since the “No” category has significantly fewer participants than the other two, it’s difficult to tell if the ratio remains consistent across all three groups.\nIf we want to highlight this ratio, a Percent Stacked Barchart (Figure 4.3, right plot) would be more appropriate. This plot shows that approximately 80% of the students who had planned to pre-register their dissertations, 50% of the students who were initially unsure, and only 33% of the students who had no plan to pre-register ended up with a pre-registered dissertation. BUT! We would lose the information about the raw values in the sample.\nIt’s all a trade-off, and the plot you choose depends on the “story” you want the data to tell.\n\n\n\n\n\n\nNote\n\n\n\nThe position argument position = \"stack\" is the default. Adding this argument to the code for the left plot in Figure 4.3 would produce the same plot as leaving the argument out.\n\n\nThe other option is a Grouped Barchart, which displays the bars next to each other. You can achieve this by changing the position argument to \"dodge\". You can see the default version of the plot in Figure 4.4 on the left, and one with additional layers on the right.\nInstead of using a pre-existing colour palette, we manually changed the colours using hex codes. These are some of the colours Gaby used in her PhD thesis, but you can:\n\ncreate your own colour hex codes by using this website, OR\nuse pre-defined colour names like “green” or “purple” instead. See a full list here.\n\nFeel free to explore.\nSince the legend title for the second plot is a bit long, we displayed the legend content across two rows by adding the layer guides(fill = guide_legend(nrow = 2)) at the end.\n\n## Default grouped barchart\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Pre_reg_group)) +\n  geom_bar(position = \"dodge\") + # add position argument here\n  theme(legend.position = \"bottom\") # move legend to the bottom\n\n## Prettier grouped barchart\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Pre_reg_group)) +\n  geom_bar(position = \"dodge\") + # add position argument here\n  # changing labels for x, y, and fill category - alternative method\n  labs(x = \"Pre-registration planned\", y = \"Count\", fill = \"Pre-registered dissertation\") +\n  # manual colour change for values\n  scale_fill_manual(values = c('#648FFF', '#DC267F'),\n                    labels = c(\"Yes\", \"No\")) +\n  scale_y_continuous(\n    # remove the space below the bars, but keep a tiny bit (5%) above\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  # pick a theme\n  theme_classic() + \n  # need to move this following line to the end otherwise the `theme_*` overrides it\n  theme(legend.position = \"bottom\") + \n  # display across 2 rows\n  guides(fill = guide_legend(nrow = 2))\n\n\n\n\n\n\n\n\n\nFigure 4.4: Default grouped barchart (left) and one with a few more layers added (right)\n\n\n\n\n\n\n\n\n\n\n\nSpecial case: Categorical variables with missing values\n\n\n\n\n\nIf we had chosen a different categorical variable that contains missing values, such as Closely_follow, our plots would have included those missing values by default. To change the colour of the missing value bars, you would need to specify this using the na.value = argument within the scale_fill() function. Here’s an example of a grouped barchart.\n\n# default grouped barchart with missing values\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Closely_follow)) +\n  geom_bar(position = \"dodge\") + \n  theme(legend.position = \"bottom\") + \n  guides(fill = guide_legend(nrow = 3)) # display across 3 rows\n\n## Prettier grouped barchart with missing values\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Closely_follow)) +\n  geom_bar(position = \"dodge\") + \n  labs(x = \"Pre-registration planned\", y = \"Count\", fill = \"Pre-registration followed\") +\n  # manual colour change for values of the factor and the NA responses\n  scale_fill_manual(values = c('#648FFF', '#DC267F'), na.value = '#FFB000') +\n  scale_y_continuous(\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  theme_classic() + \n  theme(legend.position = \"bottom\") + \n  guides(fill = guide_legend(nrow = 3)) # display across 3 rows\n\n\n\n\n\n\n\n\n\nFigure 4.5: Default grouped barchart (left) and one with a few more layers added (right) for a variable with missing values\n\n\n\n\n\nIf you don’t want the missing values to appear in the plot, you will need to do some data wrangling to remove them first. The function for this is drop_na(). Here we applied drop_na() to Closely_follow only.\n\n# remove NA\nprereg_plan_follow &lt;- data_prp_viz %&gt;% \n  select(Code, Plan_prereg, Closely_follow) %&gt;% \n  drop_na(Closely_follow)\n\n\n\n\n\n\n\ncheck NAs have been removed\n\n\n\n\n\n\n# check NA have been removed\nprereg_plan_follow %&gt;% \n  distinct(Plan_prereg, Closely_follow) %&gt;% \n  arrange(Plan_prereg, Closely_follow)\n\n\n\n\n\nPlan_prereg\nClosely_follow\n\n\n\n\nYes\nFollowed it somewhat\n\n\nYes\nFollowed it exactly\n\n\nUnsure\nFollowed it somewhat\n\n\nUnsure\nFollowed it exactly\n\n\nNo\nFollowed it somewhat\n\n\nNo\nFollowed it exactly\n\n\n\n\n\n\n\n\n\nBut keep in mind that it could misrepresent the data, e.g., giving a wrong impression about proportions. As a comparison…\n\n# with NA\nggplot(data_prp_viz, aes(x = Plan_prereg, fill = Closely_follow)) +\n  geom_bar(position = \"fill\") + # add position argument here\n  theme(legend.position = \"bottom\") + # move legend to the bottom\n  guides(fill = guide_legend(nrow = 2)) # display across 2 rows\n\n# without NA\nggplot(prereg_plan_follow, aes(x = Plan_prereg, fill = Closely_follow)) +\n  geom_bar(position = \"fill\") + # add position argument here\n  theme(legend.position = \"bottom\") + # move legend to the bottom\n  guides(fill = guide_legend(nrow = 2)) # display across 2 rows\n\n\n\n\n\n\n\n\n\nFigure 4.6: Percent stacked barchart with (left) and without missing values (right)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#activity-6-save-your-plots",
    "href": "04-dataviz.html#activity-6-save-your-plots",
    "title": "4  Data viz I",
    "section": "4.6 Activity 6: Save your plots",
    "text": "4.6 Activity 6: Save your plots\nYou can save your figures using the ggsave() function, which will save them to your project folder.\nThere are two ways to use ggsave(). If you don’t specify which plot to save, by default it will save the last plot you created. In our case, the last plot was the one without NA from the special case scenario (Figure 4.6). However, if you did not follow along with the special case scenario, your last plot will be the grouped bar chart on the right from Figure 4.4.\n\nggsave(filename = \"last_plot.png\")\n\n\n\n\n\n\n\nOur last plot saved\n\n\n\n\n\n\n\n\n\nThe second option is to save the plot as an object and refer to the object within ggsave(). As an example, let’s save the grouped barchart that contained missing values (Figure 4.4) as an object called grouped_bar.\nThe second option is to save the plot as an object and then refer to that object within ggsave(). For example, let’s save the grouped barchart that contained missing values (Figure 4.4) as an object called grouped_bar.\n\ngrouped_bar &lt;- ggplot(data_prp_viz, aes(x = Plan_prereg, fill = Closely_follow)) +\n  geom_bar(position = \"dodge\") + \n  labs(x = \"Pre-registration planned\", y = \"Count\", fill = \"Pre-registration followed\") +\n  # manual colour change for values of the factor and the NA responses\n  scale_fill_manual(values = c('#648FFF', '#DC267F'), na.value = '#FFB000') +\n  scale_y_continuous(\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  theme_classic() + \n  theme(legend.position = \"bottom\") + \n  guides(fill = guide_legend(nrow = 3)) # display across 3 rows\n\nThen, you can run the following line:\n\nggsave(filename = \"grouped_bar.png\", \n       plot = grouped_bar)\n\n\n\nSaving 7 x 5 in image\n\n\nThe filename is the name you want your PNG file to have, and plot refers to the name of the plot object.\n\n\n\n\n\n\nOur saved grouped_bar.png would look like this:\n\n\n\n\n\n\n\n\n\nThis is the plot saved with the default settings. If you like it, feel free to keep it as is. However, if it seems a bit “off”, you can adjust the width, height, and units (e.g., “cm”, “mm”, “in”, “px”). You might need to experiment with the dimensions until it feels about right.\n\nggsave(filename = \"grouped_bar2.png\", \n       plot = grouped_bar, \n       width = 16, height = 9, units = \"cm\")\n\n\n\n\n\n\n\ngrouped_bar.png with different dimensions",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "04-dataviz.html#test-your-knowledge",
    "href": "04-dataviz.html#test-your-knowledge",
    "title": "4  Data viz I",
    "section": "Test your knowledge",
    "text": "Test your knowledge\nLet’s go back to the palmerpenguins package (https://allisonhorst.github.io/palmerpenguins/), and assume you have the following data available:\n\nlibrary(palmerpenguins)\n\npenguin_selection &lt;- penguins %&gt;% \n  group_by(species, island) %&gt;% \n  summarise(penguin_count = n())\n\npenguin_selection\n\n\n\n\n\nspecies\nisland\npenguin_count\n\n\n\n\nAdelie\nBiscoe\n44\n\n\nAdelie\nDream\n56\n\n\nAdelie\nTorgersen\n52\n\n\nChinstrap\nDream\n68\n\n\nGentoo\nBiscoe\n124\n\n\n\n\n\n\n\nKnowledge check\n\nQuestion 1\nWhat geom would you use to plot penguin count for each species? geom_bargeom_col\n\n\nQuestion 2\nWhat mapping would you use to display penguin count across species?\n\n aes(x = penguin_count, y = species) aes(x = species, y = penguin_count) aes(x = species) aes(x = penguin_count)\n\n\n\nQuestion 3\nWhat geom would you use to count the number of species on each island? geom_bargeom_col\n\n\nQuestion 4\nWhat mapping would you use to display the count of species per island?\n\n aes(x = island, y = species) aes(x = species, y = island) aes(x = island) aes(x = species)\n\n\n\n\n\n\n\nExplain these answers\n\n\n\n\n\nQuestion 1: geom_col() is the appropriate choice for bar charts with predefined y-values, such as penguin_count.\nQuestion 2: The correct aesthetic mapping places the categorical variable (species) on the x-axis and the numeric variable (number of observed penguins) on the y-axis. Using aes(x = penguin_count, y = species) would flip the axes, placing the number of penguins on the x-axis and species on the y-axis, which doesn’t match the conventional structure of a bar chart.\nQuestion 3: geom_bar() is the appropriate choice when you want to automatically count the number of observations within each category, such as counting the number of penguin species on each island.\nQuestion 4: For a simple count of species per island, you only need to map the categorical variable (island) to the x-axis. The y-axis will automatically represent counts when using geom_bar().\n\n\n\n\n\n\nError mode\nSome of the code chunks contain mistakes and result in errors, while others do not produce the expected results. Your task is to identify any issues, explain why they occurred, and, if possible, fix them.\n\nQuestion 5\nWe want to plot the number of penguins across the different islands.\n\nggplot(penguins, aes(x = islands)) +\n  geom_bar()\n\nError in `geom_bar()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error in `check_aesthetics()`:\n! Aesthetics must be either length 1 or the same as the data (344).\n✖ Fix the following mappings: `x`.\n\n\nWhat does this error message mean and how do you fix it?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe error message consists of 2 parts. Part 1 is perhaps a bit trickier to interpret, but part 2 gives some useful hints:\n\n“Aesthetics must be either length 1 or the same as the data (344)”: This means that the variable mapped to x should either be a constant (like a single value) or a column that has 344 entries (matching the number of rows in the penguins dataset).\n“Fix the following mappings: x”: The issue is specifically with the x aesthetic, meaning islands is either misspelled or doesn’t exist in the dataset.\n\nTo check the penguins data, you can use glimpse().\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nTo fix the error, you need to correct the column name. The correct column in the penguins dataset is called island (without the “s” at the end). The island column has 344 entries, just like the rest of the dataset, so the mapping now works properly.\n\nggplot(penguins, aes(x = island)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\nNext, we want to create a grouped bar chart displaying species per island, using the viridis color palette.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_viridis()\n\nError in scale_fill_viridis(): could not find function \"scale_fill_viridis\"\n\n\nWhat does this error message mean and how do you fix it?\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe function scale_fill_viridis() is incorrect; the correct function is called scale_fill_viridis_d().\nFIX: correct the function name to display the grouped bar chart with the viridis color palette.\n\nggplot(penguins, aes(x = island, fill = species)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 7\nWe want to create a grouped bar chart showing the number of penguins on each island, broken down by year.\n\nggplot(penguins, aes(x = island, fill = year)) +\n  geom_bar(position = \"dodge\")\n\nWarning: The following aesthetics were dropped during statistical transformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\nHmmm. We got a plot, but certainly not the one we intended. The warning message mentions something about the grouping structure and gives some additional hints.\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThe grouping variable needs to be a factor. R helpfully asks if we’ve forgotten to convert a numerical variable into a factor!!! Oh, let’s check that in the penguins data using the glimpse() function.\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nIndeed, year is currently stored as a numeric (integer) variable. To fix this, we need to convert year to a factor. We can do this directly within the ggplot() function.\n\nggplot(penguins, aes(x = island, fill = as.factor(year))) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 8\nWe want to create a percent stacked bar chart that displays the ratio of penguins’ sex on each island, using a manual color palette. Female penguins should be displayed in blue, males in green, and NA values in red.\nNote: This task is trickier than it looks. Although the code runs and produces a plot, there are three mistakes to identify and fix.\n\nggplot(penguins, aes(x = sex, fill = island)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_manual(values = c(\"blue\", \"green\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\n\n\n\n\n\n\nHint for Mistake 1\n\n\n\n\n\nThe task was to create a percent stacked barchart, but the current plot is displaying a grouped barchart. You will need to adjust the argument that defines the type of plot to achieve the correct visualisation.\n\n\n\n\n\n\nFixing of Mistake 1\n\n\n\n\n\n\nggplot(penguins, aes(x = sex, fill = island)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"blue\", \"green\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint for Mistake 2\n\n\n\n\n\nYou may have also noticed that the colours are mapped to the islands, not to the penguins’ sex, which needs to be corrected.\n\n\n\n\n\n\nFixing of Mistake 2\n\n\n\n\n\nWe need to switch the columns mapped to the x and fill aesthetics.\n\nggplot(penguins, aes(x = island, fill = sex)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"blue\", \"green\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint for Mistake 3\n\n\n\n\n\nNow that the correct variables are mapped to the x-axis and the fill argument, the colour scheme no longer matches the instructions. According to the guidelines, missing values should be displayed in red.\n\n\n\n\n\n\nFixing of Mistake 3\n\n\n\n\n\nChanging the colour of missing values is a special case that requires the argument na.value =.\n\nggplot(penguins, aes(x = island, fill = sex)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"blue\", \"green\"), na.value = \"red\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data viz I</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html",
    "href": "05-dataviz2.html",
    "title": "5  Data viz II",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:\nIn this chapter, we continue our journey of appropriate plots. Last week, we examined which plots are appropriate for categorical variables. Today, we’ll focus on continuous variables and which plots to choose with a mix of continuous and categorical variables.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#intended-learning-outcomes",
    "href": "05-dataviz2.html#intended-learning-outcomes",
    "title": "5  Data viz II",
    "section": "",
    "text": "choose an appropriate plot for continuous variables\nchoose an appropriate plot for a mix of continuous/categorical variables\ncreate a basic version of an appropriate plot\napply extra layers to change the appearance of the plot",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#individual-walkthrough",
    "href": "05-dataviz2.html#individual-walkthrough",
    "title": "5  Data viz II",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#activity-1-set-up-and-data-for-today",
    "href": "05-dataviz2.html#activity-1-set-up-and-data-for-today",
    "title": "5  Data viz II",
    "section": "5.1 Activity 1: Set-up and data for today",
    "text": "5.1 Activity 1: Set-up and data for today\n\nWe are still working with the data by Pownall et al. (2023). Open the project.\nYou could use the same .Rmd file as last week if you want to keep all plotting in one document or create a new .Rmd to separate plots for categorical and continuous variables. Up to you.\nThe aggregated data is the same as last week. It should be in your project folder but in case it got lost, download the csv again and place it in your project folder: data_prp_for_ch4.csv.\nIf you need a reminder about the data and variables, have a look at the codebook and/or Section 1.4.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#activity-2-load-in-libraries-read-in-data-and-adjust-data-types",
    "href": "05-dataviz2.html#activity-2-load-in-libraries-read-in-data-and-adjust-data-types",
    "title": "5  Data viz II",
    "section": "5.2 Activity 2: Load in libraries, read in data, and adjust data types",
    "text": "5.2 Activity 2: Load in libraries, read in data, and adjust data types\nToday, we need to load the package tidyverse, and read in the data data_prp_ch4.csv.\n\n## packages \n???\n\n## data\ndata_prp_viz &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\ndata_prp_viz &lt;- read_csv(\"data_prp_for_ch4.csv\")\n\n\n\n\nThis is the same code as last week. We need to turn our categorical variables into factors to make plotting easier.\n\ndata_prp_viz &lt;- data_prp_viz %&gt;% \n  mutate(Gender = factor(Gender,\n                         levels = c(2, 1, 3),\n                         labels = c(\"females\", \"males\", \"non-binary\")),\n         Secondyeargrade = factor(Secondyeargrade,\n                                  levels = c(1, 2, 3, 4, 5),\n                                  labels = c(\"≥ 70% (1st class grade)\", \"60-69% (2:1 grade)\", \"50-59% (2:2 grade)\", \"40-49% (3rd class)\", \"&lt; 40%\")),\n         Plan_prereg = factor(Plan_prereg,\n                              levels = c(1, 3, 2),\n                              labels = c(\"Yes\", \"Unsure\", \"No\")),\n         Closely_follow = factor(Closely_follow,\n                                 levels = c(2, 3),\n                                 labels = c(\"Followed it somewhat\", \"Followed it exactly\")),\n         Research_exp = factor(Research_exp),\n         Pre_reg_group = factor(Pre_reg_group))\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are working within the same .Rmd file as last week, you can skip these initial steps but you have to run the code you had already placed at the start of last-week’s .Rmd file to load tidyverse into the library, read in the data, and convert some of the variables into factors.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#sec-hist",
    "href": "05-dataviz2.html#sec-hist",
    "title": "5  Data viz II",
    "section": "5.3 Activity 3: Histogram (geom_histogram())",
    "text": "5.3 Activity 3: Histogram (geom_histogram())\nIf you want to show the distribution of a continuous variable, you can use a histogram. As with every plot, you need at least 3 layers to create a base version of the plot. Similar to geom_bar(), geom_histogram() only requires an x variable as it does the counting “in the background”.\nA histogram divides the data into “bins” (i.e., groupings displayed in a single bar). These bins are plotted along the x-axis, with the y-axis showing the count of observations in each bin. It’s basically a barchart for continuous variables.\nLet’s have a look at the age distribution in our dataset.\n\nggplot(data_prp_viz, aes(x = Age)) +\n  geom_histogram() \n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\nFigure 5.1: Default histogram\n\n\n\n\n\nThe default number of bins is 30 (as shown in Figure 5.1 above). Changing the number of bins (argument bins) allows for more or less fine-tuning of the data. A higher number of bins results in more detailed granularity.\nPerhaps it’s more intuitive to modify the width of each bin using the binwidth argument. For example, binwidth = 1 for the age category would mean each “age group” represents 1 year, while binwidth = 5 would group ages into 5-year spans. The plots below show modifications for both bins and binwidth.\n\n#less finetuning\nggplot(data_prp_viz, aes(x = Age)) +\n  geom_histogram(bins = 10) \n\n# more fineturning\nggplot(data_prp_viz, aes(x = Age)) +\n  geom_histogram(binwidth = 1) \n\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range (`stat_bin()`).\nRemoved 2 rows containing non-finite outside the scale range (`stat_bin()`).\n\n\n\n\n\n\n\n\nFigure 5.2: Bins vs binwidth arguments\n\n\n\n\n\nThe warning message tells us 2 row of data were removed due to containing non-finite values outside the scale range. Have a look at the age column in data_prp_viz to see if you can decipher the warning message.\nThe rows were removed because they fall outside of the plot rangethey contain missing values.\nColours are manipulated slightly differently than in the barchart. Click through each tab to see how you can modify colours, axis labels, margins, and breaks, and apply a different theme.\n\nColourAxes labels, margins, and breaksThemes\n\n\nWe can change the plot colours by adding a fill argument and a colour argument. The fill argument changes the colour of the bars, while the colour argument modifies the outline of the bars. Note that these arguments are added directly to the geom_histogram(), rather than within the overall aes(), as we did with the barchart.\n\nggplot(data_prp_viz, aes(x = Age)) +\n  geom_histogram(binwidth = 1, fill = \"#586cfd\", colour = \"#FC58BE\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou could use:\n\nHex codes for fill and colour, as we did here: geom_histogram(binwidth = 1, fill = \"#586cfd\", colour = \"#FC58BE\"). If you want to create your own colours, check out this website.\nPre-defined colour names: geom_histogram(binwidth = 1, fill = \"purple\", colour = \"green\"). See the full list here.\n\n\n\n\n\nHere we removed the label for the y axes Count (to show you some variety) and modified the breaks. The y-axis is now displayed in increasing steps of 5 (rather than 10), and the x-axis has 1-year increments instead of 5.\nNotice how the breaks = argument changes the labels of the break ticks but not the scale limits. You can adjust the limits of the scale using the limits = argument. To exaggerate, we set the limits to 15 and 50. See how the values from 15 to 19, and 44 to 50 do not have labels? You would need to adjust that using the breaks = argument.\nThe expansion() function removes the gap between the x-axis and the bars. It is exactly the same code we used in Chapter 4.\n\nggplot(data_prp_viz, aes(x = Age)) +\n  geom_histogram(binwidth = 1, fill = \"#586cfd\", colour = \"#FC58BE\") +\n  labs(x = \"Age (in years)\", # renaming x axis label\n       y = \"\") + # removing the y axis label\n  scale_y_continuous(\n    # remove the space below the bars (first number), but keep a tiny bit (5%) above (second number)\n    expand = expansion(mult = c(0, 0.05)),\n    # changing break points on y axis\n    breaks = seq(from = 0, to = 30, by = 5)\n    ) +\n  scale_x_continuous(\n    # changing break points on x axis\n    breaks = seq(from = 20, to = 43, by = 1),\n    # Experimenting with\n    limits = c(15, 50)\n    )\n\n\n\n\n\n\n\n\n\n\nLet’s experiment with the themes. For this plot we have chosen theme_bw()\n\nggplot(data_prp_viz, aes(x = Age)) +\n  geom_histogram(binwidth = 1, fill = \"#586cfd\", colour = \"#FC58BE\") +\n  labs(x = \"Age (in years)\", # renaming x axis label\n       y = \"\") + # removing the y axis label\n  scale_y_continuous(\n    # remove the space below the bars (first number), but keep a tiny bit (5%) above (second number)\n    expand = expansion(mult = c(0, 0.05)),\n    # changing break points on y axis\n    breaks = seq(from = 0, to = 30, by = 5)\n    ) +\n  scale_x_continuous(\n    # changing break points on x axis\n    breaks = seq(from = 19, to = 44, by = 1)\n    ) +\n  # pick a theme\n  theme_bw()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#sec-scatter",
    "href": "05-dataviz2.html#sec-scatter",
    "title": "5  Data viz II",
    "section": "5.4 Activity 4: Scatterplot (geom_point())",
    "text": "5.4 Activity 4: Scatterplot (geom_point())\nScatterplots are appropriate when you want to plot two continuous variables. Here, we want to display the relationship between Acceptance of QRPs at Time point 1 and Time point 2. The default scatterplot can be created with geom_point().\nWe can also add a trendline by using geom_smooth(). The default trendline is loess. If you want a linear trendline, you would need to add method = \"lm\" inside the geom_smooth() function.\n\nggplot(data_prp_viz, aes(x = QRPs_Acceptance_Time1_mean, y = QRPs_Acceptance_Time2_mean)) +\n  geom_point() +\n  geom_smooth()\n\nggplot(data_prp_viz, aes(x = QRPs_Acceptance_Time1_mean, y = QRPs_Acceptance_Time2_mean)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\n\nFigure 5.3: Default Scatterplot with added trendline - loess (left) and linear (right)\n\n\n\n\n\nCustomising the colour of a scatterplot is slightly different from the other plots we’ve encountered so far. Technically, the point is not a “filled-in black area” but rather an extremely wide outline of a circle. Therefore, we cannot use the usual fill argument and instead need to use the colour argument, similar to how we customised the outline of the histogram.\nSee the tabs below to learn how to change the colour for all points or how to adjust the colour based on groupings.\n\nColour for all pointsColour with groupingLegend title and labels\n\n\nIf we want to change the colour of all the points, we can add the colour argument to the geom_point() function. Likewise, to change the colour of the trendline, we would also use the colour argument. Here, we used pre-defined colour names, but HEX codes would work just as well.\n\n# colour of all points and the trendline\nggplot(data_prp_viz, aes(x = QRPs_Acceptance_Time1_mean, y = QRPs_Acceptance_Time2_mean)) +\n  geom_point(colour = 'magenta') +\n  geom_smooth(method = lm, colour = 'turquoise')\n\n\n\n\n\n\n\n\n\n\nIf we want the points to change colour based on another grouping variable, the colour argument should go inside the aes(). If you don’t want to define the colours manually, you can use a colour palette like Brewer (scale_colour_brewer()) or Viridis (scale_colour_viridis_d()).\n\n## adding grouping variable Pre_reg_group and changing the colour values manually\nggplot(data_prp_viz, aes(x = QRPs_Acceptance_Time1_mean, y = QRPs_Acceptance_Time2_mean, colour = Pre_reg_group)) +\n  geom_point() +\n  geom_smooth(method = lm) +\n  scale_colour_manual(values = c('mediumvioletred', 'steelblue1'))\n\n\n\n\n\n\n\n\n\n\nYou can tidy the legend title and group labels using the scale_colour_? function, depending on the palette you’re using (e.g., scale_colour_manual(), scale_colour_brewer and many more).\n\nggplot(data_prp_viz, aes(x = QRPs_Acceptance_Time1_mean, y = QRPs_Acceptance_Time2_mean, colour = Pre_reg_group)) +\n  geom_point() +\n  geom_smooth(method = lm) +\n  scale_colour_manual(values = c('mediumvioletred', 'steelblue1'),\n                      name = \"Pre-registered Dissertation\",\n                      labels = c(\"Yes\", \"No\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nAll other layers remain exactly the same as in other plots. Try adding layers to make the plot above prettier:\n\n1. relabel axes x and y\n2. set the x and y axis range from 1 to 7\n3. move the legend to a different position (either top, left, or bottom)\n4. add a theme\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\ncan be done in 2 different ways - labs() or scale_x_?\nwe did that for the histogram\nWe did that for the barcharts\npick a theme you like\n\n\n\n\n\n\n\nMore hints\n\n\n\n\n\nIf you are experiencing issues with the legend position and theme, try modifying the order of the layers.\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(data_prp_viz, aes(x = QRPs_Acceptance_Time1_mean, y = QRPs_Acceptance_Time2_mean, colour = Pre_reg_group)) +\n  geom_point() +\n  geom_smooth(method = lm) +\n  scale_colour_manual(values = c('mediumvioletred', 'steelblue1'),\n                      name = \"Pre-registered Dissertation\",\n                      labels = c(\"Yes\", \"No\")) +\n  labs (x = \"Acceptance of Questionable Research Practices (Time 1)\", \n        y = \"Acceptance of Questionable Research Practices (Time 2)\") +\n  theme_light() + # place before moving the legend position\n  theme(legend.position = \"top\") # move legend to the top",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#activity-5-boxplot-geom_boxplot",
    "href": "05-dataviz2.html#activity-5-boxplot-geom_boxplot",
    "title": "5  Data viz II",
    "section": "5.5 Activity 5: Boxplot (geom_boxplot())",
    "text": "5.5 Activity 5: Boxplot (geom_boxplot())\nA boxplot is one of the options to display a continuous variable with categorical grouping variable. Here, we want to create a boxplot to explore whether students’ understanding of open science varies based on whether or not they have research experience. Our default boxplot would look like this:\n\n# default boxplot\nggplot(data_prp_viz, aes(x = Research_exp, y = Time1_Understanding_OS)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nTada! As usual, we can enhance the plot by adding various layers. Click on each tab below to see how.\n\nColourAxes labelsLegend and Theme\n\n\nWe can change the colour by adding a fill argument inside the aes(). To customise the colours further, we can add a scale_fill_? layer. If you have specific colours in mind, use scale_fill_manual(). If you prefer pre-defined palettes, such as Brewer, you can use scale_fill_brewer().\nBtw, this is exactly the same code we used for the barcharts.\n\nggplot(data_prp_viz, aes(x = Research_exp, y = Time1_Understanding_OS, fill = Research_exp)) +\n  geom_boxplot() +\n  # customise colour\n  scale_fill_brewer(palette = \"Dark2\")\n\n\n\n\n\n\n\n\n\n\nWe need to relabel the axes. The function to use depends on the variable type. Here, we need scale_x_discrete() for the x-axis and scale_y_continuous() for the y-axis. We can also tidy up the group labels and adjust the breaks on the y-axis (e.g., in steps of 1 instead of 2) within these same functions.\n\nggplot(data_prp_viz, aes(x = Research_exp, y = Time1_Understanding_OS, fill = Research_exp)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Dark2\") +\n  scale_x_discrete(\n    # changing the label of x\n    name = \"Research Experience\",\n    # changing the group labels of the 2 groups\n    labels = c(\"Yes\", \"No\")) + \n  scale_y_continuous(\n    # changing name of the y axis\n    name = \"Confidence in Understanding Open Science (Time 1)\",\n    # changing break labels\n    breaks = c(seq(from = 1, to = 7, by = 1))\n  )\n\n\n\n\n\n\n\n\n\n\nThe legend is superfluous; best to take it off. As before, we can remove the legend by adding the argument guide = \"none\" to the scale_fill_? function.\nLet’s pick a theme we haven’t used yet: theme_dark().\n\nggplot(data_prp_viz, aes(x = Research_exp, y = Time1_Understanding_OS, fill = Research_exp)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Dark2\",\n                    # removing the legend\n                    guide = \"none\") +\n  scale_x_discrete(\n    name = \"Research Experience\",\n    labels = c(\"Yes\", \"No\")) + \n  scale_y_continuous(\n    name = \"Confidence in Understanding Open Science (Time 1)\",\n    breaks = c(seq(from = 1, to = 7, by = 1))\n  ) +\n  # pick a theme\n  theme_dark()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#activity-6-violin-plot-geom_violin",
    "href": "05-dataviz2.html#activity-6-violin-plot-geom_violin",
    "title": "5  Data viz II",
    "section": "5.6 Activity 6: Violin plot (geom_violin())",
    "text": "5.6 Activity 6: Violin plot (geom_violin())\nAn alternative way to display a continuous variable with a categorical grouping variable is a violin plot. Here, we want to create a violin plot to explore whether the perception of supervisor support depends on whether students plan to pre-register their dissertation. Our default violin plot would look like this:\n\n# default boxplot\nggplot(data_prp_viz, aes(x = Plan_prereg, y = Mean_Supervisor_Support)) +\n  geom_violin()\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_ydensity()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nAdjusting the violin plot would be exactly the same as the boxplot. Try to add layers to the base plot above to\n\nchange the colours either manually or using a pre-defined colour palette\ntidy the axes labels and group names\nin case a legend appears, take it off\nadd a theme\n\n\n\n\n\n\n\nOne possible Solution\n\n\n\n\n\n\nggplot(data_prp_viz, aes(x = Plan_prereg, y = Mean_Supervisor_Support, fill = Plan_prereg)) +\n  geom_violin() +\n  scale_fill_manual(values = c('mediumspringgreen', 'orangered', 'slateblue'),\n                    # removing the legend\n                    guide = \"none\") +\n  scale_x_discrete(name = \"Plan to pre-register the dissertation\") + \n  scale_y_continuous(\n    name = \"Perceived Supervisory Support\",\n    breaks = c(seq(from = 1, to = 7, by = 1))\n  ) +\n  # pick a theme\n  theme_minimal()\n\nWarning: Removed 3 rows containing non-finite outside the scale range\n(`stat_ydensity()`).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#activity-7-violin-boxplots",
    "href": "05-dataviz2.html#activity-7-violin-boxplots",
    "title": "5  Data viz II",
    "section": "5.7 Activity 7: Violin-boxplots",
    "text": "5.7 Activity 7: Violin-boxplots\nSo far, we’ve only added one geom_? layer to our plots. However, thanks to ggplot’s layered system, we can add multiple geoms, for example, when creating a violin-boxplot.\nRemember, the order of the layers can sometimes make a difference. We’ve seen this already - adding a theme at the end can override earlier arguments like the legend position. Similarly, ggplot + violinplot + boxplot will look different from ggplot + boxplot + violinplot.\nLet’s use the example of QRPs at timepoint 2 and a grouping variable of Second-year Grade.\n\nggplot(data_prp_viz, aes(x = Secondyeargrade, y = QRPs_Acceptance_Time2_mean)) +\n  geom_violin() +\n  geom_boxplot()\n\n\nggplot(data_prp_viz, aes(x = Secondyeargrade, y = QRPs_Acceptance_Time2_mean)) +\n  geom_boxplot() +\n  geom_violin()\n\n\n\n\n\n\n\n\n\nFigure 5.4: Default violin-boxplot: Order of the layer matters\n\n\n\n\n\nSee the tabs below to learn how to customise various elements, such as the width of the boxes, and the colour or opacity.\n\nWidth of the boxesColour\n\n\nIf we want to get any information from the boxplot, we need to place it “on top of” the violin plot. But still, the boxplot is pretty wide and covers important details from the violin plot. To make the information more visible, we can adjust the width of the boxes. Finding an appropriate width might take some trial and error.\n\nggplot(data_prp_viz, aes(x = Secondyeargrade, y = QRPs_Acceptance_Time2_mean)) +\n  geom_violin() +\n  geom_boxplot(width = 0.2)\n\n\n\n\n\n\n\nFigure 5.5: Default violin-boxplot: adjusting width of the box\n\n\n\n\n\n\n\nAdding colour should be pretty straightforward by now. The code is no different from what we used for the boxplot or violin plot. We need to add the fill argument within the aes(), along with a scale_fill_? layer.\nHowever, we can further customise the plot by adding an opacity argument using alpha to the violin plot geom.\n\nggplot(data_prp_viz, aes(x = Secondyeargrade, y = QRPs_Acceptance_Time2_mean, fill = Secondyeargrade)) +\n  geom_violin(alpha = 0.4) + # alpha for opacity\n  geom_boxplot(width = 0.2) + # change width of the boxes\n  scale_fill_brewer(palette = \"RdPu\") # customise colour\n\n\n\n\n\n\n\nFigure 5.6: Violin-boxplot with a different colour palette\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\n\nChange the x- and y-axis labels\nRemove the legend\nadd a theme\n\n\n\n\n\n\n\nOne possible Solution\n\n\n\n\n\n\nggplot(data_prp_viz, aes(x = Secondyeargrade, y = QRPs_Acceptance_Time2_mean, fill = Secondyeargrade)) +\n  geom_violin(alpha = 0.4) +\n  geom_boxplot(width = 0.2) +\n  scale_fill_brewer(palette = \"RdPu\",\n                    guide = \"none\") + # removes the legend\n  # change labels of x and y\n  labs (x = \"Second-year Grade\", y = \"Acceptance of Questionable Research Practices (Time 2)\") +\n  theme_classic()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#activity-8-faceting---adding-another-grouping-variable",
    "href": "05-dataviz2.html#activity-8-faceting---adding-another-grouping-variable",
    "title": "5  Data viz II",
    "section": "5.8 Activity 8: Faceting - adding another grouping variable",
    "text": "5.8 Activity 8: Faceting - adding another grouping variable\nFaceting is really useful when you have subsets in the data. We will apply it to the violin-boxplot from above, but you could add this layer to pretty much any plot. The function to split the plots into facets is called facet_wrap().\nLet’s add another grouping variable, Pre_reg_group, to create separate plots for the yes and no groups.\nSince the group labels on the x-axis are quite long, we will need to adjust them for better readability. Adding guide = guide_axis(n.dodge = 2) to the scale_x_discrete() function helps to display labels across multiple rows.\n\nggplot(data_prp_viz, aes(x = Secondyeargrade, y = QRPs_Acceptance_Time2_mean, fill = Secondyeargrade)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.2) +\n  scale_fill_brewer(palette = \"RdPu\",\n                    guide = \"none\") + \n  labs (x = \"Second-year Grade\", y = \"Acceptance of Questionable Research Practices (Time 2)\") +\n  theme_classic() +\n  facet_wrap(~Pre_reg_group) + # faceting to split into subplots for yes and no\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) # want display labels in 2 rows\n\n\n\n\n\n\n\nFigure 5.7: Pretty violin-boxplot split into pre-registration groups (yes and no)\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou may have noticed that the labels of Pre_reg_group are displayed as numbers (1 and 2). If this bugs you, fix the labels in the data object. This would be less hassle than trying to adjust the facet headings in the plot.\n\n\n\n\n\n\n\n\nSpecial case: Variables with subscales\n\n\n\n\n\nFor example, if we want to show the relationship between SATs scores at Timepoints 1 and 2, separately for all four subscales of the SATs questionnaire, we need to wrangle the data so that the scores for Time 1 and Time 2 are in separate columns, but each participant has four rows (one for each subscale). The dataframe should look like this:\n\nhead(data_facet, n=5)\n\n\n\n\n\nCode\nSubscale\nTime1\nTime2\n\n\n\n\nTr10\nAffect\n4.000000\n3.500000\n\n\nTr10\nCognitiveCompetence\n5.166667\n4.166667\n\n\nTr10\nValue\n6.000000\n3.000000\n\n\nTr10\nDifficulty\n3.571429\n2.857143\n\n\nBi07\nAffect\n3.833333\n3.166667\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nCreate a new data object data_facet and wrangle the data from data_prp_viz so that it looks like the table above.\n\n\n\n\n\n\nBroad hints\n\n\n\n\n\n\nStep 1: select variables of interest from data_prp_viz\nStep 2: pivot the data\nStep 3: try to access information on subscales and timepoints from the variable names\nStep 4: pivot in the other direction\n\n\n\n\n\n\n\n\n\n\nMore specific hints\n\n\n\n\n\n\nStep 1: The variables of interest are the participants’ ID and all columns that start with SATS.\nStep 2: Pivot all columns, except the participant ID, from wide to long format.\nStep 3: Get some inspiration from Activity 4 in {#sec-wrangling2}.\nStep 4: At this point, subscales and timepoints should be in long format. However, only the subscale information should remain in long format. Pivot the data from long to wide format so that Time 1 and Time 2 are in separate columns.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata_facet &lt;- data_prp_viz %&gt;% \n  select(Code, starts_with(\"SATS\")) %&gt;% \n  pivot_longer(cols = starts_with(\"SATS\"), names_to = \"Variable\", values_to = \"Mean_Scores\") %&gt;% \n  separate(Variable, into = c(NA, \"Subscale\", \"Timepoint\", NA), sep = \"_\") %&gt;% \n  pivot_wider(names_from = Timepoint, values_from = Mean_Scores)\n\n\n\n\n\n\nNow we can build a scatterplot with facets for the subscales.\n\nggplot(data_facet, aes(x = Time1, y = Time2)) +\n  geom_point() +\n  facet_wrap(~Subscale)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "05-dataviz2.html#test-your-knowledge",
    "href": "05-dataviz2.html#test-your-knowledge",
    "title": "5  Data viz II",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nKnowledge check\n\nQuestion 1\nWhy would this line of code not create a barplot, assuming you already loaded all data and libraries and you spelt the data and column names correctly?\n\nggplot(summarydata, aes(x = sex)) +\n  geom_barplot()\n\n\n because there is no geom_barplot() and it should be geom_bar() because you have piped the barplot and not added it because this would create a histogram because you have not included a y axis\n\n\n\nQuestion 2\nIf I wanted precisely 5 bars in my histogram, what argument would I use?\n\n ggplot() + geom_histogram(binwidth = 5) ggplot() + geom_histogram(bins = 5) ggplot() + geom_histogram() ggplot() + geom_histogram(bars = 5)\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n\nggplot() + geom_histogram(bins = 5). This is the correct answer as you are asking ggplot2 to give you the plot organised into 5 bins.\nggplot() + geom_histogram(bars = 5). This is incorrect as you bars is not the right argument name. You want 5 bars, but the argument is bins.\nggplot() + geom_histogram(binwidth = 5). This is incorrect as binwidth controls the x-axis range to include per bar, rather than the number of bars.\nggplot() + geom_histogram(). This is incorrect as you did not control the number of bins, so it will default to 30.\n\n\n\n\n\n\nQuestion 3\nYou want to create a scatterplot to show the correlation between two continuous variables, which geom would you use?\n\n geom_violin() geom_point() geom_boxplot() geom_histogram()\n\n\n\nQuestion 4\nTrue or False? To showcase different groups in a scatterplot, you could specify a grouping variable using the fill argument to change the colour of the points. TRUEFALSE\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nHave a look in the scatterplot section again. There, we explained that we cannot “colour in” the area of the points using fill, but need to change the outline colour of the points with colour instead.\n\n\n\n\n\n\nError mode\nSome of the code chunks contain mistakes and result in errors, while others do not produce the expected results. Your task is to identify any issues, explain why they occurred, and, if possible, fix them.\nLet’s go back to the Palmer penguins for this part.\n\nlibrary(palmerpenguins)\n\n\nAttaching package: 'palmerpenguins'\n\n\nThe following objects are masked from 'package:datasets':\n\n    penguins, penguins_raw\n\n\n\nQuestion 5\nWe want to plot the number of penguins across the different islands.\n\nggplot(penguins, aes(x = islands)) %&gt;% \n  geom_bar()\n\nError in `geom_bar()`:\n! `mapping` must be created by `aes()`.\nℹ Did you use `%&gt;%` or `|&gt;` instead of `+`?\n\n\nThe error message is incredibly useful. So that should be an easy fix!\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nTo fix the error, all we need to do is turn the pipe %&gt;% into a plus +.\n\nggplot(penguins, aes(x = island)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 6\nWe want to create a violin-boxplot showing the bill length across species, separately for male and female penguins.\n\npenguins_no_na &lt;- penguins %&gt;% \n  drop_na(island, flipper_length_mm, sex)\n\nggplot(penguins_no_na, aes(x = island, y = flipper_length_mm, fill = sex)) +\n  geom_violin() +\n  geom_boxplot(width = 0.2) +\n  labs(x = \"Island\", y = \"Bill length in mm\") +\n  facet_wrap(~sex)\n\n\n\n\n\n\n\n\nWe got a plot, but is it the one we aimed for? yesno\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nThis was a tricky one. The code runs, so we think everything is fine. Despite having re-labelled the y-axis “Bill length in mm”, it’s really showing the flipper length. Did you spot this???\n\npenguins_no_na &lt;- penguins %&gt;% \n  drop_na(island, bill_length_mm, sex)\n\nggplot(penguins_no_na, aes(x = island, y = bill_length_mm, fill = sex)) +\n  geom_violin() +\n  geom_boxplot(width = 0.2) +\n  labs(x = \"Island\", y = \"Bill length in mm\") +\n  facet_wrap(~sex)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 7\nThis time, we want to show the relationship between flipper length and body mass of the penguins. The following code runs, but the x- and y-axes are misbehaving somehow. Not what we wanted. Any idea why?\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, colour = island)) +\n  geom_point() +\n  scale_colour_viridis_d(name = \"Island\") +\n  scale_y_discrete(name = \"Body mass in g\",\n                     breaks = seq(2500, 6500, 500),\n                     limits = c(2500, 6500)) +\n  scale_x_discrete(name = \"Flipper length in mm\")\n\nWarning in scale_y_discrete(name = \"Body mass in g\", breaks = seq(2500, : Continuous limits supplied to discrete scale.\nℹ Did you mean `limits = factor(...)` or `scale_*_continuous()`?\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplain the solution\n\n\n\n\n\nWe used the wrong function for continuous variables. The error message helpfully asked us if we either meant to turn something into a factor or use scale_*_continuous() instead.\nIndeed, we used scale_x_discrete and scale_y_discrete, instead of scale_x_continuous and scale_y_continuous. We must honour the variable type when we customise plots, so always check what type of variable is on each axis and which function lets you edit it.\n\nggplot(penguins, aes(x = flipper_length_mm, y = body_mass_g, colour = island)) +\n  geom_point() +\n  scale_colour_viridis_d(name = \"Island\") +\n  scale_y_continuous(name = \"Body mass in g\",\n                     breaks = seq(2500, 6500, 500),\n                     limits = c(2500, 6500)) +\n  scale_x_continuous(name = \"Flipper length in mm\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data viz II</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html",
    "href": "06-chi-square-one-sample.html",
    "title": "6  Chi-square and one-sample t-test",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#intended-learning-outcomes",
    "href": "06-chi-square-one-sample.html#intended-learning-outcomes",
    "title": "6  Chi-square and one-sample t-test",
    "section": "",
    "text": "compute a Cross-tabulation Chi-square test and report the results\ncompute a one-sample t-test and report the results\nunderstand when to use a non-parametric equivalent for the one-sample t-test, compute it, and report the results",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#individual-walkthrough",
    "href": "06-chi-square-one-sample.html#individual-walkthrough",
    "title": "6  Chi-square and one-sample t-test",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#overview",
    "href": "06-chi-square-one-sample.html#overview",
    "title": "6  Chi-square and one-sample t-test",
    "section": "Overview",
    "text": "Overview\nFrom here on, we will explore inferential statistics, including chi-square test, various t-tests, correlations, ANOVAs, and regression. Most of these tests belong to the General Linear Model (GLM) family, which helps us analyse relationships between variables using linear equations. The chi-square test, while not part of the GLM, is also included here as it’s useful for analysing categorical data.\nTo help you choose the most appropriate test, refer to the simplified flowchart below. It guides you based on the types of variables - whether they are categorical or continuous.\n\n\n\nSimplified flowchart to help select the most appropriate test (created with drawio). To view a larger version, click on the image or click here\n\n\nEach test is discussed in its respective chapter with guidance on when and how to apply it:\n\nCross-tabulation chi-Square test (this chapter, Section 6.4)\nOne-sample t-test (this chapter, Section 6.5)\nTwo-sample or independent t-test (between-subjects design, Chapter 7)\nPaired t-test (within-subjects design, Chapter 8)\nCorrelation (Chapter 9)\nSimple regression (Chapter 10)\nMultiple regression (Chapter 11)\nOne-way ANOVA (Chapter 12)\nFactorial ANOVA (Chapter 13)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#activity-1-setup-download-the-data",
    "href": "06-chi-square-one-sample.html#activity-1-setup-download-the-data",
    "title": "6  Chi-square and one-sample t-test",
    "section": "6.1 Activity 1: Setup & download the data",
    "text": "6.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2A_chapter6”, or “06_chi_square_one_sample_t”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you get stuck.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the new dataset here: data_ch6.zip. This zip file contains one csv file with demographic information and questionnaire data as well as and Excel codebook.\nExtract the data files from the zip folder and place them directly in your project folder (next to the project icon, not in a subfolder). For more help, see Section 1.4.\n\nCitation\n\nBallou, N., Vuorre, M., Hakman, T., Magnusson, K., & Przybylski, A. K. (2024, July 12). Perceived value of video games, but not hours played, predicts mental well-being in adult Nintendo players. https://doi.org/10.31234/osf.io/3srcw\n\nAs you can see, the study is a pre-print published on PsyArXiv Preprints. The data and supplementary materials are available on OSF: https://osf.io/6xkdg/\nAbstract\n\nStudies on video games and well-being often rely on self-report measures or data from a single game. Here, we study how 703 US adults’ time spent playing for over 140,000 hours across 150 Nintendo Switch games relates to their life satisfaction, affect, depressive symptoms, and general mental well-being. We replicate previous findings that playtime over the past two weeks does not predict well-being, and extend these findings to a wider range of timescales (one hour to one year). Results suggest that relationships, if present, dissipate within two hours of gameplay. Our non-causal findings suggest substantial confounding would be needed to shift a meaningful true effect to the observed null. Although playtime was not related to well-being, players’ assessments of the value of game time—so called gaming life fit—was. Results emphasise the importance of defining the gaming population of interest, collecting data from more than one game, and focusing on how players integrate gaming into their lives rather than the amount of time spent.\n\nChanges made to the dataset\n\nWe extracted key demographic variables from the rich dataset, including age, gender, ethnicity, employment, education level, and scores from the Warwick-Edinburgh Mental Wellbeing Scale.\nWe removed rows with missing values and categorical groupings with low observed frequencies for the purpose of this chapter.\nWe won’t explore any associations related to gaming, but feel free to download the full dataset if you wish to investigate further.\nUnlike the original study, which applied strict inclusion criteria, we used more flexible criteria, resulting in a larger sample size than the original analysis.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "href": "06-chi-square-one-sample.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "title": "6  Chi-square and one-sample t-test",
    "section": "6.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data",
    "text": "6.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data\nToday, we will be using the following packages: tidyverse, lsr, scales, qqplotr, car, pwr, and rcompanion. If you need to install any of them, do so via the console (see Section 1.5.1 for more detail).\nAdditionally, we will need to read in the data data_ballou_reduced.\n\n# load in the packages\n???\n\n# read in the data\ndata_ballou &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# load in the packages\nlibrary(tidyverse)\nlibrary(lsr)\nlibrary(scales)\nlibrary(qqplotr)\nlibrary(car)\nlibrary(pwr)\nlibrary(rcompanion)\n\n# read in the data\ndata_ballou &lt;- read_csv(\"data_ballou_reduced.csv\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#activity-3-data-wrangling",
    "href": "06-chi-square-one-sample.html#activity-3-data-wrangling",
    "title": "6  Chi-square and one-sample t-test",
    "section": "6.3 Activity 3: Data wrangling",
    "text": "6.3 Activity 3: Data wrangling\nThe categorical variables in our dataset look tidy, but we need to make a few adjustments to prepare for our analysis:\n\nConvert gender and education_level into factors in the original data_ballou object. Our statistical tests require these variables to be factors, and converting them will also help with sorting categories effectively for plotting. Feel free to arrange the categories in a meaningful order.\nCreate a new data object called data_wemwbs to calculate the total score for the Warwick-Edinburgh Mental Wellbeing Scale (WEMWBS): According to the official WEMWBS website, the individual item scores should be summed to get the total.\nJoin the the original data_ballou dataset with the new data_wemwbs dataset to have all the information in one place.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nWe converted categorical variables into factors previously in Chapter 4 - refer back if you need a refresher\nCheck how we handled the QRPs questionnaire in Chapter 2 for guidance on aggregating scores\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata_wemwbs &lt;- data_ballou %&gt;% \n  pivot_longer(cols = wemwbs_1:wemwbs_14, names_to = \"Questions\", values_to = \"Scores\") %&gt;% \n  group_by(pid) %&gt;% \n  summarise(wemwbs_sum = sum(Scores))\n\ndata_ballou &lt;- data_ballou %&gt;% \n  mutate(gender = factor(gender,\n                         levels = c(\"Woman\", \"Man\", \"Non-binary\")),\n         eduLevel = factor(eduLevel,\n                           levels = c(\"Completed Secondary School\", \"Some University but no degree\", \"University Bachelors Degree\", \"Vocational or Similar\", \"Graduate or professional degree (MA, MS, MBA, PhD, etc)\"))) %&gt;% \n  left_join(data_wemwbs)\n\nJoining with `by = join_by(pid)`",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#sec-chi_square",
    "href": "06-chi-square-one-sample.html#sec-chi_square",
    "title": "6  Chi-square and one-sample t-test",
    "section": "6.4 Activity 4: Cross-tabulation Chi-square test",
    "text": "6.4 Activity 4: Cross-tabulation Chi-square test\nA Cross-Tabulation Chi-Square Test, also known as a Chi-Square Test of Association or Independence, tests how one variable is associated with the distribution of outcomes in another variable.\nWe will be performing a Chi-Square test using the categorical variables gender and eduLevel:\n\nPotential research question: “Is there an association between gender and level of education in the population?”\nNull Hypothesis (H0): “Gender and level of education are independent; there is no association between gender and level of education.”\nAlternative Hypothesis (H1): “Gender and level of education are not independent; there is an association between gender and level of education.”\n\n\n6.4.1 Task 1: Preparing the dataframe\nFirst, select your variables of interest - here participant id, gender, and education levels. This dataset does not contain missing values, but in future datasets that might, use drop_na() to remove them before converting categorical variables into factors.\n\nchi_square &lt;- data_ballou %&gt;% \n  select(pid, gender, eduLevel)\n\n\n\n6.4.2 Task 2: Compute descriptives\nNext, we need to calculate counts for each combination of the variables, which is best done in a frequency table - or more precisely a contingency table since we are looking at a combination of 2 categorical variables (sometimes they are called crosstabulation and two-way tables).\nThis will also allow us to verify that there are no missing values in any cells, as the function we’re using cannot handle missing values\n\nchi_square_frequency &lt;- chi_square %&gt;% \n  count(gender, eduLevel) %&gt;% \n  pivot_wider(names_from = eduLevel, values_from = n)\n\nchi_square_frequency\n\n\n\n\n\n\n\n\n\n\n\n\n\ngender\nCompleted Secondary School\nSome University but no degree\nUniversity Bachelors Degree\nVocational or Similar\nGraduate or professional degree (MA, MS, MBA, PhD, etc)\n\n\n\n\nWoman\n63\n118\n169\n42\n65\n\n\nMan\n70\n125\n250\n34\n81\n\n\nNon-binary\n9\n23\n20\n4\n10\n\n\n\n\n\n\nWe should be fine here, even though the count for the non-binary/vocational category is quite low.\n\n\n6.4.3 Task 3: Check assumptions\n\nAssumption 1: Categorical data\nBoth variables should be categorical, measured at either the ordinal or nominal level.\nWe can confirm that for our dataset. Gender is ordinalnominal, and level of education is ordinalnominal.\n\n\nAssumption 2: Independent observartions\nEach observation in the dataset has to be independent, meaning the value of one observation does not affect the value of any other.\nAnd we assume as much for our data.\n\n\nAssumption 3: Cells in the contingency table are mutually exclusive\nEach individual can belong to only one cell in the contingency table. We can confirm this by examining the data and reviewing the contingency table.\n\n\nAssumption 4: Expected frequencies are sufficiently large\nAssumption 4 is not an assumption that is listed consistently across various sources. When it is, it suggests that expected frequencies are larger than 5 or at least 80% of the the expected frequencies are above 5 and none of them are below 1. However, Danielle Navarro points out that this seems to be a “somewhat conservative” criterion and should be taken as “rough guidelines” only (see https://learningstatisticswithr.com/book/chisquare.html#chisqassumptions.\nThis is information, we can either compute manually (see lecture slides) or wait till we get the output from the inferential statistics later.\n\n\n\n6.4.4 Task 4: Create an appropriate plot\nNow we can create the appropriate plot. Which plot would you choose when building one from object chi_square? A BarchartHistogramScatterplotViolin-Boxplot with geom layer geom_colgeom_bargeom_histogramgeom_pointgeom_boxplot and geom_violin\nTry creating the plot on your own before checking the solution. Feel free to practice adding different layers to make the plot pretty!\n\n\n\n\n\n\nOne possible solution\n\n\n\n\n\n… is a grouped bar chart.\nI played about with the labels of the x-axis categories since the graduate label is super long. Google was my friend in this instance and showed me a nifty function called label_wrap() from the scales package which automatically inserts line breaks after a set number of characters. Setting it to 12 characters looked best. (See other options for long labels at https://www.andrewheiss.com/blog/2022/06/23/long-labels-ggplot/).\n\nggplot(chi_square, aes(x = eduLevel, fill = gender)) +\n  geom_bar(position = \"dodge\") + \n  scale_fill_viridis_d(name = \"Gender\") +\n  scale_x_discrete(name = \"Level of Education\",\n                   labels = label_wrap(12)) +\n  scale_y_continuous(name = \"Count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.4.5 Task 5: Compute a chi-square test\nBefore we can do that, we need to turn our tibble into a dataframe - the associationTest() function we are using to compute the Chi-square test does not like tibbles. [you have nooooo clue how long that took to figure out - let’s say the error message was not exactly helpful]\n\nchi_square_df &lt;- as.data.frame(chi_square)\n\nNow we can run the associationTest() function from the lsr package. The first argument is a formula. It starts with a ~ followed by the two variables you want to associate, separated by a +. The second argument is the dataframe.\n\nassociationTest(formula = ~ eduLevel + gender, data = chi_square_df)\n\nWarning in associationTest(formula = ~eduLevel + gender, data = chi_square_df):\nExpected frequencies too small: chi-squared approximation may be incorrect\n\n\n\n     Chi-square test of categorical association\n\nVariables:   eduLevel, gender \n\nHypotheses: \n   null:        variables are independent of one another\n   alternative: some contingency exists between variables\n\nObserved contingency table:\n                                                         gender\neduLevel                                                  Woman Man Non-binary\n  Completed Secondary School                                 63  70          9\n  Some University but no degree                             118 125         23\n  University Bachelors Degree                               169 250         20\n  Vocational or Similar                                      42  34          4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)    65  81         10\n\nExpected contingency table under the null hypothesis:\n                                                         gender\neduLevel                                                  Woman   Man\n  Completed Secondary School                               59.9  73.4\n  Some University but no degree                           112.2 137.5\n  University Bachelors Degree                             185.2 227.0\n  Vocational or Similar                                    33.8  41.4\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)  65.8  80.7\n                                                         gender\neduLevel                                                  Non-binary\n  Completed Secondary School                                    8.65\n  Some University but no degree                                16.21\n  University Bachelors Degree                                  26.75\n  Vocational or Similar                                         4.88\n  Graduate or professional degree (MA, MS, MBA, PhD, etc)       9.51\n\nTest results: \n   X-squared statistic:  13.594 \n   degrees of freedom:  8 \n   p-value:  0.093 \n\nOther information: \n   estimated effect size (Cramer's v):  0.079 \n   warning: expected frequencies too small, results may be inaccurate\n\n\nThe output is quite informative as it gives information about:\n\nthe variables that were tested,\nthe null and alternative hypotheses,\na table with the observed frequencies (which matches our calculations in chi_square_frequency without the rows/columns of the missing values we removed),\nan output of the frequencies you’d expect if the null hypothesis were true,\nthe result of the hypothesis test, and\nthe effect size Cramer’s v.\n\nIt also gives us a warning message saying that expected frequencies are too small and that the chi-squared approximation may be incorrect. This relates to Assumption 4. Depending on your stance on Assumption 4, you may choose to either address or ignore this warning.\nThe p-value indicates that we do not reject the null hypothesis, as it is greater than 0.05.\n\n\n6.4.6 Task 6: Sensitivity power analysis\nA sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect given the number of participants you have in the sample (i.e., sample size), the alpha level at 0.05, and an assumed power of 0.8. Remember, power analysis relies on four key factors — alpha, power, effect size, and sample size (APES). If you know three of these, you can calculate the fourth.\nFor a Chi-square test, we use the pwr.chisq.test() function from the pwr package. In this case, we already know the alpha, power, and sample size, and we want to calculate the smallest effect size detectable with this design. The function also requires the degrees of freedom (df), which tells R how many groups are being compared. You can find the df value in the output of your Chi-square test (e.g., from associationTest()).\nThe key arguments for this function are:\n\nw = Effect size (Cohen’s omega, ⍵). (Leave this one out to calculate it.)\nN = Total number of observations.\ndf = Degree of freedom (from your Chi-square test).\nsig.level = The significance level of the study (usually set to 0.05).\npower = The power level of the study (usually set to 0.8).\n\n\npwr.chisq.test(N = 1083,\n               df = 8,\n               sig.level = 0.05,\n               power = 0.8)\n\n\n     Chi squared power calculation \n\n              w = 0.1178008\n              N = 1083\n             df = 8\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: N is the number of observations\n\n\nThis output gives us the smallest effect size detectable with this design. To interpret it, we need to compare it with the effect size from our test output. However, there’s a catch: the power analysis reports Cohen’s omega (⍵), while the Chi-square test reports Cramer’s V. To make them comparable, we need to convert Cramer’s V into Cohen’s omega.\nThe formula to do so is:\n\\[\nCohen's \\; \\omega = Cramer's \\; V * \\sqrt(k-1)\n\\]\nwhere k s the number of categories in the variable with fewer levels.\nFor example, if one variable has 3 levels (e.g., gender) and the other has 5 (e.g., eduLevel), then k = 3.\n\nw = 0.079 * sqrt(3-1)\n\nw\n\n[1] 0.1117229\n\n\nComparison:\nWith 1,083 observations, alpha = 0.05, and power = 0.8, the smallest detectable effect size is `⍵ = 0.118. Our calculated effect size from the Chi-square test was ⍵ = 0.112. Because 0.112 is smaller than 0.118, our study is slightly underpowered, meaning there’s a higher risk of missing an effect that actually exists (a Type II error). In this case, because our Chi-square test was non-significant, the lack of significance might reflect low power rather than the true absence of an effect.\n\n\n\n\n\n\nNote\n\n\n\nIf one of your categorical variables only has 2 levels (e.g., yes/no), then Cramer’s V and Cohen’s ⍵ are identical. In that case, you can compare them directly:\n\nif Cohen’s ⍵ (sensitivity) &lt; Cramer’s V (observed), your design is sufficiently powered.\nif Cramer’s V (observed) &lt; Cohen’s ⍵ (sensitivity), your study is underpowered, and you should be cautious about drawing strong conclusions.\n\n\n\n\n\n6.4.7 Task 7: The write-up\nThe Cross-Tabulation Chi-Square Test revealed a small association between Gender and Level of Education that was not statistically significant, \\(\\chi^2(8) = 13.59, p = .093, V = .079\\). We therefore fail to reject the null hypothesis. However, a sensitivity power analysis indicated that the study was slightly underpowered, which means the non-significant result may reflect limited power rather than the true absence of an association.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#sec-onesample",
    "href": "06-chi-square-one-sample.html#sec-onesample",
    "title": "6  Chi-square and one-sample t-test",
    "section": "6.5 Activity 5: One-sample t-test",
    "text": "6.5 Activity 5: One-sample t-test\nThe one-sample t-test is used to determine whether a sample comes from a population with a specific mean. This population mean is not always known, but is sometimes hypothesised.\nWe will perform a one-sample t-test using the continuous variable wemwbs_sum. The official website for the Warwick-Edinburgh Mental Wellbeing Scales states that the “WEMWBS has a mean score of 51.0 in general population samples in the UK with a standard deviation of 7 (Tennant et al., 2007)”.\n\nPotential research question: “Is the average mental well-being of gamers different from the general population’s average well-being?”\nNull Hypothesis (H0): “The summed-up WEMWBS score of gamers is not different to 51.0.”\nAlternative Hypothesis (H1): “The summed-up WEMWBS score of gamers is different from 51.0.”\n\n\n6.5.1 Task 1: Preparing the dataframe\nFirst, we need to select the variables of interest: participant ID and wemwbs_sum.\n\none_sample &lt;- data_ballou %&gt;% \n  select(pid, wemwbs_sum)\n\n\n\n6.5.2 Task 2: Compute descriptives\nNext, we want to compute means and standard deviations for our variable of interest. This should be straight forward. Try it yourself and then compare your result with the solution below.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndescriptives &lt;- one_sample %&gt;% \n  summarise(mean_wemwbs = mean(wemwbs_sum),\n            sd = sd(wemwbs_sum))\n\ndescriptives\n\n\n\n\n\nmean_wemwbs\nsd\n\n\n\n\n45.42013\n10.88615\n\n\n\n\n\n\n\n\n\n\n\n6.5.3 Task 3: Create an appropriate plot\nThis is the plot you will want to include in your report, so make sure everything is clearly labelled. Which plot would you choose? Try creating one on your own first, then compare it with the solution below.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(one_sample, aes(x = \"\", y = wemwbs_sum)) +\n  geom_violin(fill = \"#FB8D61\", alpha = 0.4) + # alpha for opacity, fill for adding colour\n  geom_boxplot(fill = \"#FB8D61\", width = 0.5) + # change width of the boxes\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Total WEMWBS Scores\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.4 Task 4: Check assumptions\n\nAssumption 1: Continuous DV\nThe dependent variable (DV) needs to be measured at interval or ratio level. We can confirm that by looking at one_sample.\n\n\nAssumption 2: Data are independent\nThere should be no relationship between the observations. While this is an important assumption, it is more related to study design and isn’t something we can easily test for. Anyway, we will assume this assumption holds for our data.\n\n\nAssumption 3: No significant outliers\nWe can check for that visually, for example in the violin-boxplot above.\nIt appears there is one outlier in the lower tail. However, upon inspecting the one_sample data, we see it is a single participant with a score of 14, which is a possible value. Additionally, with a large sample size of 1,083 participants, removing a single outlier makes not much sense. Thus, we have checked this assumption, considered this outlier not significant, and therefore keep this observation in the dataset.\n\n\n\n\n\n\nImportant\n\n\n\nIf you decide to remove any outliers, remember to recalculate the descriptive statistics.\n\n\n\n\nAssumption 4: DV should be approximately normally distributed\nWe can already check normality from the violin-boxplot above but you could also use a histogram, a density plot, or a Q-Q plot as an alternative to assess normality visually.\nEach of these options shows that the data is normally distributed. This allows us to proceed with a parametric test, specifically a one-sample t-test.\n\n\n\n\n\n\nAlternatives to visually assess normality\n\n\n\n\n\n\nHistogramDensity plotQ-Q plot\n\n\nWe’ve already covered histograms in Chapter 5.\n\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_histogram(binwidth = 1, fill = \"magenta\")\n\n\n\n\n\n\n\n\n\n\nA density plot shows a smooth distribution curve of the data. Unlike a histogram, the height of the curve reflects the proportion of data within each range rather than the frequency of individual values. This means the curve shows where data points are concentrated, not how many times each value appears.\n\nggplot(one_sample, aes(x = wemwbs_sum)) +\n  geom_density(fill = \"magenta\")\n\n\n\n\n\n\n\n\n\n\nQ-Q plot stands for Quantile-Quantile Plot and compare two distributions by matching a common set of quantiles. Essentially, it compares the distribution of your data to a normal distribution and plots the points along a 45-degree line.\nIf the dots in the Q-Q plot fall roughly along that line, we can assume the data is normally distributed. If they stray away from the line (and worse in some sort of pattern), we might not assume normality and conduct a non-parametric test instead. For the non-parametric equivalent, see Section 6.6.\nTo create the Q-Q plot, you can use either the car or qqplotr package\n\nThe qqPlot() function is a single line but requires BaseR syntax (i.e., the $ symbol) to access the column within the data object. For example, one_sample$wemwbs_sum directs R to look for a column named wemwbs_sum that is located within the data object one_sample.\n\n\n# Version 1 with the car package\nqqPlot(one_sample$wemwbs_sum)\n\n[1] 295 394\n\n\n\n\n\n\n\n\nFigure 6.1: Q-Q plot created with the car package\n\n\n\n\n\n\nIf you have gotten used to ggplot by now, and prefer avoiding BaseR, you can use the package qqplotr. The downside is that you have to add the points, the line, and the confidence envelope yourself. On the plus, it has layers like ggplot, and is more customisable (just in case you wanted to look at something more colourful in the 2 seconds it’ll take you to assess normality).\n\n\n# Version 2 with package qqplotr\nggplot(one_sample, aes(sample = wemwbs_sum)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n\n\n\n\n\n\n\nFigure 6.2: Q-Q plot created with the qqplotr package\n\n\n\n\n\n\n\n\n\n\n\nYou could also assess normality with the Shapiro-Wilk’s test. The null hypothesis is that the population is distributed normally. Therefore, if the p-value of the Shapiro-Wilk’s test smaller than .05, normality is rejected.\n\n\n\n\n\n\nImportant\n\n\n\nShapiro-Wilk is an OK method for small sample sizes (e.g., smaller than 50 samples) if the deviation from normality is fairly obvious. If we are dealing with slight deviations from normality, it might not be sensitive enough to pick that up. But t-tests, ANOVAs etc. should be robust for slight deviations from normality anyway.\nIn contrast, when you have large sample sizes, Shapiro-Wilk is overly sensitive and will definitely produce a significant p-value regardless of what the distribution looks like. So don’t rely on its output when you have large sample sizes, and be mindful of its output when you have small sample sizes.\n\n\nThe function in R for this test is shapiro.test() which is part of BaseR. This means, we need to specify our data object, use the $, and indicate the column we want to address.\n\nshapiro.test(one_sample$wemwbs_sum)\n\n\n    Shapiro-Wilk normality test\n\ndata:  one_sample$wemwbs_sum\nW = 0.99404, p-value = 0.0002619\n\n\nNo surprise here! The test shows a p-value of &lt; .001 due to our large sample size of over 1000 participants. Nevertheless, if you decided on using the Shapiro-Wilk test in your report, you’d need to write this result up in APA style: \\(W = .99, p &lt; .001\\).\n\n\n\n\n\n\nReport-writing Tip\n\n\n\nEither choose visual or computational inspection for normality tests. NO NEED TO DO BOTH!!!\n\nState what method you used and your reasons for choosing the method (visual/computational and what plot/test you used)\nState the outcome of the test - for visual inspection just say whether normality assumption held or not (no need to include that extra plot in the results section). For computational methods, report the test result in APA style\nState the conclusions you draw from it - parametric or non-parametric test\n\n\n\n\n\n\n6.5.5 Task 5: Compute a One-sample t-test and effect size\nTo compute a one-sample t-test, we can use the t.test() function, which is part of Base R. And yes, you guessed it, our first argument should follow the pattern data$column. The second argument, mu, specifies the population mean we are testing our sample against (in this case, 51.0). The alternative is “two.sided” by default, so it can be omitted if you are conducting a two-sided test.\n\nt.test(one_sample$wemwbs_sum, mu = 51.0, alternative = \"two.sided\")\n\n\n    One Sample t-test\n\ndata:  one_sample$wemwbs_sum\nt = -16.868, df = 1082, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 51\n95 percent confidence interval:\n 44.77106 46.06920\nsample estimates:\nmean of x \n 45.42013 \n\n\nThe output is quite informative. It provides information about:\n\nthe variable column that was tested,\nthe t value, degrees of freedom, and p,\nthe alternative hypothesis,\na 95% confidence interval,\nand the mean of the column (which matches the one we computed in the descriptive - yay)\n\nWhat it doesn’t give us is an effect size. Meh. So we will need to compute one ourselves.\nWe will calculate Cohen’s d using the function cohensD() from the lsr package. Similar to the t-test we just conducted, the first argument is data$column, the second argument is mu.\n\ncohensD(one_sample$wemwbs_sum, mu = 51.0)\n\n[1] 0.5125662\n\n\n\n\n6.5.6 Task 6: Sensitivity power analysis\nA sensitivity power analysis allows you to determine the minimum effect size that the study could reliably detect given the number of participants you have in the sample (i.e., sample size), the alpha level at 0.05, and an assumed power of 0.8.\nTo perform this calculation, we use the pwr.t.test() function from the pwr package. This function relies on four key factors — alpha, power, effect size, and sample size (APES). If you know three, you can calculate the fourth. Since we have three specified, we can solve for the effect size. Additionally, we need to specify the type argument to indicate we are using a one-sample t-test, and set alternative to “two.sided” for a non-directional hypothesis.\n\npwr.t.test(n = 1083, sig.level = 0.05, power = 0.8, type = \"one.sample\")\n\n\n     One-sample t test power calculation \n\n              n = 1083\n              d = 0.08520677\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nSo the smallest effect size we can detect with a sample size of 1083, an alpha level of 0.05, and power of 0.8 is 0.09. This is a smaller value than the actual effect size we calculated with our CohensD function above (i.e., 0.51) which means our analysis is sufficiently powered.\n\n\n6.5.7 Task 7: The write-up\nA one-sample t-test was computed to determine whether the average mental well-being of gamers as measured by the WEMWBS was different to the population well-being mean. The average WEMWBS of the gamers \\((N = 1083, M = 45.42, SD = 10.89)\\) was significantly lower than the population mean well-being score of 51.0, \\(t(1082) = 16.87, p &lt; .001, d = .51\\). The strength of the effect is considered medium and the study was sufficiently powered. We therefore reject the null hypothesis in favour of H1.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#sec-alternative_one_sample",
    "href": "06-chi-square-one-sample.html#sec-alternative_one_sample",
    "title": "6  Chi-square and one-sample t-test",
    "section": "6.6 Activity 6: Non-parametric alternative",
    "text": "6.6 Activity 6: Non-parametric alternative\nIf any of the assumptions are violated, switch to the non-parametric alternative. For the one-sample t-test, this would be a One-sample Wilcoxon signed-rank test. Instead of the mean, it compares the median of a sample against a single value (i.e., the population median).\nThat means we will need to determine the population median, and calculate some summary stats for our sample:\n\nThe population median is listed in a supporting document on the official WEMWBS website as 53.0.\nWe can easily calculate the summary statistics using the function summary().\n\n\nsummary(one_sample)\n\n     pid              wemwbs_sum   \n Length:1083        Min.   :14.00  \n Class :character   1st Qu.:38.00  \n Mode  :character   Median :46.00  \n                    Mean   :45.42  \n                    3rd Qu.:53.00  \n                    Max.   :70.00  \n\n\nThe function to compute a one-sample Wilcoxon test is wilcox.test() which is part of BaseR. Code-wise, it works very similar to the one-sample t-test.\n\nwilcox.test(one_sample$wemwbs_sum, mu = 53.0)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  one_sample$wemwbs_sum\nV = 87218, p-value &lt; 2.2e-16\nalternative hypothesis: true location is not equal to 53\n\n\nAs we can see, the output shows a V value, but for the final write-up, we need to report the standardised test statistic Z in the final write-up. Unfortunately, this requires manual calculation. According to Andy Field (2012, p. 665), we need to use the qnorm function on the halved p-value from our Wilcoxon test above. Here, we store the p-value in the Global Environment as p_wilcoxon. This retains more decimal places than shown in the output, giving us a more precise Z value.”\n\n# storing the p-value\np_wilcoxon &lt;- wilcox.test(one_sample$wemwbs_sum, mu = 53.0)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n\n[1] -19.12264\n\n\nWe also need to calculate the effect size r for the One-sample Wilcoxon signed-rank test. This can be done using the wilcoxonOneSampleR() function from the rcompanion package. By default, the result is rounded to three decimal places, but you can adjust this by adding the digits argument.\n\nwilcoxonOneSampleR(one_sample$wemwbs_sum, mu = 53.0, digits = 3)\n\n    r \n-0.59 \n\n\nNow we have all the numbers we need to write up the results:\nA One-sample Wilcoxon signed-rank test was used to compare Gamers’ mental-wellbeing median scores (Mdn = 46.0) to the population median of 53.0. The test showed a significant difference, \\(Z = -19.12, p &lt; .001, r = .590\\). The strength of the effect is considered medium. We therefore reject the null hypothesis in favour of H1.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "06-chi-square-one-sample.html#test-your-knowledge",
    "href": "06-chi-square-one-sample.html#test-your-knowledge",
    "title": "6  Chi-square and one-sample t-test",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1: Conceptual Understanding - Chi-Square Test\nWhat is the primary purpose of a Chi-square test?\n\n To assess the correlation between two continuous variables To test the relationship between categorical variables To test for differences in variances To compare means between two groups\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe Chi-square test evaluates whether there is an association or relationship between two categorical variables. Those variables can either be nominal or ordinal.\n\n\n\n\n\nQuestion 2: Application - Chi-Square Test\nWhich of the following scenarios would require a Chi-square test?\n\n Comparing the average exam scores of students in two classrooms Determining if there is an association between people’s favourite pizza topping and their region of residence Testing whether the average height of basketball players differs from the general population Assessing whether the reaction times of drivers are influenced by caffeine consumption\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe only option with 2 categorical variables is pizza topping (e.g., pepperoni, vegetarian, cheese) and region of residence (e.g., North, South, East, West).\n\n\n\n\n\nQuestion 3: Interpreting Output - Chi-Square Test\nIn a Chi-square test, the p-value is .005. What does this imply if the significance level is set at .05?\n\n The null hypothesis is rejected; there is no significant association. The null hypothesis is not rejected; there is a significant association. The null hypothesis is not rejected; there is no significant association. The null hypothesis is rejected; there is a significant association.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nA p-value of .005 is less than the significance level (.05), indicating that the observed association between the variables is unlikely to have happened by chance.\n\n\n\n\n\nQuestion 4: Using R - Chi-Square Test\nWhich of the following R functions is used to perform a Chi-square test and displays a Cramer’s V in the output?\n\n t.test() one.sample() associationTest() chisq.test()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe associationTest() function from the lsr package performs a Chi-square test and directly provides Cramer’s V as part of the output. The chisq.test() function exists it but does not compute Cramer’s V. The other options either don’t exist or don’t meet the criteria.\n\n\n\n\n\nQuestion 5: Conceptual Understanding - One-sample t-test\nWhat is the null hypothesis in a one-sample t-test?\n\n The sample mean is equal to the population mean The sample mean is greater than the population mean The sample mean is less than the population mean The population mean is equal to zero\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe one-sample t-test tests whether the sample mean is significantly different from a known or hypothesised population mean.\n\n\n\n\n\nQuestion 6: Application - One-sample t-test\nWhich of the following scenarios would require a one-sample t-test?\n\n Comparing the average exam scores of students in two classrooms Determining if there is an association between people’s favourite pizza topping and their region of residence Testing whether the average height of basketball players differs from the general population Assessing whether the reaction times of drivers are influenced by caffeine consumption\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nA one-sample t-test is appropriate when comparing the mean of a single sample (e.g., basketball players’ heights) to a known or hypothesised population mean (e.g., mean of the general population). The other options involve comparisons between groups (option 1), categorical associations (option 2), or repeated measures (option 4).\n\n\n\n\n\nQuestion 7: Interpreting Output - One-sample t-test\nIf the p-value in a one-sample t-test is .15 and the significance level is .05, what is the conclusion?\n\n The sample mean is not significantly different from the population mean. The sample mean is significantly different from the population mean. The sample mean is equal to the population mean. The sample mean is further from the population mean than expected by chance.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nSince the p-value (.15) is greater than the significance level (.05), we fail to reject the null hypothesis. This means there is no evidence to suggest that the sample mean is significantly different from the population mean.\nHowever, this does not mean we have evidence to confirm that the sample mean is exactly equal to the population mean. In statistics, ‘not significantly different’ is not the same as ‘equal.’ Therefore, the option ‘The sample mean is equal to the population mean’ is incorrect.\n\n\n\n\n\nQuestion 8: Using R - One-sample t-test\nWhich of the following R functions is used to perform a one-sample t-test?\n\n t.test() associationTest() chisq.test() one.sample()\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nt.test() is the standard function in R for performing a one-sample t-test. In the next 2 weeks, we will see that the function can also be used for two-sample and paired t-tests.\nThe function one.sample() does not exist.\nThe other two functions perform Chi-square tests, which are specifically designed for categorical variables. They cannot be used when one of the variables is continuous.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Chi-square and one-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html",
    "href": "07-independent.html",
    "title": "7  Two-sample t-test",
    "section": "",
    "text": "Intended Learning Outcomes\nIn this chapter, we will focus on two-sample t-tests, also known as between-groups, between-subjects, or independent-samples t-tests. By the end of this chapter, you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#intended-learning-outcomes",
    "href": "07-independent.html#intended-learning-outcomes",
    "title": "7  Two-sample t-test",
    "section": "",
    "text": "Compute a two-sample t-test and effectively report the results.\nUnderstand when to use a non-parametric equivalent of the two-sample t-test, compute it, and report the results.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#individual-walkthrough",
    "href": "07-independent.html#individual-walkthrough",
    "title": "7  Two-sample t-test",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-1-setup-download-the-data",
    "href": "07-independent.html#activity-1-setup-download-the-data",
    "title": "7  Two-sample t-test",
    "section": "7.1 Activity 1: Setup & download the data",
    "text": "7.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2A_chapter7”, or “07_independent_ttest”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you get stuck.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the reduced version of a new dataset here: data_ch7.zip. The zip folder includes the following files:\n\nCodebookSimonTask.xlsx: A codebook with detailed variable descriptions\nDemoSimonTask.csv: A CSV file containing demographic information\nMeanSimonTask.csv: A CSV file with the mean response times\nSup_Mats_Simon_Task.docx: A Word document with Supplementary Materials providing additional details about the task\nRawDataSimonTask.csv: The raw data file, allowing you to explore what experimental data looks like prior to pre-processing.\n\nExtract the data files from the zip folder and place them in your project folder. If you need help, see Section 1.4.\n\nCitation\n\nZwaan, R. A., Pecher, D., Paolacci, G., Bouwmeester, S., Verkoeijen, P., Dijkstra, K., & Zeelenberg, R. (2018). Participant nonnaiveté and the reproducibility of cognitive psychology. Psychonomic Bulletin & Review, 25, 1968-1972. https://doi.org/10.3758/s13423-017-1348-y\n\nThe data and supplementary materials are available on OSF: https://osf.io/ghv6m/\nAbstract\n\nMany argue that there is a reproducibility crisis in psychology. We investigated nine well-known effects from the cognitive psychology literature—three each from the domains of perception/action, memory, and language, respectively—and found that they are highly reproducible. Not only can they be reproduced in online environments, but they also can be reproduced with nonnaïve participants with no reduction of effect size. Apparently, some cognitive tasks are so constraining that they encapsulate behavior from external influences, such as testing situation and prior recent experience with the experiment to yield highly robust effects.\n\nChanges made to the dataset\n\nThe dataset, demographic information, and Supplementary Materials have been reduced to include only information related to the Simon Task. The full dataset, which includes the other eight tasks, is available on OSF.\nNo other changes were made.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-2-library-and-data-for-today",
    "href": "07-independent.html#activity-2-library-and-data-for-today",
    "title": "7  Two-sample t-test",
    "section": "7.2 Activity 2: Library and data for today",
    "text": "7.2 Activity 2: Library and data for today\nToday, we’ll be using the following packages: rstatix, tidyverse, car, lsr, and pwr. You may need to install the packages before using them (see Section 1.5.1 if you need some help). Make sure that rstatix is loaded in before tidyverse to avoid masking certain functions that we will need later.\nWe will also read in the data from MeansSimonTask.csv and the demographic information from DemoSimonTask.csv.\n\n# load in the packages\n???\n\n# read in the data\nzwaan_data &lt;- ???\nzwaan_demo &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# load in the packages\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(car)\nlibrary(lsr)\nlibrary(pwr)\n\n# read in the data\nzwaan_data &lt;- read_csv(\"MeansSimonTask.csv\")\nzwaan_demo &lt;- read_csv(\"DemoSimonTask.csv\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-3-familiarise-yourself-with-the-data",
    "href": "07-independent.html#activity-3-familiarise-yourself-with-the-data",
    "title": "7  Two-sample t-test",
    "section": "7.3 Activity 3: Familiarise yourself with the data",
    "text": "7.3 Activity 3: Familiarise yourself with the data\nAs usual, take some time to familiarise yourself with the data before starting on the between-subjects t-test. Also, more importantly, have a look at the Supplementary Materials in which the Simon effect is explained in more depth.\nIn general, the Simon effect refers to the phenomenon where participants respond faster when the stimulus appears on the same side of the screen as the button they need to press (i.e., a congruent condition). Conversely, response times are slower when the stimulus appears on the opposite side of the screen from the required button (i.e., an incongruent condition).\nIn this experiment, all participants completed two sessions of trials. However, they were divided into two groups based on the stimuli they received:\n\nSame Stimuli Group: Half of the participants received the same set of stimuli in both sessions.\nDifferent Stimuli Group: The other half received a different set of stimuli in session 2 compared to session 1.\n\n\n7.3.1 Potential research questions and hypotheses\n\nPotential research question: “Is there a significant difference in the Simon effect between participants who received the same stimuli in both sessions compared to those who received different stimuli?”\nNull Hypothesis (H0): “There is no significant difference in the Simon effect between participants who received the same stimuli in both sessions and those who received different stimuli.”\nAlternative Hypothesis (H1): “There is a significant difference in the Simon effect between participants who received the same stimuli in both sessions and those who received different stimuli.”",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-4-preparing-the-dataframe",
    "href": "07-independent.html#activity-4-preparing-the-dataframe",
    "title": "7  Two-sample t-test",
    "section": "7.4 Activity 4: Preparing the dataframe",
    "text": "7.4 Activity 4: Preparing the dataframe\nThe data is already in a very good shape, however, we need to perform some data wrangling to compute the Simon effect.\nSteps to calculate the Simon effect:\n\nFor each participant, compute the mean response time (RT) for congruent trials and the mean RT for incongruent trials\nSubtract the mean RT of congruent trials from the mean RT of incongruent trials to calculate the Simon effect\n\nTo streamline analysis, we should join this output with the demographics data to have all relevant information in one place.\nBasically, we want to create a tibble that has the following content. [Note that I re-arranged the columns and re-labelled some of them in a final step, so your column names and/or order might be slightly different, but content should match.]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant\ngender\nage\neducation\nsimilarity\ncongruent\nincongruent\nsimon_effect\n\n\n\n\nT1\nFemale\n50\nHigh school\nsame\n475.0032\n508.2835\n33.28029\n\n\nT10\nMale\n45\nAssociate’s degree\nsame\n420.1515\n401.5800\n-18.57148\n\n\nT109\nMale\n33\nBachelor’s degree\nsame\n339.5343\n375.7152\n36.18085\n\n\nT11\nFemale\n71\nHigh school\nsame\n516.9722\n542.3111\n25.33889\n\n\nT111\nFemale\n34\nHigh school\nsame\n373.5778\n394.0665\n20.48874\n\n\n\n\n\n\nObviously, there are various ways to achieve this, so feel free to explore and come up with your own approach. However, we will provide step-by-step instructions for one of those ways that will get you the desired output.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nStep 1: Convert the data from wide format to long format, so that all RT values are consolidated into a single column. This transformation will result in each participant having four rows.\nStep 2: There should be a column now that contained the previous column headings with information on session number and congruency. Separate this information into 2 separate columns (i.e., session number and congruency).\nStep 3: Compute the mean RT values for each combination of participant, similarity, and congruency\nStep 4: Pivot the data back to wide format so that the mean RT values for congruent and incongruent trials are placed in two separate columns.\nStep 5: Add a new column called the simon_effect that calculates the Simon effect by subtracting the mean RT for congruent trials from the mean RT for incongruent trials.\nStep 6: Merge this processed dataset with the demographics data to ensure all relevant information is in one table.\nStep 7: Feel free to rearrange the order of columns and/or rename them to match your output with ours (not strictly necessary tbh)\n\n\n\n\n\n\n\nSolution to the steps outlined above\n\n\n\n\n\n\nsimon_effect &lt;- zwaan_data %&gt;% \n  pivot_longer(cols = session1_congruent:session2_incongruent, names_to = \"col_headings\", values_to = \"RT\") %&gt;% \n  separate(col_headings, into = c(\"Session_number\", \"congruency\"), sep = \"_\") %&gt;% \n  group_by(participant, similarity, congruency) %&gt;% \n  summarise(mean_RT = mean(RT)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = congruency, values_from = mean_RT) %&gt;% \n  mutate(simon_effect = incongruent - congruent) %&gt;% \n  full_join(zwaan_demo, by = join_by(participant == twosubjectnumber)) %&gt;% \n  select(participant, gender = gender_response, age = age_response, education = education_response, similarity:simon_effect)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-5-compute-descriptives",
    "href": "07-independent.html#activity-5-compute-descriptives",
    "title": "7  Two-sample t-test",
    "section": "7.5 Activity 5: Compute descriptives",
    "text": "7.5 Activity 5: Compute descriptives\nNext, we want to compute number of participants (n), means and standard deviations for each group (i.e., same and different) of our variable of interest (i.e., simon_effect).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndescriptives &lt;- simon_effect %&gt;% \n  group_by(similarity) %&gt;% \n  summarise(n = n(),\n            mean_RT = mean(simon_effect),\n            sd_RT = sd(simon_effect)) %&gt;% \n  ungroup()\n\ndescriptives\n\n\n\n\n\nsimilarity\nn\nmean_RT\nsd_RT\n\n\n\n\ndifferent\n80\n32.85726\n20.79313\n\n\nsame\n80\n35.99415\n22.39601",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-6-create-an-appropriate-plot",
    "href": "07-independent.html#activity-6-create-an-appropriate-plot",
    "title": "7  Two-sample t-test",
    "section": "7.6 Activity 6: Create an appropriate plot",
    "text": "7.6 Activity 6: Create an appropriate plot\nWhich plot would you choose to represent the data appropriately? Create a plot that effectively visualises the data, and then compare it with the solution provided below.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(simon_effect, aes(x = similarity, y = simon_effect, fill = similarity)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.4, alpha = 0.8) +\n  scale_fill_viridis_d(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"Similarity\", y = \"Simon effect\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-7-check-assumptions",
    "href": "07-independent.html#activity-7-check-assumptions",
    "title": "7  Two-sample t-test",
    "section": "7.7 Activity 7: Check assumptions",
    "text": "7.7 Activity 7: Check assumptions\n\nAssumption 1: Continuous DV\nThe dependent variable must be measured at interval or ratio level. We can confirm that by looking at simon_effect.\n\n\nAssumption 2: Data are independent\nThere should be no relationship between the observations. Scores in one condition or observation should not influence scores in another. We assume this assumption holds for our data.\n\n\nAssumption 3: Homoscedasticity (homogeneity of variance)\nThis assumption requires the variances between the two groups to be similar (i.e., homoscedasticity). If the variances between the 2 groups are dissimilar/unequal, we have heteroscedasticity.\nWe can test this using a Levene’s Test for Equality of Variance which is available in the package car. The first argument specifies the formula in the format DV ~ IV. Here:\n\nThe dependent variable (DV) is simon_effect (continuous)\nThe independent variable (IV) is similarity (the grouping variable)\n\nTo perform the test, separate the variables with a tilde (~), and specify the dataset using the data argument:\n\nleveneTest(simon_effect ~ similarity, data = simon_effect)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n1\n0.7263221\n0.3953679\n\n\n\n158\nNA\nNA\n\n\n\n\n\n\nThe warning message tells us that the grouping variable was converted into a factor. Oops, I guess we forgot to convert similarity into a factor during data wrangling.\nThe test output shows a p-value greater than .05. This indicates that we do not have enough evidence to reject the null hypothesis. Therefore, the variances across the two groups can be assumed equal.\nYou would report this result in APA style: A Levene’s test of homogeneity of variances was used to compare the variances of the same and the different groups. The test indicated that the variances were homogeneous, \\(F(1,158) = 0.73, p = .395\\).\n\n\n\n\n\n\nImportant\n\n\n\nThe t-test we are conducting is a Welch t-test by default. The Welch t-test provides similar results to a Student’s t-test when variances are equal but is preferred when variances are unequal.\nThis means that even if Levene’s test returns a significant p-value, indicating that the variances between the groups are unequal, the Welch t-test remains appropriate and valid for analysis.\n\n\n\n\nAssumption 4: DV should be approximately normally distributed\nIt’s important to note that this assumption requires the dependent variable to be normally distributed within each group.\nWe can either use our eyeballs again on the violin-boxplot we created earlier (or use a qqplot, density plot, or histogram instead), OR compute a statistic like the Shapiro-Wilk’s test we already mentioned previously for the one-sample t-test. However, keep in mind that with large sample sizes (approximately 80 participants per group), this test may flag minor deviations from normality as significant, even if the data is reasonably normal.\nVisual inspection suggests that both groups are approximately normally distributed. The “same” group appears slightly more normally distributed than the “different” group, which has a small peak in the lower tail. Despite this, both distributions seem normal enough for practical purposes with real-world data.\n\n\n\n\n\n\nTip: Visual inspection\n\n\n\nIf you want to use a histogram, density plot or qqplot (the ones created with the ggplot2 and qqplotr packages), you can simply add a facet_wrap() function to display the plots separately for each group.\nIf you are using the Q-Q plot function from the car package, you will need to create separate data objects filtered for each group before generating Q-Q plots for the groups individually.\n\n\n\n\n\n\n\n\nTask: Compute Shapiro-Wilk’s test\n\n\n\nAs mentioned above, the function for the Shapiro-Wilk’s test does not allow for a formula. This means you will need to create separate data objects for the two groups first. Consider this a good opportunity to practice using the filter() function.\nStep-by-step instructions:\n\nCreate separate data objects for the same and different groups.\nRun the Shapiro-Wilk test on each group’s data.\nExamine the results. What do you conclude from the test outcomes?\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## same group\nsame &lt;- simon_effect %&gt;% \n  filter(similarity == \"same\")\n\nshapiro.test(same$simon_effect)\n\n\n    Shapiro-Wilk normality test\n\ndata:  same$simon_effect\nW = 0.98921, p-value = 0.7447\n\n## different group\ndifferent &lt;- simon_effect %&gt;% \n  filter(similarity == \"different\")\n\nshapiro.test(different$simon_effect)\n\n\n    Shapiro-Wilk normality test\n\ndata:  different$simon_effect\nW = 0.96949, p-value = 0.05262\n\n\nInterpretation:\nShapiro-Wilk’s test also suggests that the data for both groups, “same” and “different”, are normally distributed as all p-values are above .05.\nAgain, if you used this method in your report, you would have to write up the results in APA style (refer to the section on the one-sample t-test for guidance on reporting).\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you have read the Delacre et al. (2017) paper (https://rips-irsp.com/articles/10.5334/irsp.82), you might be aware that the normality assumption is not critical for the Welch t-test.\nThis means that, whether you consider both groups to be “normally distributed” or interpret one as slightly deviating from normality, the Welch t-test remains an appropriate choice for this dataset.\n\n\nAfter verifying all the assumptions, we concluded that they were met. Therefore, we will compute a Welch two-sample t-test.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-8-compute-a-two-sample-t-test-and-effect-size",
    "href": "07-independent.html#activity-8-compute-a-two-sample-t-test-and-effect-size",
    "title": "7  Two-sample t-test",
    "section": "7.8 Activity 8: Compute a Two-sample t-test and effect size",
    "text": "7.8 Activity 8: Compute a Two-sample t-test and effect size\nThe t.test() function, which we previously used for the one-sample t-test, can also be used here, but with a slightly different approach. It supports a formula option, which simplifies the process. This means we don’t need to wrangle the data further or use the $ operator to access columns directly. Instead, we can specify the formula as DV ~ IV.\nThe key arguments for t.test() are:\n\nThe first argument in the formula with the pattern DV ~ IV\nThe second argument is the data\nThe third argument is specifying whether variances are equal between the groups. The default value is var.equal = FALSE, which conducts a Welch t-test. If you set var.equal = TRUE, you would conduct a Student t-test instead.\nThe 4th argument alternative specifies the alternative hypothesis. The default value is “two.sided”, meaning the test will check for differences in both directions (i.e., a non-directional hypothesis)\n\n\nt.test(simon_effect ~ similarity, data = simon_effect, var.equal = FALSE, alternative = \"two.sided\")\n\n\n    Welch Two Sample t-test\n\ndata:  simon_effect by similarity\nt = -0.91809, df = 157.14, p-value = 0.36\nalternative hypothesis: true difference in means between group different and group same is not equal to 0\n95 percent confidence interval:\n -9.885574  3.611799\nsample estimates:\nmean in group different      mean in group same \n               32.85726                35.99415 \n\n\nThe output of the t.test() function tells us:\n\nthe type of test that was conducted (here Welch t-test)\nthe variables that were tested (here simon_effect by similarity),\nthe t-value, degrees of freedom, and p,\nthe alternative hypothesis tested,\na 95% confidence interval for the difference between group means, and\nthe mean of both groups (which should match our descriptive stats)\n\nThe t.test() function does not calculate an effect size, so we have to compute it separately once again. As with the one-sample t-test, we can use the CohensD() function from the lsr package. The formula-based approach works here too. For the Welch version of the t-test, you need to include the argument method = \"unequal\" in the CohensD() function to account for unequal variances.\n\ncohensD(simon_effect ~ similarity, data = simon_effect, method = \"unequal\")\n\n[1] 0.1451628",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-9-sensitivity-power-analysis",
    "href": "07-independent.html#activity-9-sensitivity-power-analysis",
    "title": "7  Two-sample t-test",
    "section": "7.9 Activity 9: Sensitivity power analysis",
    "text": "7.9 Activity 9: Sensitivity power analysis\nNext, we will conduct a sensitivity power analysis to determine the minimum effect size that could have been reliably detected with our sample size, an alpha level of 0.05, and a power of 0.8.\nTo perform this analysis, we use the pwr.t.test() from the pwr package. The arguments are the same as those used for the one-sample t-test, but with a few adjustments:\n\nNumber of Participants: Specify the number of observations per sample (i.e., n)\nTest Type: Set the type argument to “two.sample” for a two-sample t-test.\n\n\npwr.t.test(n = 80, sig.level = 0.05, power = 0.8, type = \"two.sample\", alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 80\n              d = 0.445672\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\nSooo, the smallest effect size we can detect with a sample size of 80 participants in each group, an alpha level of .05, and power of .8 is 0.45. Our observed effect size was only 0.15 (calculated with the CohensD() function). Because the observed effect is smaller than the smallest detectable effect, the analysis is underpowered, meaning it is unlikely to detect such a small effect reliably.\n\nHypothetical Replication Study\nOut of curiosity, if we were to replicate this study and wanted to reliably detect an effect size as small as 0.15, how many participants would we need?\nWe can use the pwr.t.test() function again. This time, instead of specifying n, we provide the effect size (d = 0.145). The result shows that we would need approximately 1,500 participants in total (750 per group). Ooft; that’s quite a few people to recruit.\nHowever, it’s worth noting that an effect size of 0.15 may not be practically meaningful, even if statistically detectable.\n\npwr.t.test(d = 0.145, sig.level = 0.05, power = 0.8, type = \"two.sample\", alternative = \"two.sided\")\n\n\n     Two-sample t test power calculation \n\n              n = 747.5833\n              d = 0.145\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n\n\n\n\n\n\n\n\nBut my two groups have unequal sample sizes, and there is only one n in pwr.t.test. What do I do?\n\n\n\nNo problem! You can use the pwr.t2n.test() function, which allows you to specify different sample sizes for the two groups (n1 and n2).\nThe rest of the arguments are essentially the same as with pwr.t.test(). Additionally, there is no need to specify the type argument, as the function is specifically designed for two-sample t-tests with unequal sample sizes.\n\npwr.t2n.test(n1 = NULL, n2= NULL, d = NULL, sig.level = 0.05, power = NULL, alternative = c(\"two.sided\", \"less\",\"greater\"))\n\nLet’s try it for our example. We should get the same result though.\n\npwr.t2n.test(n1 = 80, n2= 80, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")\n\n\n     t test power calculation \n\n             n1 = 80\n             n2 = 80\n              d = 0.445672\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#activity-10-the-write-up",
    "href": "07-independent.html#activity-10-the-write-up",
    "title": "7  Two-sample t-test",
    "section": "7.10 Activity 10: The write-up",
    "text": "7.10 Activity 10: The write-up\nWe hypothesised that there would be a significant difference in the Simon effect between participants who received the same stimuli in both sessions \\((N = 80, M = 35.99 \\ \\text{msec}, SD = 22.40 \\ \\text{msec})\\) and those who received different stimuli \\((N = 80, M = 32.86 \\ \\text{msec}, SD = 20.79 \\ \\text{msec})\\). A Welch two-sample t-test revealed the small effect to be non-significant, \\(t(157.14) = 0.92, p = .360, d = 0.15\\). Therefore, we fail to reject the null hypothesis. However, the analysis was underpowered to reliably detect such a small effect.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#sec-alternative_two_sample",
    "href": "07-independent.html#sec-alternative_two_sample",
    "title": "7  Two-sample t-test",
    "section": "7.11 Activity 11: Non-parametric alternative",
    "text": "7.11 Activity 11: Non-parametric alternative\nThe Mann-Whitney U-test is the non-parametric equivalent of the independent two-sample t-test. It is used to compare the medians of two samples and is particularly useful when the assumptions of the t-test are not met.\nAccording to Delacre et al. (2017), the Mann-Whitney U-test is robust to violations of normality but remains sensitive to heteroscedasticity. In this case, we don’t need to worry about heteroscedasticity, as the variances in the two groups are equal. However, it’s important to keep this in mind when assessing assumptions and interpreting results with other datasets.\nFirst, let’s start by computing some summary statistics for each group.\n\nsimon_effect %&gt;% \n  group_by(similarity) %&gt;% \n  summarise(n = n(), \n            median = median(simon_effect))\n\n\n\n\n\nsimilarity\nn\nmedian\n\n\n\n\ndifferent\n80\n34.44134\n\n\nsame\n80\n35.68470\n\n\n\n\n\n\nTo conduct a Mann-Whitney U-test, use the wilcox.test() function. As with the independent t-test, you can use the formula approach DV ~ IV. The code structure is identical to what we used for the independent t-test.\n\nwilcox.test(simon_effect ~ similarity, data = simon_effect)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  simon_effect by similarity\nW = 3001, p-value = 0.4981\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe should compute the standardised test statistic Z manually. To do this, use the qnorm() function on the halved p-value obtained from the Wilcoxon test conducted earlier.\n\n# storing the p-value\np_wilcoxon &lt;- wilcox.test(simon_effect ~ similarity, data = simon_effect)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n\n[1] -0.6774047\n\n\nThe effect size for the Mann-Whitney U-test is r. To compute r, we’d need the standardised test statistic z and divide that the square-root of the number of pairs n: \\(r = \\frac{|z|}{\\sqrt n}\\).\nAlternatively, you can use the wilcox_effsize() function from the rstatix package to simplify the process.\nThe arguments for this function are slightly different in order but otherwise identical to those used in the wilcox.test() function above.\n\nwilcox_effsize(data = simon_effect, formula = simon_effect ~ similarity)\n\n\n\n\n\n.y.\ngroup1\ngroup2\neffsize\nn1\nn2\nmagnitude\n\n\n\n\nsimon_effect\ndifferent\nsame\n0.0536884\n80\n80\nsmall\n\n\n\n\n\n\nThis is once again considered a small effect. Anyway, we do have all the numbers now to write up the results:\nA Mann-Whitney U-test was conducted to determine whether there was a significant difference in the Simon effect between participants who received the same stimuli in both sessions \\((N = 80, Mdn = 35.68 \\ \\text{msec})\\) and those who received different stimuli \\((N = 80, Mdn = 34.44 \\ \\text{msec})\\). The results indicate that the median difference in response time was non-significant and of small magnitude, \\(W = 3001, Z = -0.68, p = .498, r = .054\\). Therefore, we fail to reject the null hypothesis.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "07-independent.html#test-your-knowledge",
    "href": "07-independent.html#test-your-knowledge",
    "title": "7  Two-sample t-test",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nWhat is the main purpose of an independent t-test?\n\n To compare means between two related groups To compare means between two independent groups To test for differences in variances between two independent groups To assess the correlation between two continuous variables\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe independent t-test is specifically designed to compare the means of two separate (independent) groups to determine whether the difference between their means is statistically significant. For example, it could be used to compare the test scores of students who received two different teaching methods (Group 1 vs. Group 2).\n\n\n\n\n\nQuestion 2\nWhich of the following is a key assumption of the two-sample t-test that should be considered?\n\n The independent variable is normally distributed The dependent variable is categorical The observations are independent of each other The sample sizes must be equal\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIndependence of observations is a crucial assumption for the two-sample t-test. It means that the data collected from one participant should not influence the data from another participant.\n\n\n\n\n\nQuestion 3\nHow can you recognise the difference between the output of a Student’s t-test and a Welch t-test?\n\n The Welch t-test uses medians instead of means, unlike the Student’s t-test. The Welch t-test reports non-integer degrees of freedom, while the Student’s t-test reports integer degrees of freedom. The Welch t-test includes a confidence interval, while the Student’s t-test does not. The Welch t-test reports an effect size directly, while the Student’s t-test does not.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe Welch t-test adjusts for unequal variances and sample sizes, which leads to non-integer degrees of freedom. In contrast, the Student’s t-test assumes equal variances and reports integer degrees of freedom based on total sample size minus the number of groups.\nThe other options are incorrect:\n\nBoth tests report confidence intervals for the mean difference.\nBoth tests compare means, not medians.\nNeither test reports effect size directly; it must be calculated separately (e.g., using Cohen’s d).\n\n\n\n\n\n\nQuestion 4\nYou perform an independent t-test and find \\(t(48)=2.10,p=.042,d=0.58\\). How would you interpret these results?\n\n There is a significant difference between the two groups, with a medium effect size. There is no significant difference between the two groups There is a significant difference between the two groups, with a small effect size. There is a significant difference between the two groups, with a large effect size.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe p-value (\\(p=.042\\)) is less than the common significance threshold of 0.05, indicating that the difference between the two groups is statistically significant. This means we reject the null hypothesis and conclude that there is evidence of a difference between the group means.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Two-sample t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html",
    "href": "08-paired.html",
    "title": "8  Paired t-test",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#intended-learning-outcomes",
    "href": "08-paired.html#intended-learning-outcomes",
    "title": "8  Paired t-test",
    "section": "",
    "text": "Compute a paired t-test and effectively report the results.\nUnderstand when to use a non-parametric equivalent of the paired t-test, compute it, and report the results.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#individual-walkthrough",
    "href": "08-paired.html#individual-walkthrough",
    "title": "8  Paired t-test",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-1-setup",
    "href": "08-paired.html#activity-1-setup",
    "title": "8  Paired t-test",
    "section": "8.1 Activity 1: Setup",
    "text": "8.1 Activity 1: Setup\nIn this chapter, we will continue working with the dataset from the study by Zwaan et al. (2018). Have a look at Chapter 7 or the SupMats document if you need a refresher on the Simon Task data.\n\nOpen last week’s project\nCreate a new .Rmd file and save it to your project folder\nDelete everything after the setup code chunk (e.g., line 12 and below)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-2-library-and-data-for-today",
    "href": "08-paired.html#activity-2-library-and-data-for-today",
    "title": "8  Paired t-test",
    "section": "8.2 Activity 2: Library and data for today",
    "text": "8.2 Activity 2: Library and data for today\nToday, we will need the following packages rstatix, tidyverse, qqplotr, lsr, and pwr. You should have all the necessary packages installed from previous chapters already. If not, you can install them via the console (see Section 1.5.1 for more details).\nAgain, load the rstatix package before tidyverse. Then read in the data from MeansSimonTask.csv and the demographics information from DemoSimonTask.csv.\n\n# load in the packages\n???\n\n# read in the data\nzwaan_data &lt;- ???\nzwaan_demo &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# load in the packages\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(qqplotr)\nlibrary(lsr)\nlibrary(pwr)\n\n# read in the data\nzwaan_data &lt;- read_csv(\"MeansSimonTask.csv\")\nzwaan_demo &lt;- read_csv(\"DemoSimonTask.csv\")\n\n\n\n\nAs usual, take some time to familiarise yourself with the data before starting the within-subjects t-test.\nToday, we will focus on the Simon effect itself. Remember that the Simon effect predicts shorter response times for congruent trials compared to incongruent trials. Therefore, we are inclined to propose a directional hypothesis.\n\nPotential research question: “Is there a significant difference in response times between congruent and incongruent trials in a Simon task?”\nNull Hypothesis (H0): “There is no significant difference in response times between congruent and incongruent trials in a Simon task.”\nAlternative Hypothesis (H1): “Response times for congruent trials are significantly shorter than those for incongruent trials in a Simon task.” or phrased differently “Participants will respond significantly faster in congruent trials than in incongruent trials in a Simon task.”",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-3-preparing-the-dataframe",
    "href": "08-paired.html#activity-3-preparing-the-dataframe",
    "title": "8  Paired t-test",
    "section": "8.3 Activity 3: Preparing the dataframe",
    "text": "8.3 Activity 3: Preparing the dataframe\nAgain, we need to calculate the mean response time (RT) for both congruent and incongruent trials per participant. As we did last week, we can also compute the Simon effect as the difference score between incongruent and congruent trials.\n\n\n\n\n\n\nTip\n\n\n\nTo keep all the data in one place, we should join this output with the demographics. While you won’t need the demographic information for the t-test itself, having it included will give you a complete dataframe. This can be useful when you need to calculate demographics for the Methods section; for example if you end up excluding data points, you can compute sample size, age, and gender splits straight away rather than having to apply the same exclusion criteria to a different data object.\n\n\nFor the paired version of the t.test, we need the congruent and incongruent trials in separate columns, ensuring each participant still has only one row in the dataframe (i.e., wide format). Below is the output we aim to achieve:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant\ngender\nage\neducation\nsimilarity\ncongruent\nincongruent\nsimon_effect\n\n\n\n\nT1\nFemale\n50\nHigh school\nsame\n475.0032\n508.2835\n33.28029\n\n\nT10\nMale\n45\nAssociate’s degree\nsame\n420.1515\n401.5800\n-18.57148\n\n\nT109\nMale\n33\nBachelor’s degree\nsame\n339.5343\n375.7152\n36.18085\n\n\nT11\nFemale\n71\nHigh school\nsame\n516.9722\n542.3111\n25.33889\n\n\nT111\nFemale\n34\nHigh school\nsame\n373.5778\n394.0665\n20.48874\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nChallenge yourself! Try recreating the table without hints this time. (Note: The table above is abbreviated; your data object should include the data from ALL participants.)\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nsimon_effect &lt;- zwaan_data %&gt;% \n  pivot_longer(cols = session1_congruent:session2_incongruent, names_to = \"col_headings\", values_to = \"RT\") %&gt;% \n  separate(col_headings, into = c(\"Session_number\", \"congruency\"), sep = \"_\") %&gt;% \n  group_by(participant, similarity, congruency) %&gt;% \n  summarise(mean_RT = mean(RT)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = congruency, values_from = mean_RT) %&gt;% \n  mutate(simon_effect = incongruent - congruent) %&gt;% \n  full_join(zwaan_demo, by = join_by(participant == twosubjectnumber)) %&gt;% \n  select(participant, gender = gender_response, age = age_response, education = education_response, similarity:simon_effect)\n\n\n\n\n\n\n\n\n\n\nYou could have also…\n\n\n\n\n\n\nlooked at the hints from the last chapter, since we are working with the exact same dataframe today.\nsaved the data object from last week as a csv file and read it in here.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-4-compute-descriptives",
    "href": "08-paired.html#activity-4-compute-descriptives",
    "title": "8  Paired t-test",
    "section": "8.4 Activity 4: Compute descriptives",
    "text": "8.4 Activity 4: Compute descriptives\nWe want to compute means and standard deviations for both the congruent and the incongruent trials. Then, we will subtract the mean RT of the congruent trials from the mean RT of the incongruent trials to calculate the average difference score between the two conditions.\n\ndescriptives &lt;- simon_effect %&gt;% \n  summarise(mean_congruent = mean(congruent),\n            sd_congruent = sd(congruent),\n            mean_incongruent = mean(incongruent),\n            sd_incongruent = sd(incongruent),\n            diff = mean_incongruent - mean_congruent, # diff = mean(simon_effect) would also work\n            sd_diff = sd(simon_effect))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmean_congruent\nsd_congruent\nmean_incongruent\nsd_incongruent\ndiff\nsd_diff\n\n\n\n\n427.6528\n74.17418\n462.0785\n74.69692\n34.42571\n21.59876\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that we did not have to use group_by() here because the data is already in wide format.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-5-create-an-appropriate-plot",
    "href": "08-paired.html#activity-5-create-an-appropriate-plot",
    "title": "8  Paired t-test",
    "section": "8.5 Activity 5: Create an appropriate plot",
    "text": "8.5 Activity 5: Create an appropriate plot\n\n8.5.1 Option 1: congruent and incongruent trials\nTo create an appropriate plot, we need the data in long format. This format should include a congruency column containing the labels for congruent and incongruent trials, and a mean_RT column to store the corresponding mean response times. Each participant should now have two rows in the dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant\ngender\nage\neducation\nsimilarity\nsimon_effect\ncongruency\nmean_RT\n\n\n\n\nT1\nFemale\n50\nHigh school\nsame\n33.28029\ncongruent\n475.0032\n\n\nT1\nFemale\n50\nHigh school\nsame\n33.28029\nincongruent\n508.2835\n\n\nT10\nMale\n45\nAssociate’s degree\nsame\n-18.57148\ncongruent\n420.1515\n\n\nT10\nMale\n45\nAssociate’s degree\nsame\n-18.57148\nincongruent\n401.5800\n\n\nT109\nMale\n33\nBachelor’s degree\nsame\n36.18085\ncongruent\n339.5343\n\n\n\n\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\nFirst, wrangle data into long format. The first 5 rows should match the output above. Then, use this table to create an appropriate plot that visualises the differences in mean response times between congruent and incongruent trials.\n\n\n\n\n\n\nSolution for the data\n\n\n\n\n\n\nsimon_effect_long &lt;- simon_effect %&gt;% \n  pivot_longer(cols = c(congruent, incongruent), names_to = \"congruency\", values_to = \"mean_RT\")\n\n\n\n\n\n\n\n\n\n\nSolution for the plot\n\n\n\n\n\n\nggplot(simon_effect_long, aes(x = congruency, y = mean_RT, fill = congruency)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.4, alpha = 0.8) +\n  scale_fill_viridis_d(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"Congruency\", y = \"mean Response Time\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.2 Option 2: difference scores between congruent and incongruent trials\nWe could have displayed the difference scores between the two conditions directly. This approach would use the simon_effect object without requiring additional data wrangling, as the difference scores are already stored in the simon_effect column.\n\n\n\n\n\n\nHints for the plot\n\n\n\n\n\nWe want to create a violin-boxplot, but this time it will have only one value on the x-axis instead of a grouping variable as we usually include. This causes the ggplot() function to behave slightly differently. Specifically, you would leave the x-value blank.\n\nggplot(data, aes(x = \"\", y = continuous_variable)) +\n\nTo add colour, use the usual arguments (e.g., fill, colour), but specify them within the geom_ functions instead of ggplot(), as we typically do.\n\n\n\n\n\n\n\n\n\nSolution for the plot\n\n\n\n\n\n\nggplot(simon_effect, aes(x = \"\", y = simon_effect)) +\n  geom_violin(fill = \"#A3319F\", alpha = 0.5) +\n  geom_boxplot(fill = \"#A3319F\", width = 0.4) +\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Difference in mean Response Time scores\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-6-check-assumptions",
    "href": "08-paired.html#activity-6-check-assumptions",
    "title": "8  Paired t-test",
    "section": "8.6 Activity 6: Check assumptions",
    "text": "8.6 Activity 6: Check assumptions\nThe assumptions for a paired t-test are fairly similar to the one-sample t-test.\n\nAssumption 1: Continuous DV\nThe dependent variable needs to be measured at interval or ratio level. We can confirm that by looking at either the columns congruent and incongruent in the object simon_effect. Or the variable mean_RT in simon_effect_long. This assumption holds.\n\n\nAssumption 2: Data are independent\nFor a paired t-test this assumption applies to the pair of values, i.e., each pair of values needs to be from a separate participant. We assume this assumption holds for our data.\n\n\nAssumption 3: Normality\nThis assumption requires the difference scores to be approximately normally distributed. We cannot see that from the violin-boxplot above (Option 1) and have to plot the difference score, i.e., variable simon_effect.\n\n\n\n\n\n\nYour Turn\n\n\n\nPlot the difference score.\n\n\n\n\n\n\nHint\n\n\n\n\n\nThink back to the one-sample t-test. How did we plot the normality assumption there?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nExplore the three possible approaches in the tabs below.\n\nOption 1: Q-Q plotOption 2: Violin-boxplot of the difference scoreOption 3: Shapiro-Wilk test\n\n\n\nggplot(simon_effect, aes(sample = simon_effect)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n\n\n\n\n\n\n\n\n\n\nYou can use the plot from above if you chose Option 2 in Activity 5, or create a new violin-boxplot if you created plot Option 1 above.\n\nggplot(simon_effect, aes(x = \"\", y = simon_effect)) +\n  geom_violin(fill = \"#FB8D61\", alpha = 0.5) + # alpha for opacity, fill for adding colour\n  geom_boxplot(fill = \"#FB8D61\", width = 0.4) + # change width of the boxes\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Difference in mean Response Time scores\")\n\n\n\n\n\n\n\n\n\n\n\nshapiro.test(simon_effect$simon_effect)\n\n\n    Shapiro-Wilk normality test\n\ndata:  simon_effect$simon_effect\nW = 0.98588, p-value = 0.1047\n\n\n\n\n\nBoth plots suggest slight deviations from normality in the tails, which are not detected by the Shapiro-Wilk test. However, minor deviations from normality are acceptable for t-tests, especially in the tails of the distribution. Therefore, we conclude that the difference scores are approximately normally distributed.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAssessing normality is never as straightforward as it appears in textbooks. While idealised examples often depict perfectly symmetrical bell curves, real-world data rarely aligns with such precision. Instead, normality exists “on a spectrum”, and it is your responsibility to evaluate whether the data’s shape is sufficiently close to normal for the purposes of your analysis.\nThis evaluation requires either visual inspection or relying on statistical tests. However, as pointed out in previous chapters, both approaches have limitations and neither provides an absolute answer. Instead of seeking perfection, focus on whether any deviations from normality meaningfully impact the validity of your results.\n\n\nIf any of the assumptions are violated, use the non-parametric equivalent to the paired t-test, see Section 8.10.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-7-compute-a-paired-t-test-and-effect-size",
    "href": "08-paired.html#activity-7-compute-a-paired-t-test-and-effect-size",
    "title": "8  Paired t-test",
    "section": "8.7 Activity 7: Compute a paired t-test and effect size",
    "text": "8.7 Activity 7: Compute a paired t-test and effect size\nWe can use the t.test() function again to compute the paired t-test. However, we are stuck with the BaseR pattern data$column once more.\n\n\n\n\n\n\nRant about BaseR and reminiscing about the “good old days”\n\n\n\n\n\nIn case you haven’t picked it up by now, I am not much a fan of data$column (i.e., wide format) and prefer the DV ~ IV (i.e., long format) pattern. And there was a time when the t.test() function allowed to add an extra argument paired = TRUE to the formula version but that is no longer the case. 😭😭😭 Now, the argument only works on the default method, specifying arguments x and y separately. And because the default version doesn’t allow us to add a data = argument, we have to revert to data$column.\nPS: Carolina disagrees with me and prefers some BaseR every now and then. And that’s totally fine, too - different researchers and coders have their own preferences, which you may have already noticed in the way you code.\n\n\n\nLong story short, here are the arguments you need from the data object in wide format (in this case data object simon_effect):\n\ndata$column for condition 1\ndata$column for condition 2\nthe extra argument paired = TRUE to tell the function we are conducting a paired rather than a two-sample t-test\n\n\nt.test(simon_effect$congruent, simon_effect$incongruent, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  simon_effect$congruent and simon_effect$incongruent\nt = -20.161, df = 159, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -37.79808 -31.05334\nsample estimates:\nmean difference \n      -34.42571 \n\n\nThe output tells us pretty much what we need to know:\n\nthe test that was conducted (here a paired t-test),\nthe conditions that were compared (here congruent and incongruent),\nthe t-value, degrees of freedom, and a p-value,\nthe alternative hypothesis,\na 95% confidence interval,\nand the mean difference score between both conditions (which also matches with our descriptives above).\n\nThe t.test() function does not give us an effect size, so, again, we have to compute it ourselves. We can use the CohensD() function from the lsr package as we did for the one-sample and the two-sample t-test. We can use the formula approach here as well, and add the extra argument method = \"paired\".\n\ncohensD(simon_effect$congruent, simon_effect$incongruent, method = \"paired\")\n\n[1] 1.593874\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe cohensD() function would also take a long format formula approach, such as from simon_effect_long, but you would need to make sure that the data within the columns are ordered correctly, i.e., Participant 1: condition 1, condition 2; Participant 2: condition 1, condition 2; etc. If that’s not the case, then your results will be wrong. R helpfully provides a warning message for you to notice and double-check your data accordingly.\n\ncohensD(mean_RT ~ congruency, data = simon_effect_long, method = \"paired\")\n\nWarning in cohensD(mean_RT ~ congruency, data = simon_effect_long, method =\n\"paired\"): calculating paired samples Cohen's d using formula input. Results\nwill be incorrect if cases do not appear in the same order for both levels of\nthe grouping factor\n\n\n[1] 1.593874",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-8-sensitivity-power-analysis",
    "href": "08-paired.html#activity-8-sensitivity-power-analysis",
    "title": "8  Paired t-test",
    "section": "8.8 Activity 8: Sensitivity power analysis",
    "text": "8.8 Activity 8: Sensitivity power analysis\nAs with the other t-test, we are conducting a sensitivity power analysis to determine the minimum effect size detectable with the number of participants we have in our sample (here n = 160), alpha of 0.05 and power of 0.8. This will tell us if our analysis was sufficiently powered or not.\nThe function we will use again is pwr.t.test() from the pwr package. The arguments in the formula are the same as for the one-sample t-test; we just need to adjust the number of participants and set the type to “paired”.\n\npwr.t.test(n = 160, sig.level = 0.05, power = 0.8, type = \"paired\", alternative = \"two.sided\")\n\n\n     Paired t test power calculation \n\n              n = 160\n              d = 0.222858\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\nNOTE: n is number of *pairs*\n\n\nThe minimum effect size we could reliably detect is 0.22. Our actual effect size was 1.59, so this analysis was sufficiently powered. YAY!",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#activity-9-the-write-up",
    "href": "08-paired.html#activity-9-the-write-up",
    "title": "8  Paired t-test",
    "section": "8.9 Activity 9: The write-up",
    "text": "8.9 Activity 9: The write-up\nWe hypothesised that there would be a significant difference in the response times between congruent \\((M = 427.65 msec, SD = 74.17 msec)\\) and incongruent trials \\((M = 462.08 msec, SD = 74.70 msec)\\) of a Simon task. On average, participants were faster in the congruent compared to the incongruent condition \\((M_{diff} = 34.43 msec, SD_{diff} = 21.60 msec)\\). Using a within-subjects t-test, the effect was found to be significant and of a large magnitude, \\(t(159) = 20.16, p &lt; .001, d = 1.59\\). Therefore, we reject the null hypothesis in favour of H1. The analysis was sufficiently powered to detect this effect.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#sec-alternative_paired",
    "href": "08-paired.html#sec-alternative_paired",
    "title": "8  Paired t-test",
    "section": "8.10 Activity 10: Non-parametric alternative",
    "text": "8.10 Activity 10: Non-parametric alternative\nThe Wilcoxon signed-rank test is the non-parametric equivalent to the paired t-test, comparing the difference between the median for two measurements.\nBefore we compute the test, we need to determine some summary stats (e.g., here we focus on the median scores) for the congruent and incongruent conditions. Similar to the One-sample Wilcoxon signed-rank test, we can use the summary() function again because our data is in wide format.\n\nsummary(simon_effect)\n\n participant           gender               age         education        \n Length:160         Length:160         Min.   :19.00   Length:160        \n Class :character   Class :character   1st Qu.:30.75   Class :character  \n Mode  :character   Mode  :character   Median :37.00   Mode  :character  \n                                       Mean   :39.86                     \n                                       3rd Qu.:49.00                     \n                                       Max.   :71.00                     \n  similarity          congruent      incongruent     simon_effect   \n Length:160         Min.   :290.0   Min.   :324.9   Min.   :-18.57  \n Class :character   1st Qu.:379.4   1st Qu.:413.9   1st Qu.: 21.62  \n Mode  :character   Median :411.3   Median :449.7   Median : 34.77  \n                    Mean   :427.7   Mean   :462.1   Mean   : 34.43  \n                    3rd Qu.:458.7   3rd Qu.:496.3   3rd Qu.: 46.22  \n                    Max.   :741.5   Max.   :727.9   Max.   :103.84  \n\n\nNow we can move on to the Wilcoxon signed-rank test. We will use the wilcox.test() function again, but add the argument paired = TRUE.\n\nwilcox.test(simon_effect$congruent, simon_effect$incongruent, paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  simon_effect$congruent and simon_effect$incongruent\nV = 144, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe could have also run a One-sample Wilcoxon signed-rank test on the difference score, but instead of comparing that to a population median (as we did in Section 6.6), we would compare it to 0 to assess whether the median difference between paired observations is significantly different from zero.\n\nwilcox.test(simon_effect$simon_effect, mu = 0)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  simon_effect$simon_effect\nV = 12736, p-value &lt; 2.2e-16\nalternative hypothesis: true location is not equal to 0\n\n\n\n\n\n\n\n\nThe V values are different between the 2 approaches - Does that matter?\n\n\n\nYes and no. The order in which you input variables into the function will affect the value of V - has to do with how the ranks are getting assigned. In our column simon_effect we subtracted congruent RT from incongruent RT. To have the exact equivalent, we will need to switch the columns in the wilcox.test() function.\n\nwilcox.test(simon_effect$incongruent, simon_effect$congruent, paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  simon_effect$incongruent and simon_effect$congruent\nV = 12736, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0\n\n\nAnd as you can see, the V values match now.\n\n\n\n\nWe should also compute the standardised test statistic Z. Again, we need to calculate Z manually, using the qnorm function on the halved p-value from our Wilcoxon test above.\n\n# storing the p-value\np_wilcoxon &lt;- wilcox.test(simon_effect$incongruent, simon_effect$congruent, paired = TRUE)$p.value\n\n# calculate the z value from half the p-value\nz = qnorm(p_wilcoxon/2)\nz\n\n[1] -10.72532\n\n\nTo calculate an effect size, we would need to use the function wilcox_effsize() from the rstatix package. Unlike, the wilcox.test() and the t.test() function, wilcox_effsize() expects data to be in long format to be able to use the DV ~ IV pattern. Fortunately, we still have that available in simon_effect_long. We also need to add the argument paired = TRUE.\n\nwilcox_effsize(data = simon_effect_long, formula = mean_RT ~ congruency, paired = TRUE)\n\n\n\n\n\n.y.\ngroup1\ngroup2\neffsize\nn1\nn2\nmagnitude\n\n\n\n\nmean_RT\ncongruent\nincongruent\n0.8479786\n160\n160\nlarge\n\n\n\n\n\n\nNow we have all the numbers to write this up:\nA Wilcoxon signed-rank test was conducted to determine whether there was a significant difference in response times between congruent \\((Mdn = 411.3 msec)\\) and incongruent trials \\((Mdn = 449.7 msec)\\) in a Simon task. Median response times of Congruent trials were significantly faster \\((Mdn = 34.77 msec)\\) than incongruent trials, \\(Z = -10.73, p &lt; .001, r = .848\\). The difference can be classified as large according to Cohen (1992). Therefore, we reject the null hypothesis in favour of H1.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "08-paired.html#test-your-knowledge",
    "href": "08-paired.html#test-your-knowledge",
    "title": "8  Paired t-test",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nWhat is the main purpose of an paired-samples t-test?\n\n To assess the correlation between two continuous variables To compare means between two independent groups To compare means between two related groups To test for differences in variances between two independent groups\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe paired t-test is used when comparing means from related groups. It requires two measurements from the same group or individual. Examples could be before-and-after measurements (e.g., pre- and post-intervention), or repeated measures (e.g., exercise under 2 different conditions, such as indoor and outdoor), etc.\n\n\n\n\n\nQuestion 2\nWhich of the following is a key assumption of the paired t-test?\n\n The differences between paired observations are normally distributed. The dependent variable is categorical. The two groups have equal variances. The two samples are independent.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe paired t-test assumes that the differences between the paired observations are normally distributed, as the test is applied to these differences, not the raw scores.\n\n\n\n\n\nQuestion 3\nWhat is the null hypothesis for a paired t-test?\n\n The means of two independent groups are equal. The differences between paired observations are equal to zero. The variances of the two samples are equal. There is no relationship between two variables.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe paired t-test specifically tests whether the mean difference between paired observations (e.g., pre-test and post-test scores) is zero, indicating no systematic difference.\nWhy the other options are incorrect:\n\nThe means of two independent groups are equal: This describes the null hypothesis for an independent t-test, not a paired t-test. The paired t-test is used for related groups or repeated measures, not independent groups.\nThe variances of the two samples are equal: This is an assumption that applies to the independent t-test, which compares two unrelated groups. The paired t-test does not test variances; it focuses on the differences between paired observations.\nThere is no relationship between two variables: This is not the null hypothesis for a paired t-test. It relates more to correlation or regression analyses, which assess relationships between variables, not mean differences.\n\n\n\n\n\n\nQuestion 4\nA paired-samples t-test was conducted to compare sleep quality scores with (M = 7.5, SD = 1.8) and without (M = 6.0, SD = 1.9) white noise, t(29) = 4.55, p &lt; .001, d = 0.82. Answer the questions below.\n\nHow many participants were included in the study? \nWhat is the effect size, and how would you describe its magnitude? The effect size is  and of smallmediumlarge magnitude.\nIs the result statistically significant? The result is statistically non-significant because p &lt; .001The result is statistically significant because p &lt; .001\nBased on the means and standard deviations, how would you summarise the direction of the effect?\n\n The direction of the effect cannot be determined from the output. Sleep quality was the same in both conditions. Sleep quality was higher with white noise than without white noise. Sleep quality was higher without white noise than with white noise.\n\n\n\n\n\n\n\n\nExplain these answers\n\n\n\n\n\nThe degrees of freedom for a paired-samples t-test are calculated as N - 1 for the number of paired observations. With df = 29, the sample size is 30 participants.\nAn effect size of d = 0.82 is considered large. This suggests a meaningful and substantial difference in sleep quality between the two conditions.\nThe result is statistically significant. The p-value (p &lt; .001) indicates that the observed difference in the sample is very unlikely to occur if we assume there is no true difference in the population.\nThe mean sleep quality score with white noise (M = 7.5) is higher than without white noise (M = 6.0), indicating improved sleep quality with white noise.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Paired t-test</span>"
    ]
  },
  {
    "objectID": "09-correlation.html",
    "href": "09-correlation.html",
    "title": "9  Correlations",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#intended-learning-outcomes",
    "href": "09-correlation.html#intended-learning-outcomes",
    "title": "9  Correlations",
    "section": "",
    "text": "Compute a Pearson correlation and effectively report the results.\nUnderstand when to use a non-parametric equivalent of correlation, compute it, and report the results.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#individual-walkthrough",
    "href": "09-correlation.html#individual-walkthrough",
    "title": "9  Correlations",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-1-setup-download-the-data",
    "href": "09-correlation.html#activity-1-setup-download-the-data",
    "title": "9  Correlations",
    "section": "9.1 Activity 1: Setup & download the data",
    "text": "9.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2A_chapter9”, or “09_correlation”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you need help.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the new dataset here: data_ch9.zip. The zip folder includes the following files:\n\nSoupbowl_data_dictionary.xlsx: A codebook with detailed variable descriptions\ndata_ch9_correlation.csv: A CSV file containing data from the experiment and demographic information\nA copy of the paper by Lopez et al. (2024) and the Supplementary materials\n\nExtract the data files from the zip folder and place them in your project folder. If you need help, see Section 1.4.\n\nCitation\n\nLopez, A., Choi, A. K., Dellawar, N. C., Cullen, B. C., Avila Contreras, S., Rosenfeld, D. L., & Tomiyama, A. J. (2024). Visual cues and food intake: A preregistered replication of Wansink et al. (2005). Journal of Experimental Psychology: General, 153(2), 275–281. https://doi.org/10.1037/xge0001503\n\nThe preregistration, data and supplementary materials are available on OSF & APA’s “Journal of Experimental Psychology: General”:\n\nPre-reg: https://osf.io/ux42g\nData: https://osf.io/8q647/\nSupMats: https://supp.apa.org/psycarticles/supplemental/xge0001503/xge0001503.pdf\n\nAbstract\n\nImagine a bowl of soup that never emptied, no matter how many spoonfuls you ate—when and how would you know to stop eating? Satiation can play a role in regulating eating behavior, but research suggests visual cues may be just as important. In a seminal study by Wansink et al. (2005), researchers used self-refilling bowls to assess how visual cues of portion size would influence intake. The study found that participants who unknowingly ate from self-refilling bowls ate more soup than did participants eating from normal (not self-refilling) bowls. Despite consuming 73% more soup, however, participants in the self-refilling condition did not believe they had consumed more soup, nor did they perceive themselves as more satiated than did participants eating from normal bowls. Given recent concerns regarding the validity of research from the Wansink lab, we conducted a preregistered direct replication study of Wansink et al. (2005) with a more highly powered sample (N =464 vs. 54 in the original study). We found that most results replicated, albeit with half the effect size (d= 0.45 instead of 0.84), with participants in the self-refilling bowl condition eating significantly more soup than those in the control condition. Like the original study, participants in the selfrefilling condition did not believe they had consumed any more soup than participants in the control condition. These results suggest that eating can be strongly controlled by visual cues, which can even override satiation.\n\nPublic Significance Statement\n\nResults from this study are relevant to public health and science given the influence that the bottomless soup bowls study had on public policy and the skepticism surrounding research from the Wansink lab. We found that what the eyes see plays a significant role in how much people eat and how full they feel. Given the high prevalence of diseases of overconsumption, this study has implications for the regulation of eating behavior.\n\nChanges made to the dataset\n\nThe basis for data_ch9_correlation.csv is the file named included&excludedFINAL.sav on OSF. It contains 632 observations.\nThe original authors used an SPSS file format, which was exported as a csv.\nThe original authors coded missing values as 999 and 888. These were replaced with actual missing values (NA).\nVariables M_postsoup and Condition were removed so we can practice more data wrangling. It also gives us an opportunity to include one of Gaby’s favourite functions coalesce().\nNo other changes were made.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-2-library-and-data-for-today",
    "href": "09-correlation.html#activity-2-library-and-data-for-today",
    "title": "9  Correlations",
    "section": "9.2 Activity 2: Library and data for today",
    "text": "9.2 Activity 2: Library and data for today\nToday, we will use the following packages: tidyverse, ggExtra, correlation, qqplotr, and pwr. As always, you may need to install any packages you have not used/ installed before (see Section 1.5.1 if you need some help).\nAdditionally, we will read in today’s data from data_ch9_correlation.\n\n# load in the packages\n???\n\n# read in the data\nlopez_data &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# load in the packages\nlibrary(tidyverse)\nlibrary(ggExtra)\nlibrary(correlation)\nlibrary(qqplotr)\nlibrary(pwr)\n\n# read in the data\nlopez_data &lt;- read_csv(\"data_ch9_correlation.csv\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-3-familiarise-yourself-with-the-data",
    "href": "09-correlation.html#activity-3-familiarise-yourself-with-the-data",
    "title": "9  Correlations",
    "section": "9.3 Activity 3: Familiarise yourself with the data",
    "text": "9.3 Activity 3: Familiarise yourself with the data\nAs usual, take some time to familiarise yourself with the data before starting the analysis. Review the codebook to understand the variables and their measurement.\nWe notice that lopez_data contains data from 632 participants, whereas the Lopez et al. (2024) paper reports a total of 654 participants. Have a look at the data and the paper. Can you explain the discrepancy?\n\n\n\n\n\n\nExplanation\n\n\n\n\n\nLopez et al. appear to have published data for both the participants included in the final sample (464 participants) and those excluded after discovering the true purpose of the study (168 participants). However, an additional 22 participants were excluded due to experimenter error, and their data were not recorded.\n\n\n\nToday, we will focus on a few correlation values and attempt to reproduce some of the results presented in Table 2 of Lopez et al. (2024).\n\n\n\nTable 2 (Lopez et al., 2024)\n\n\nAs shown in the table above, the original authors aimed to replicate the correlations reported by Wansink et al. (2005). Specifically, they examined the following relationships:\n\nEstimated ounces of soup consumed with actual consumption volume\nEstimated calories of soup consumed with actual consumption volume\n\nThese correlations were calculated for three groups: participants who ate from normal bowls, participants who ate from self-refilling bowls, and the combined group of all participants.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-4-preparing-the-dataframe",
    "href": "09-correlation.html#activity-4-preparing-the-dataframe",
    "title": "9  Correlations",
    "section": "9.4 Activity 4: Preparing the dataframe",
    "text": "9.4 Activity 4: Preparing the dataframe\nTo calculate correlations, the data must be in wide format. Fortunately, lopez_data is already in wide format. However, if your data is organised differently, ensure that each variable is in its own column.\n\nStep 1: Excluding participants’ data\nCheck that only participants who meet the recruitment criteria are included, and exclude those who do not. Lopez and colleagues made this straightforward by including the variable Included in the dataset. This variable indicates which participants were included in the final dataset (value of 1) and which were excluded (value of 0). After completing this step, our new data object should contain 464 participants.\n\n\n\n\n\n\nYour Turn\n\n\n\n\n\nCreate a new data object named lopez_included that contains only the participants marked as included in the final dataset (i.e., those with a value of 1 in the Included variable).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlopez_included &lt;- lopez_data %&gt;% \n  filter(Included == 1)\n\n\n\n\n\n\n\n\n\nStep 2: Selecting relevant variables\nBig datasets can be messy, so it is often helpful to focus only on the variables relevant to your analysis. For this task, we want to include the following variables:\n\nParticipantID\nEstimated ounces of food consumed (OzEstimate)\nEstimated calories of food consumed (CalEstimate)\nConsumption volume - Experimental soup intake (ExpSoupAte)\nConsumption volume - Control soup intake (CtrlSoupAte)\nSeatPosition - so we can determine whether participants were sorted into in the Experimental or the Control group\n\nStore the new data object as lopez_reduced.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlopez_reduced &lt;- lopez_included %&gt;% \n  select(ParticipantID, Sex, OzEstimate, CalEstimate, CtrlSoupAte, ExpSoupAte, SeatPosition)\n\n\n\n\n\n\nStep 3: Recoding the values\nAs we can see now, our lopez_reduced data object could use some tidying.\n\nSex is a categorical variable, yet, it is currently displayed as numeric, which isn’t ideal. Recode these values according to the Soupbowl_data_dictionary. You could either recode the values as we did in Section 3.3) or convert Sex into a factor if that’s easier (see Chapter 4 for guidance).\nParticipantID should also be converted into a factor (see Chapter 4 for guidance).\nCreate a new variable called Condition to indicate whether participants are in the Control or Experimental group. Use the Soupbowl_data_dictionary o determine which SeatPosition corresponds to normal bowls (Control) and self-refilling bowls (Experimental). If you’re unsure which function to use, refer to Section 3.4.\nCtrlSoupAte and ExpSoupAte can remain separate if we want to focus on these two conditions individually, as we can remove missing values later. However, to calculate correlations across the whole sample, we need these “SoupAte” values in a single column instead of two. We will name this coalesced variable M_postsoup to align with the Soupbowl_data_dictionary.\n\nYou should be able to complete recoding tasks 1, 2, and 3 on your own. However, Task 4 involves a new function, so we will walk through it together.\n\n\n\n\n\n\nSolution for Recoding tasks 1-3\n\n\n\n\n\nIn the panels below, I have created new variables in lopez_reduced to show you solutions for both the case_match() and the factor() approach for recoding Sex. Alternatively, you could simply name your new column Sex to overwrite the numeric values in the existing Sex column.\n\nSex with case_match()Sex with factor()ParticipantID with factor()Condition with case_when()\n\n\nSince no conditional statement is needed, a simple case_match() will suffice. This will create a character column.\n\nlopez_reduced &lt;- lopez_reduced %&gt;% \n  mutate(Sex_case_match = case_match(Sex,\n                                     0 ~ \"Male\",\n                                     1 ~ \"Female\",\n                                     2 ~ \"Other\",\n                                     3 ~ \"Prefer not to say\"))\n\n\n\nUsing a factor is helpful if you want to reorder the labels simultaneously. This will create a factor column.\n\nlopez_reduced &lt;- lopez_reduced %&gt;% \n  mutate(Sex_factor = factor(Sex,\n                         levels = c(1, 0, 2, 3),\n                         labels = c(\"Female\", \"Male\", \"Other\", \"Prefer not to say\")))\n\n\n\nThere is not much to it, as the levels and labels don’t need changing.\n\nlopez_reduced &lt;- lopez_reduced %&gt;% \n  mutate(ParticipantID = factor(ParticipantID))\n\n\n\nAccording to the Soupbowl_data_dictionary, even numbers in SeatPosition indicate the Experimental group, and odd numbers represent the Control group. Here we will need to use case_when() because conditional statements (see Chapter 3 Activity 4 for a refresher).\n\nlopez_reduced &lt;- lopez_reduced %&gt;% \n  mutate(Condition = case_when(\n    SeatPosition %in% c(1,3) ~ \"Control\",\n    SeatPosition %in% c(2,4) ~ \"Experimental\"\n  ))\n\n\n\n\n\n\n\nNote\n\n\n\nIn the code, I specified 1 and 3 should be labelled “Control” and 2 and 4 “Experimental”. I could have used with the .default = argument for the even seat numbers, however, this requires being certain that all other values are either 2 or 4 (e.g., no invalid numbers like 5 or missing values). Since I did not check beforehand, any value that is not 1, 2, 3, or 4 will remain unlabelled, making it easier to identify and address.\n\n\n\n\n\n\n\n\nWe want to combine the values from CtrlSoupAte and ExpSoupAte into a single column named M_postsoup. (No idea why the authors called it M_postsoup rather than AllSoupAte. However, since this was one of the columns deleted from the original dataset earlier, we’ll stick with the original variable name as the authors intended.)\nRecoding task 4 is straightforward with a function like coalesce(). For each row, it checks the specified columns and finds the first non-missing value at each position. Essentially, R scans the columns row by row, looking for the first available value that isn’t missing and assigns it to the new column. For example:\n\nParticipant 1001 has no value in CtrlSoupAte but has a value in ExpSoupAte, so R skips the missing value and assigns 4.5 to the new column.\nParticipant 1002 has a value in CtrlSoupAte (3.3), directly assigns it to the new column, and so on.\n\n\nlopez_reduced &lt;- lopez_reduced %&gt;% \n  mutate(M_postsoup = coalesce(CtrlSoupAte, ExpSoupAte))\n\nAs always, all these “preparing the dataframe” steps could have been combined into a single pipe.\n\n\n\n\n\n\nSolution for Activity 4 in a single pipe\n\n\n\n\n\n\nlopez_reduced &lt;- lopez_data %&gt;% \n  # Step 1\n  filter(Included == 1) %&gt;% \n  #Step 2\n  select(ParticipantID, Age, Sex, OzEstimate, CalEstimate, CtrlSoupAte, ExpSoupAte, SeatPosition) %&gt;% \n  # Step 3 (I decided to use the factor approach and override my `Sex` column and include it all into the same `mutate()` function)\n  mutate(Sex = factor(Sex,\n                      levels = c(1, 0, 2, 3),\n                      labels = c(\"Female\", \"Male\", \"Other\", \"Prefer not to say\")),\n         ParticipantID = factor(ParticipantID),\n         Condition = case_when(\n           SeatPosition %in% c(1,3) ~ \"Control\",\n           SeatPosition %in% c(2,4) ~ \"Experimental\"),\n         # Step 4\n         M_postsoup = coalesce(CtrlSoupAte, ExpSoupAte))",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-5-compute-descriptives",
    "href": "09-correlation.html#activity-5-compute-descriptives",
    "title": "9  Correlations",
    "section": "9.5 Activity 5: Compute descriptives",
    "text": "9.5 Activity 5: Compute descriptives\nNow that the data is ready, we can focus on reproducing the correlations. For the remainder of this chapter, we will focus on correlating the estimated calories of soup consumption with actual consumption volume for the control group. Testing every correlation would require assessing assumptions for each relationship, making this chapter unnecessarily long. However, you are welcome to reproduce all other correlations in your own time if you wish.\nFor the descriptives, we will compute the number of participants (n), means and standard deviations for the Control group of our variables of interest (i.e., CalEstimate and M_postsoup).\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nFilter the data to include only the Control group and focus on the two variables of interest (CalEstimate and M_postsoup), and keep the ParticipantID. You may want to store the data as a new object named lopez_control.\nWatch out for missing values in some of the columns. We will address them later during the correlation analysis. For now, instruct R to ignore missing values when calculating descriptive statistics.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## data object lopez_control\nlopez_control &lt;- lopez_reduced %&gt;% \n  filter(Condition == \"Control\") %&gt;% \n  select(ParticipantID, CalEstimate, M_postsoup)\n\n# descriptives for lopez_control\ndescriptives_control &lt;- lopez_control %&gt;% \n  summarise(n = n(),\n            mean_CalEstimate = mean(CalEstimate, na.rm = TRUE),\n            sd_CalEstimate = sd(CalEstimate, na.rm = TRUE),\n            mean_M_postsoup = mean(M_postsoup),\n            sd_M_postsoup = sd(M_postsoup)) %&gt;% \n  ungroup()\n\ndescriptives_control\n\n\n\n\n\nn\nmean_CalEstimate\nsd_CalEstimate\nmean_M_postsoup\nsd_M_postsoup\n\n\n\n\n246\n133.0328\n121.3261\n8.86748\n6.236679",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-6-create-an-appropriate-plot",
    "href": "09-correlation.html#activity-6-create-an-appropriate-plot",
    "title": "9  Correlations",
    "section": "9.6 Activity 6: Create an appropriate plot",
    "text": "9.6 Activity 6: Create an appropriate plot\nThe only option for a correlation is a stacked barcharthistogramscatterplotviolin-boxplot because both variables are categoricalboth variables are continuousone variable is continuous and the other categoricalThere is only one variable and it’s continuous.\n\n\n\n\n\n\nYour Turn\n\n\n\n\n\nCreate an appropriate plot to visualise the relationship between CalEstimate and M_postsoup.\n\n\n\n\n\n\nSolution for the plot\n\n\n\n\n\n\nggplot(lopez_control, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-7-check-assumptions",
    "href": "09-correlation.html#activity-7-check-assumptions",
    "title": "9  Correlations",
    "section": "9.7 Activity 7: Check assumptions",
    "text": "9.7 Activity 7: Check assumptions\n\nAssumption 1: Continuous variables\nBoth variables must be measured at the interval or ratio level (i.e., continuous data). We can confirm this by examining our two variables of interest, CalEstimate and M_postsoup. Plus, you would already know whether the variables are continuous based on your study design.\n\n\nAssumption 2: Related pairs\nEach participant needs to have 2 data points, in our case one value for CalEstimate and one for M_postsoup. You can verify this directly in the dataset (e.g., lopez_control) or watch for warning messages when creating the scatterplot.\nIn this dataset, there are no missing values in M_postsoup but CalEstimate has two missing values. hmmm. Interestingly, the Lopez paper mentions exclusion criteria in the Supplementary Materials but only in relation to participants, not statistical exclusions.\nTechnically, incomplete pairs won’t appear in the scatterplot and will be automatically excluded during the correlation analysis (as we will observe later). However, in the interest of transparency, any data exclusions should be clearly stated in your reports.\nTo address this, we can also exclude the missing values from lopez_control. Here, I’m using the drop_na() function to remove rows with missing data. I will save this as a new data object lopez_control_no_na.\n\nlopez_control_no_na &lt;- lopez_control %&gt;% \n  drop_na()\n\nData from participants 1895 and 1908 has now been excluded, leaving us with complete pairs. The assumption holds.\n\n\nAssumption 3: Independence of cases/observations\nSimilar to the paired t-test, we must assume that the two observations for each case are independent of the observations for any other case. This basically means that participants did not influence each other’s ratings. Once again, this assumption is related to the study design and is satisfied in this instance.\n\n\nAssumption 4: Linearity\nTo run a Pearson correlation, the relationship between the two variables must be linear.\nYou can assess linearity visually using a Residuals vs Fitted plot, which can be generated by applying the plot() function to a linear model (lm) object. The function requires the following arguments:\n\nThe 2 variables of interest, separated by a tilde (~)\nThe dataset\nThe which argument specifies which plot we want to show. Number 1 will produce a Residuals vs Fitted plot.\n\n\nplot(lm(CalEstimate~M_postsoup, data = lopez_control_no_na), which = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternative\n\n\n\n\n\nYou can also assess linearity using a scatterplot, but instead of fitting a linear model “lm”, use the “loess” method for the line of best fit. Then, examine how closely the resulting line resembles a linear line.\n\nggplot(lopez_control_no_na, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nVerdict: This does actually look non-linear to me. The original authors did not mention any assumption testing in their paper or Supplementary Materials. If they conducted these tests, we can assume they deemed the assumptions satisfied.\n\n\nAssumption 5: Normality\nResiduals for both variables should follow a bivariate normal distribution (i.e., both together normally distributed). We can use a Q-Q plot to visually check this assumptions. The code is the same as above (i.e., plot() with lm()), but this time, set the which argument to 2 to generate the Q-Q plot.\n\nplot(lm(CalEstimate~M_postsoup, data = lopez_control_no_na), which = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternatives\n\n\n\n\n\n\nOption 1: plotting both variables individuallyOption 2: Scatterplot\n\n\nIn practice it is frequently accepted that each variable is normally distributed rather than both together (i.e., univariate normality). However, there is some disagreement among experts whether Pearson’s correlation is “robust” to violations of univariate normality. Anyway, we are showing this approach as an alternative using the Q-Q plot version with packages ggplot and qqplotr.\n\nggplot(lopez_control_no_na, aes(sample = CalEstimate)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n\nggplot(lopez_control_no_na, aes(sample = M_postsoup)) +\n  stat_qq_band(fill = \"#FB8D61\", alpha = 0.4) +\n  stat_qq_line(colour = \"#FB8D61\") +\n  stat_qq_point()\n\n\n\n\n\n\n\n\n\nFigure 9.1: Bins vs binwidth arguments\n\n\n\n\n\n\n\nWe can also use the function ggMarginal() to enhance a ggplot2 scatterplot by adding marginal density plots, histograms, or boxplots. The workflow is slightly different: first, save the scatterplot as a data object, then apply ggMarginal() to that object.\nTo customise the marginal plots:\n\nUse type = \"histogram\" for histograms.\nUse type = \"boxplot\" for boxplots.\nLeave the type argument out or set it to type = \"density\" to display the default density plots.\n\n\np1 &lt;- ggplot(lopez_control_no_na, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point()\n\nggMarginal(p1, type = \"density\")\n\n\n\n\n\n\n\n\nMore info here: https://cran.r-project.org/web/packages/ggExtra/vignettes/ggExtra.html\n\n\n\n\n\n\nVerdict: For me, the assumption of normality would not hold, whether assessed jointly or independently, as the points follow a curve rather than “hugging” the straight line with potentially some potential deviations in the tails. However, I seem to be more conservative in my judgements compared to Lopez et al. Since they proceeded with a Pearson correlation, the assumption must have held for them.\n\n\nAssumption 6: Homoscedasticity\nHomoscedasticity assumes that the data is evenly distributed around the line of best fit, with no visible pattern. This assumption can be assessed visually using a Scale-Location plot or directly within the scatterplot.\n\nOption 1: Scale-Location plotOption 2: Scatterplot\n\n\nAs you might have guessed, we will use the plot() function with lm() again but this time set the which argument to 3 to generate the Scale-Location plot.\n\nplot(lm(CalEstimate~M_postsoup, data = lopez_control_no_na), which = 3)\n\n\n\n\n\n\n\n\n\n\nWe will use the same scatterplot as above, but this time focus on the points and their distance from the blue line. If the points are randomly scattered around the line of best fit, the assumption holds. However, if a distinct pattern emerges, the assumption is violated.\n\nggplot(lopez_control_no_na, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nVerdict: This is another assumption that feels borderline to me. There appears to be slight heteroscedasticity. In the Scale-Location plot, the red line should ideally be flat and horizontal, but ours has a slight slope and could be flatter. If you prefer looking at the scatterplot, you can observe the data points moving slightly further away from the line of best fit as the x and y values increase. This is kinda forming a slight funnel shape rather than the roughly random spread of data points shown in last week’s lecture slides. Nevertheless, the authors took a more lenient approach and considered the assumption to be met.\n\n\nAssumption 7: Absence of outliers\nIdeally, our data should not contain any outliers or influential points, as these can distort the relationship between the variables of interest. We can assess this assumption visually with a Residuals vs Leverage plot or by revisiting the scatterplot (as shown above).\n\nOption 1: Residuals vs Leverage plotOption 2: Scatterplot\n\n\nTo identify those data points, we can look at plot 5 from the plot() function with the lm() object but setting the which argument to 5.\n\nplot(lm(CalEstimate~M_postsoup, data = lopez_control_no_na), which = 5)\n\n\n\n\n\n\n\n\nHere, case numbers 3, 183, and 205 are identified. In the data object lopez_control_no_na, these correspond to participant IDs 1007, 1716, and 1789, respectively. Two of these participants estimated they had consumed 800 calories, while the third data point has a y-value over 40 (the one with the lower x-value).\n\n\nLooking at the scatterplot, I would have probably identified 4 outliers - anyone who estimated more than 600 cal and anyone who consumed more than 40 ounces of soup.\n\n\n\nVerdict: There are several ways to handle outliers, such as excluding them, replacing their extreme values with the group mean, or winsorising them. For now, I would likely exclude these three data points from the dataset before proceeding. However, Lopez et al. chose to retain all data points.\nRemember: Any data exclusions in your reports must be clearly justified.\n\n\n\n\n\n\nYour Turn\n\n\n\nFilter out the 3 (or 4) influential points/outliers and create the plot again. It’s best to save the data without outliers as a new data object. I’ve named mine lopez_control_no_outliers, but feel free to use a name that works for you.\n\n\n\n\n\n\nSolution for removing 3 outliers\n\n\n\n\n\n\nlopez_control_no_outliers &lt;- lopez_control_no_na %&gt;% \n  filter(!ParticipantID %in% c(1007, 1716, 1789))\n\n\nggplot(lopez_control_no_outliers, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution for removing 4 outliers\n\n\n\n\n\n\nlopez_control_no_outliers4 &lt;- lopez_control_no_na %&gt;% \n  filter(CalEstimate &lt; 600,\n         M_postsoup &lt; 40)\n\n\nggplot(lopez_control_no_outliers4, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinal word on Assumption checks\nFor me, there would be enough justification to switch to a non-parametric correlation method, such as Spearman. However, since the original authors ran Pearson correlations, we will follow their approach in Activity 8. We will also revert to the data object lopez_control, as the original authors chose not to exclude any data points (e.g., missing values, outliers, etc.).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-8-pearsons-correlation-effect-size",
    "href": "09-correlation.html#activity-8-pearsons-correlation-effect-size",
    "title": "9  Correlations",
    "section": "9.8 Activity 8: Pearson’s correlation & effect size",
    "text": "9.8 Activity 8: Pearson’s correlation & effect size\nThere are plenty of options out there to compute a correlation. We will use the correlation() function from the correlation package because it offers more consistent reporting features. The correlation() function requires:\n\nThe name of the data set you are using.\nThe name of the first variable you want to select for the correlation.\nThe name of the second variable you want to select for the correlation.\nThe type of correlation you want to run: e.g. Pearson, Spearman.\n\nFor a two-tailed Pearson correlation using the lopez_control dataset, the code would look like this (note the quotation marks around everything except the data object):\n\ncorrelation(data = lopez_control,\n            select = \"CalEstimate\",\n            select2 = \"M_postsoup\",\n            method = \"Pearson\",\n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nCalEstimate\nM_postsoup\n0.4045319\n0.95\n0.293876\n0.5044879\n6.881219\n242\n0\nPearson correlation\n244\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nSince lopez_control contains only three variables and we’ve already converted ParticipantID into a factor, we can pass the entire data object to the correlation() function. This will compute correlations between all numeric columns in the dataset. In this case, it would result in just one association, but see below for an example with more numeric variables.\n\ncorrelation(lopez_control)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nCalEstimate\nM_postsoup\n0.4045319\n0.95\n0.293876\n0.5044879\n6.881219\n242\n0\nPearson correlation\n244\n\n\n\n\n\n\n\n\nHere we obtained a Pearson correlation value of .405 which is close to the value of .41 reported by Lopez et al. (2024). Remember to report correlation values to three decimal places to adhere to APA style (though the journal in this case may have followed different guidelines).\n\n\n\n\n\n\nCorrelation Matrix - more than 1 comparison\n\n\n\n\n\nIf you want to correlate multiple variables with one another, you can do that in a correlation matrix.\nLet’s try to replicate the correlations for full sample:\n\nOzEstimate and CalEstimate,\nOzEstimate and M_postsoup, and\nCalEstimate and M_postsoup.\n\nTo do this, first ensure that only the relevant variables are selected and that a variable like ParticipantID is converted into a factor. I have stored all four variables in an object called lopez_overall.\nYou can also include an additional argument, p_adjust, to specify the type of correction you want to apply for multiple comparisons (e.g., “Bonferroni”). If you don’t include the p_adjust argument, the default method will be “Holm”. In either case, the correction method will be listed in the output.\n\nlopez_overall &lt;- lopez_reduced %&gt;% \n  select(ParticipantID, OzEstimate, CalEstimate, M_postsoup)\n\ncorrelation(lopez_overall, p_adjust = \"bonferroni\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nOzEstimate\nCalEstimate\n0.2575243\n0.95\n0.1700045\n0.3410133\n5.697404\n457\n1e-07\nPearson correlation\n459\n\n\nOzEstimate\nM_postsoup\n0.2829064\n0.95\n0.1967556\n0.3647221\n6.326103\n460\n0e+00\nPearson correlation\n462\n\n\nCalEstimate\nM_postsoup\n0.3611089\n0.95\n0.2789816\n0.4379921\n8.296305\n459\n0e+00\nPearson correlation\n461\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen running the code in the .Rmd file, the correction method is displayed beneath the table in the printout. However, when the document is knitted into HTML, this information does not appear.\nHowever, in the knitted document, the output also includes the number of observations for each row, whereas the .Rmd printout only displays the range of observation values beneath the table.\nSimilarly, p-values are displayed in APA style (e.g., p &lt; .001) in the .Rmd printout, but in the knitted document, they may appear in scientific notation or as 0. When reporting p-values in your report, ensure they adhere to APA style.\n\n\n\n\n\nThe effect size for correlations does not require additional computation. It is simply the vale of the correlation coefficient r.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-9-sensitivity-power-analysis",
    "href": "09-correlation.html#activity-9-sensitivity-power-analysis",
    "title": "9  Correlations",
    "section": "9.9 Activity 9: Sensitivity power analysis",
    "text": "9.9 Activity 9: Sensitivity power analysis\nAs with the t-test, we will conduct a sensitivity power analysis to determine the minimum effect size detectable with our sample of control participants (n = 244, accounting for the two missing values), an alpha level of 0.05, and a power of 0.8. This will help us assess whether our analysis was sufficiently powered.\nWe will use the pwr.r.test() function from the pwr package for the correlation analysis. As usual, include n, alpha, and power as arguments in the function, and leave out the effect size r.\n\npwr.r.test(n = 244, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")\n\n\n     approximate correlation power calculation (arctangh transformation) \n\n              n = 244\n              r = 0.1782315\n      sig.level = 0.05\n          power = 0.8\n    alternative = two.sided\n\n\nAccording to the output above, the smallest r detectable with 244 participants, a significance level of .05, and a power of .8 is .178. Since Lopez et al. reported an effect size of r = .41, the study was sufficiently powered.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-10-the-write-up",
    "href": "09-correlation.html#activity-10-the-write-up",
    "title": "9  Correlations",
    "section": "9.10 Activity 10: The write-up",
    "text": "9.10 Activity 10: The write-up\nLopez et al. (2024) hypothesised a positive correlation between estimated calories of soup consumed \\((M = 133.0 cal, SD = 121.3 cal)\\) and actual consumption volume \\((M = 8.87 oz, SD = 6.24 oz)\\). A Pearson correlation revealed a moderately strong, positive, and statistically significant relationship between these two variables that was sufficiently powered, \\(r(242) = .405, p &lt; .001, 95\\% CI = [.294, .504]\\). Lopez et al. rejected the null hypothesis in favour of H1.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#activity-11-non-parametric-alternative",
    "href": "09-correlation.html#activity-11-non-parametric-alternative",
    "title": "9  Correlations",
    "section": "9.11 Activity 11: Non-parametric alternative",
    "text": "9.11 Activity 11: Non-parametric alternative\nRunning a Pearson correlation when its assumptions are violated can lead to unreliable and misleading results, meaning the calculated correlation coefficient may not accurately reflect the true relationship between the variables.\nThe non-parametric alternative is Spearman’s Rank correlation. However, Spearman’s correlation also has a few assumptions:\n\nBoth variables must be measured on ordinal, interval or ratio scales.\nThere must be a monotonic relationship between the two variables, meaning they are either positively or negatively correlated. The data points should not display a “U-shape” or an “inverted U-shape”.\n\nLet’s assess monotonicity with a scatterplot. Use the “loess” method to fit the curve, as we are not aiming to show a linear relationship this time.\n\nggplot(lopez_control_no_outliers, aes(x = CalEstimate, y = M_postsoup)) +\n  geom_point() +\n  geom_smooth(method = \"loess\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nVerdict: Both assumptions hold. The line of best fit displays a clear monotonic relationship, especially with the outliers removed. Therefore, we will proceed with Spearman’s correlation.\nBefore proceeding, we may want to recalculate the descriptives after removing the outliers:\n\n# descriptives for lopez_control_no_outliers\ndescriptives_control_no_outliers &lt;- lopez_control_no_outliers %&gt;% \n  summarise(n = n(),\n            mean_CalEstimate = mean(CalEstimate, na.rm = TRUE),\n            sd_CalEstimate = sd(CalEstimate, na.rm = TRUE),\n            mean_M_postsoup = mean(M_postsoup),\n            sd_M_postsoup = sd(M_postsoup)) %&gt;% \n  ungroup()\n\ndescriptives_control_no_outliers\n\n\n\n\n\nn\nmean_CalEstimate\nsd_CalEstimate\nmean_M_postsoup\nsd_M_postsoup\n\n\n\n\n241\n127.9668\n105.4418\n8.684232\n5.862664\n\n\n\n\n\n\nNext we will move on to the inferential test. The code remains the same as above, but this time we will change the method to “Spearman” and use the data object lopez_control_no_outliers.\n\ncorrelation(lopez_control_no_outliers, method = \"Spearman\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nrho\nCI\nCI_low\nCI_high\nS\np\nMethod\nn_Obs\n\n\n\n\nCalEstimate\nM_postsoup\n0.5225186\n0.95\n0.4210739\n0.6110526\n1113907\n0\nSpearman correlation\n241\n\n\n\n\n\n\nWriting-up the results would be similar to the Pearson correlation above.\nIt was hypothesised that there would be a positive correlation between estimated calories of soup consumed \\((M = 128.0 cal, SD = 105.4 cal)\\) with actual consumption volume \\((M = 8.68 oz, SD = 5.86 oz)\\). The assumptions of linearity, normality, and homoscedasticity were assessed visually using a Residuals vs Fitted plot, a Q-Q plot, and a Scale-Location plot, respectively. These assumptions did not hold. Additionally, three outliers were removed from the dataset.\nConsequently, a Spearman’s rank correlation was conducted, revealing a strong, positive, and statistically significant relationship between estimated calories of soup consumed and actual consumption volume, \\(rho(239) = .522, p &lt; .001, 95\\% CI = [.421, .611]\\). The study was sufficiently powered. Therefore, the null hypothesis is rejected in favour of H1.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "09-correlation.html#test-your-knowledge",
    "href": "09-correlation.html#test-your-knowledge",
    "title": "9  Correlations",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nWhat is the main purpose of a Pearson correlation?\n\n To compare the means of two independent groups. To determine the monotonic relationship between two ordinal variables. To test for differences in variances between two continuous variables. To assess the strength and direction of a linear relationship between two continuous variables.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n“To assess the strength and direction of a linear relationship between two continuous variables.” is the correct answer.\nThe other options are incorrect:\n\n“To compare the means of two independent groups” is incorrect because that describes an independent t-test, not correlation.\n“To determine the monotonic relationship between two ordinal variables” is incorrect because that describes Spearman’s correlation, not Pearson’s.\n“To test for differences in variances between two continuous variables” is incorrect because that refers to Levene’s test or similar, not correlation.\n\n\n\n\n\n\nQuestion 2\nWhich of the following is a key assumption of the Pearson correlation?\n\n The two variables are measured on an ordinal, interval, or ratio scale The dependent variable is continuous. The relationship between the two variables is linear. The test is robust against outliers.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nPearson correlation assumes linearity.\nThe other options are incorrect: \n\n“The two variables are measured on a ordinal scale” is incorrect because Pearson correlation requires interval or ratio data, but for ordinal data you would have to switch to the non-parametric equivalent (i.e. “Spearman”).\n“The dependent variable is continuous” is incorrect because there are no dependent and independent variables in a correlation. The variables are called “measured variables” or just “variables”. And both of them need to be measured on a continuous scale.\n“The test is robust against outliers” is incorrect because outliers can strongly influence the Pearson correlation coefficient, making it less robust in their presence.\n\n\n\n\n\n\nQuestion 3\nYou perform a Pearson correlation and find \\(r(244) = .415, p = .002\\). How would you interpret these results??\n\n There is a moderate, positive, statistically significant correlation between the two variables. There is a moderate, negative, statistically non-significant correlation between the two variables. There is a moderate, negative, statistically significant correlation between the two variables. There is a moderate, positive, statistically non-significant correlation between the two variables.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n“There is a moderate, positive, statistically significant correlation between the two variables.” is the correct answer. The correlation value (\\(r=.415\\)) indicates a moderate, positive relationship, and the p-value (\\(p=.002\\)) indicates statistical significance.\n\n\n\n\n\nQuestion 4\nWhat does a Spearman correlation coefficient of \\(rho = -.729\\) indicate?\n\n A non-significant relationship. A strong, negative linear relationship. A strong, negative monotonic relationship. A strong, positive monotonic relationship.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\n“A strong, negative monotonic relationship.” is the correct answer. The value of .729 indicates a strong relationship and the minus indicates it is negative. For Spearman the relationship has to be monotonic.\nThe other options are incorrect:\n\n“A strong, positive monotonic relationship” is incorrect because the minus implies the relationship is negative, not positive.\n“A strong, negative linear relationship” is incorrect because Spearman measures monotonic relationships, not linear ones.\n“A non-significant relationship” is incorrect because the question does not state the p-value or provide sample size information. Hence, we cannot assume anything about significance. For example, small samples with large rho (or r) values may not be statistically significant. Contrastingly, in large samples, smaller rho (or r) values can be significant.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Correlations</span>"
    ]
  },
  {
    "objectID": "10-regression.html",
    "href": "10-regression.html",
    "title": "10  Simple regression",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#intended-learning-outcomes",
    "href": "10-regression.html#intended-learning-outcomes",
    "title": "10  Simple regression",
    "section": "",
    "text": "Compute a Simple linear regression.\nRead and interpret the output.\nReport the results.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#individual-walkthrough",
    "href": "10-regression.html#individual-walkthrough",
    "title": "10  Simple regression",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-1-setup-download-the-data",
    "href": "10-regression.html#activity-1-setup-download-the-data",
    "title": "10  Simple regression",
    "section": "10.1 Activity 1: Setup & download the data",
    "text": "10.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2B_chapter10”, or “10_regression”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you need help.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the new dataset here: data_ch10.zip. The zip folder includes the data file and the codebook.\nExtract the data file from the zip folder and place it in your project folder. If you need help, see Section 1.4.\n\nCitation\n\nAlter, U., Dang, C., Kunicki, Z. J., & Counsell, A. (2024). The VSSL scale: A brief instructor tool for assessing students’ perceived value of software to learning statistics. Teaching Statistics, 46(3), 152-163. https://doi.org/10.1111/test.12374\n\nAbstract\n\nThe biggest difference in statistical training from previous decades is the increased use of software. However, little research examines how software impacts learning statistics. Assessing the value of software to statistical learning demands appropriate, valid, and reliable measures. The present study expands the arsenal of tools by reporting on the psychometric properties of the Value of Software to Statistical Learning (VSSL) scale in an undergraduate student sample. We propose a brief measure with strong psychometric support to assess students’ perceived value of software in an educational setting. We provide data from a course using SPSS, given its wide use and popularity in the social sciences. However, the VSSL is adaptable to any statistical software, and we provide instructions for customizing it to suit alternative packages. Recommendations for administering, scoring, and interpreting the VSSL are provided to aid statistics instructors and education researchers understand how software influences students’ statistical learning.\n\nThe data is available on OSF: https://osf.io/bk7vw/\nChanges made to the dataset\n\nWe converted the Excel file into a CSV file.\nWe aggregated the main scales (columns 50-57) by reverse-scoring all reverse-coded items (as specified in the codebook), and then computed an average score for each scale.\nHowever, responses to the individual questionnaire items (columns 1-49) remain as raw data and have not been reverse-coded. If you’d like to practice your data-wrangling skills, feel free to do so!\nWe tidied the columns RaceEthE, GradesE, and MajorE, but we’ve left Gender and Student Status for you to clean.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "href": "10-regression.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "title": "10  Simple regression",
    "section": "10.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data",
    "text": "10.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data\nToday, we will be using the packages tidyverse, performance, and pwr, along with the dataset Alter_2024_data.csv.\n\n???\n\ndata_alter &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(performance)\nlibrary(pwr)\ndata_alter &lt;- read_csv(\"Alter_2024_data.csv\")\n\n\n\n\nAs always, take a moment to familiarise yourself with the data before starting your analysis.\n\n\n\n\n\n\nYour Turn\n\n\n\nQuick check: Have you familiarised yourself with the data? Answer the following questions:\n\nHow many observations? \nHow many variables? \nHow many columns are col_character or chr data type? \nHow many columns are col_double or dbl data type? \nFrom the dropdown menu, select the variable type and the data type for each of the following variables.\n\n\n\n\n\n\n\n\n\nColumn\nVariable type\nData type\n\n\n\n\nAgeE\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nGenderE\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nGPAE\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nStuStaE\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nMA1E\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nMean_MA\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\n\n\n\n\nPotential Research Question & Hypthesis\nLet’s assume that individuals who are confident in quantitative reasoning are more likely to feel comfortable using statistical software.\n\nPotential research question: “Does quantitative self-efficacy predict attitudes toward SPSS, as measured by the VSSL Scale?”\nNull Hypothesis (H0): “Quantitative self-efficacy does not significantly predict attitudes toward SPSS (VSSL scores).”\nAlternative Hypothesis (H1): “Quantitative self-efficacy significantly predicts attitudes toward SPSS (VSSL scores), such that higher quantitative self-efficacy is associated with more positive attitudes toward SPSS.”\n\nThus, in this hypothetical scenario, the regression model would be:\n\nIndependent Variable (IV)/ Predictor: Quantitative self-efficacy\nDependent Variable (DV)/ Outcome: Attitudes toward SPSS (measured by the VSSL Scale)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-3-preparing-the-dataframe",
    "href": "10-regression.html#activity-3-preparing-the-dataframe",
    "title": "10  Simple regression",
    "section": "10.3 Activity 3: Preparing the dataframe",
    "text": "10.3 Activity 3: Preparing the dataframe\nThe dataframe is already tidy for most variables, except for Gender and Student Status. This means we’re all set for this week.\nHowever, working with a smaller subset of the data will be beneficial. Select the relevant variables of interest and store the results in a new data object called data_alter_reduced.\n\n\n\n\n\n\nHints\n\n\n\n\n\nOf course, you have identified the variables Quantitative self-efficacy (Mean_QSE) and the VSSL Scale: Value of Software to Learning Statistics (Mean_SPSS).\nBut did you remember that we also need the participant ID (StudentIDE)?\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata_alter_reduced &lt;- data_alter %&gt;% \n  select(StudentIDE, Mean_QSE, Mean_SPSS)\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Activity - recoding Gender and Student Status\n\n\n\n\n\n\n\n\n\n\n\nChallenge yourself: Easy (recoding Gender)\n\n\n\n\n\nRecode column GenderE so the values read “Female”, “Male”, and “Non-Binary” instead of 1, 2, and 3. Use the codebook to guide you. We have done this quite a few times now, but if you need a hint, recoding values was covered in Section 3.3.\nMight as well turn Gender into a factor while we are at it.\n\n\n\n\n\n\nSolution for Gender\n\n\n\n\n\n\ndata_alter &lt;- data_alter %&gt;% \n  mutate(Gender = case_match(GenderE,\n                             1 ~ \"Female\",\n                             2 ~ \"Male\",\n                             3 ~ \"Non-Binary\"),\n         Gender = factor(Gender))\n\n\n\n\n\n\n\n\n\n\n\n\n\nChallenge yourself: A bit harder (recoding Student Status)\n\n\n\n\n\nHowever, recoding Student Status is a bit more tricky. There appear to be numbers and different ways of spelling.\nTo capture all of them, we will need to know the distinct categories fist. We have used the distinct() function briefly in previous chapters. Time to use it once more.\n\n\n\n\n\n\nSolution to identify distinct categories\n\n\n\n\n\n\ndata_alter %&gt;% \n  distinct(StuStaE)\n\n\n\n\n\nStuStaE\n\n\n\n\n4\n\n\n3\n\n\nJunior\n\n\nSenior\n\n\nsenior\n\n\nSophomore\n\n\n2\n\n\nNA\n\n\nFreshman\n\n\npost-bac\n\n\n\n\n\n\n\n\n\nNow that we have identified the distinct values of column StuStaE, we can use a conditional statement to recode those distinct categories to obtain the categorical labels in the codebook.\nDo you remember how conditional recoding is done? If not, get some inspiration from Section 3.4.\n\n\n\n\n\n\nSolution for Student Status: Option 1\n\n\n\n\n\nYou could only recode the values that are “incorrect”, i.e., converting the numbers into labels and grouping together everyone who falls into the category “Senior or Higher”.\nAs Student_Status is an ordinal variable, we should turn it into a factor to order the categories accordingly.\n\ndata_alter &lt;- data_alter %&gt;% \n  mutate(Student_Status = case_when(\n    StuStaE == \"2\" ~ \"Sophomore\",\n    StuStaE == \"3\" ~ \"Junior\",\n    StuStaE %in% c(\"4\", \"Senior\", \"senior\", \"post-bac\") ~ \"Senior or Higher\",\n    .default = StuStaE\n  )) %&gt;% \n  mutate(Student_Status = factor(Student_Status,\n                                 levels = c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior or Higher\")))\n\n\n\n\n\n\n\n\n\n\nSolution for Student Status: Option 2\n\n\n\n\n\nYou could also recode all the labels whether they are already correctly spelled or not, if that seems more intuitive to you. You could leave out the .default argument this way. Yet, you’d still have to group everyone who falls into the category “Senior or Higher”. Perhaps, a bit more writing overall, but the same outcome.\nI will label the newly recoded columns differently, so you’ll see that both ways get you the same outcome.\n\ndata_alter &lt;- data_alter %&gt;% \n  mutate(StuSta_tidy = case_when(\n           StuStaE %in% c(\"1\", \"Freshman\") ~ \"Freshman\",\n           StuStaE %in% c(\"2\", \"Sophomore\") ~ \"Sophomore\",\n           StuStaE %in% c(\"3\", \"Junior\") ~ \"Junior\",\n           StuStaE %in% c(\"4\", \"Senior\", \"senior\", \"post-bac\") ~ \"Senior or Higher\"),\n         StuSta_tidy = factor(StuSta_tidy,\n                              levels = c(\"Freshman\", \"Sophomore\", \"Junior\", \"Senior or Higher\")))",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-4-compute-descriptives",
    "href": "10-regression.html#activity-4-compute-descriptives",
    "title": "10  Simple regression",
    "section": "10.4 Activity 4: Compute descriptives",
    "text": "10.4 Activity 4: Compute descriptives\nNow, we can calculate the means and standard deviations for our predictor and outcome variables.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndescriptives &lt;- data_alter_reduced %&gt;%\n  summarise(mean_QSE = mean(Mean_QSE, na.rm = TRUE),\n            sd_QSE = sd(Mean_QSE, na.rm = TRUE),\n            mean_SPSS = mean(Mean_SPSS, na.rm = TRUE),\n            sd_SPSS = sd(Mean_SPSS, na.rm = TRUE))",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-5-create-an-appropriate-plot",
    "href": "10-regression.html#activity-5-create-an-appropriate-plot",
    "title": "10  Simple regression",
    "section": "10.5 Activity 5: Create an appropriate plot",
    "text": "10.5 Activity 5: Create an appropriate plot\nNow, let’s recreate the following appropriate plot using data_alter_reduced:\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(data_alter_reduced, aes(x = Mean_QSE, y = Mean_SPSS)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-6-check-assumptions",
    "href": "10-regression.html#activity-6-check-assumptions",
    "title": "10  Simple regression",
    "section": "10.6 Activity 6: Check assumptions",
    "text": "10.6 Activity 6: Check assumptions\n\nAssumption 1: Levels of measurement\n\nThe outcome variable must be interval/ratio (continuous)\nThe predictor variable must be either interval/ratio (continuous) or categorical (with two levels)\n\nIn our case, both the predictor variable (Quantitative self-efficacy) and the outcome variable (Attitudes toward SPSS as measured by the VSSL Scale) are continuous. The assumption holds.\n\n\nAssumption 2: Independence of cases/observations\nWe must assume that each observation is independent of the others, meaning that each score comes from a different participant. Like assumption 1, this assumption is determined by the study design and it holds.\n\n\nAssumption 3: Non-zero variance\nSimply put, we need to have some spread in the data. The variance must be greater than zero.\nWe can check this by looking at the scatterplot: both the x-axis (predictor) and y-axis (outcome) should show variability. Similarly, we computed standard deviations for both variables in Activity 4, and both of them had values different to 0. So this assumption holds as well.\n\n\nAssumption 4: Linearity\nSince we will need the linear model for the next few assumptions and later for inferential statistics, we should first save it to the Global Environment as an object called mod.\nThe linear model function lm() requires the following arguments:\n\nThe outcome variable, followed by a tilde (~), followed by the the predictor variable\nThe dataset\n\n\nmod &lt;- lm(Mean_SPSS~Mean_QSE, data = data_alter_reduced)\n\nNow we can continue with the assumption check of linearity. The relationship between the two variables must be linear.\nWe can assess linearity visually, just as we did in the correlation chapter, by using a Residuals vs Fitted plot. We can use the plot() function on our linear model (mod) with the which argument set to 1.\n\nplot(mod, which = 1)\n\n\n\n\n\n\n\n\nVerdict: The red line is roughly horizontal and flat, indicating that the relationship between the predictor and outcome is linear. This assumption holds.\n\n\nAssumption 5: Normality\nResiduals for both variables should follow a bivariate normal distribution (i.e., both together normally distributed).\nWe can visually check this assumption using a Q-Q plot. To generate it, we use the plot() function on our linear model mod, setting the which argument to 2. Again, this is the same approach we used in the correlation chapter to check for normality.\n\nplot(mod, which = 2)\n\n\n\n\n\n\n\n\nVerdict: Doesn’t this look beautiful? ✨ The points closely follow the diagonal line, indicating that the assumption of normality holds.\n\n\nAssumption 6: Homoscedasticity\nHomoscedasticity assumes that the spread of residuals is consistent across all levels of the predictor variable, meaning that the data is evenly distributed around the line of best fit, with no visible pattern. We can assess this assumption visually using a Scale-Location plot.\nTo generate it, we use the plot() function on our linear model mod, setting the which argument to 3:\n\nplot(mod, which = 3)\n\n\n\n\n\n\n\n\nVerdict: The variance of the residual is constant along the values of predictor variable as indicated by this roughly flat and horizontal red line. Hence, we consider this assumption met.\n\n\nChecking Assumptions Differently: Using check_model() from the performance package\nAssumptions 4-6 can also be tested using the check_model() function from the performance package. This function provides the same diagnostic checks as plot(), but with a cleaner presentation and useful reminders of what to look for.\n\ncheck_model(mod)\n\n\n\n\n\n\n\n\nOne key difference is that you get a posterior predictive check, which compares observed values to the model’s predictions. Additionally, the Q-Q plot for normality of residuals is displayed different. Instead of a diagonal reference line, residuals are plotted as deviations from a horizontal line. This visualisation can sometimes exaggerate small deviations, so focus on identifying clear overall patterns rather than minor fluctuations.\n\n\n\n\n\n\nTip\n\n\n\nThe diagnostic plots in the performance package are generated using ggplot2, so you can save them using ggsave() if needed.\n\n\nBut again; all assumptions are met. Let’s move on to inferential statistics!",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-7-compute-the-regression-confidence-intervals-and-effect-size",
    "href": "10-regression.html#activity-7-compute-the-regression-confidence-intervals-and-effect-size",
    "title": "10  Simple regression",
    "section": "10.7 Activity 7: Compute the regression, confidence intervals, and effect size",
    "text": "10.7 Activity 7: Compute the regression, confidence intervals, and effect size\nThe lm() function from Base R is the main function to estimate a Linear Model (hence the function name lm). And if you’re experiencing a hint of déjà vu, you’re onto something! We have actually already used this function to store our linear model for assumption checks (remember the object called mod???).\nJust to recap, the lm() function uses formula syntax with the following arguments:\n\nlm(OutcomeVariable ~ PredictorVariable, data)\n\nFor our example, the variables are:\n\nIV (Predictor): Quantitative self-efficacy, and\nDV (Outcome): Attitudes toward SPSS (measured by the VSSL Scale)\n\nThus, our regression model is:\n\nmod &lt;- lm(Mean_SPSS~Mean_QSE, data = data_alter_reduced)\n\nAs you can see in the Global Environment, mod stores a list of 12 elements, containing quite a bit of information about the regression model.\nTo view the results of our simple linear regression, use the summary() function on the mod object:\n\nsummary(mod)\n\n\nCall:\nlm(formula = Mean_SPSS ~ Mean_QSE, data = data_alter_reduced)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.94132 -0.48539 -0.01985  0.51461  1.60274 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.60403    0.23404  11.126  &lt; 2e-16 ***\nMean_QSE     0.26441    0.06722   3.933  0.00012 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7023 on 179 degrees of freedom\nMultiple R-squared:  0.07956,   Adjusted R-squared:  0.07442 \nF-statistic: 15.47 on 1 and 179 DF,  p-value: 0.0001196\n\n\n\n\n\n\n\n\nDoes it matter if the slope is positive or negative?\n\n\n\nWhen working with a continuous predictor, the sign of the slope is important to consider:\n\nA positive slope indicates that as the predictor increases, the outcome variable also tends to increase.\nA negative slope means that as the predictor increases, the outcome variable tends to decrease.\n\nUnderstanding the direction of the relationship is crucial for correctly interpreting the regression coefficient.\n\n\nSooo. We already have several key values, but we still need confidence intervals and effect sizes to fully report our results.\nR has a built-in function called confint() to calculate confidence intervals using our linear model object mod.\n\nconfint(mod)\n\n                2.5 %    97.5 %\n(Intercept) 2.1421954 3.0658579\nMean_QSE    0.1317614 0.3970575\n\n\nThe effect size for a simple linear regression is Cohen’s \\(f^2\\). We can calculate it manually. As you may recall from the lectures, the formula for Cohen’s \\(f^2\\) is:\n\\[\nf^2 = \\frac{R^2_{Adjusted}}{1-R^2_{Adjusted}}\n\\]\nIn our case, we can extract \\(R^2_{Adjusted}\\) from the summary(mod) output.\n\nr_sq_adj &lt;- summary(mod)$adj.r.squared\n\nAnd then, we just use r_sq_adj in the formula above:\n\nf_2 &lt;- r_sq_adj/(1-r_sq_adj)\n\nf_2\n\n[1] 0.08039889\n\n\nNow, we have all the necessary values to write up the results!",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-8-sensitivity-power-analysis",
    "href": "10-regression.html#activity-8-sensitivity-power-analysis",
    "title": "10  Simple regression",
    "section": "10.8 Activity 8: Sensitivity power analysis",
    "text": "10.8 Activity 8: Sensitivity power analysis\nAs usual, we can calculate the smallest effect size that our study was able to detect, given our design and sample size.\nTo do this, we use the pwr.f2.test() function from the pwr package. This function requires the following arguments:\n\nu = Numerator degrees of freedom. This the number of coefficients you have in your model (minus the intercept)\nv = Denominator degrees of freedom. This is calculated as \\(v=n-u-1\\), where \\(n\\) is the number of participants.\nf2 = The effect size. Here we are solving the effect size, so this parameter is left out\nsig.level = The significance level of your study\npower = The power level of your study\n\n\npwr.f2.test(u = 1, v = 179, sig.level = 0.05, power = 0.8)\n\n\n     Multiple regression power calculation \n\n              u = 1\n              v = 179\n             f2 = 0.04381313\n      sig.level = 0.05\n          power = 0.8\n\n\nWith the design and sample size we have, we could have detected an effect as small as \\(f^2 = 0.044\\). Since the observed effect size from our inferential statistics was larger (\\(f^2 = 0.080\\)), this means our test was sufficiently powered to detect the observed effect.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#activity-9-the-write-up",
    "href": "10-regression.html#activity-9-the-write-up",
    "title": "10  Simple regression",
    "section": "10.9 Activity 9: The write-up",
    "text": "10.9 Activity 9: The write-up\nA simple linear regression was performed with Attitudes toward SPSS \\((M = 3.50, SD = 0.73)\\) as the outcome variable and Quantitative self-efficacy \\((M = 3.39, SD = 0.78)\\) as the predictor variable.\nThe results of the regression indicated that the model significantly predicted Attitudes toward SPSS \\((F(1, 179) = 15.47 p &lt; .001, R^2_{Adjusted} = .074, f^2 = 0.080)\\), accounting for 7.4% of the variance. The effect of Quantitative self-efficacy was statistically significant, positive, and of small magnitude \\((b = 0.26, 95\\% CI = [.13, .40], p &lt;.001)\\). Therefore, we reject the null hypothesis in favour of H1. The analysis was sufficiently powered to detect this effect.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "10-regression.html#test-your-knowledge",
    "href": "10-regression.html#test-your-knowledge",
    "title": "10  Simple regression",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nWhat is the main purpose of a simple regression analysis?\n\n To compare means between two groups and determine if they are significantly different. To assess whether multiple independent variables jointly predict an outcome variable. To predict or explain changes in an outcome variable based on changes in a predictor variable. To determine whether there is an association between two variables, without assuming causality.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nSimple regression is used to model the relationship between one predictor and one outcome variable and to determine how well the predictor explains variations in the outcome. While correlation measures association and t-tests compare means, regression specifically focuses on prediction or explanation. Multiple regression involves more than one predictor.\n\n\n\n\n\nQuestion 2\nA sports scientist wants to examine whether an athlete’s reaction time (in milliseconds) can predict their sprint speed (in seconds) in a 100m race.\nWhich of the following correctly specifies the simple regression model in R?\n\n lm(Sprint_Speed ~ Reaction_Time + Training_Hours, data = data) lm(Reaction_Time ~ Sprint_Speed, data = data) lm(Reaction_Time ~ Sprint_Speed + Age, data = data) lm(Sprint_Speed ~ Reaction_Time, data = data)\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIn a simple regression model, the outcome variable (dependent variable, DV) should be placed first, followed by the tilde (~), and then the predictor variable (independent variable, IV). That’s why the correct solution is Sprint_Speed ~ Reaction_Time.\nIn one of the options, the variables were reversed, treating sprint speed as the predictor and reaction time as the outcome variable.\nThe other 2 options incorrectly include multiple predictors, which would make this a multiple regression model.\n\n\n\n\n\nQuestion 3\nIn a simple regression model where reaction time (milliseconds) predicts sprint speed (seconds), the regression output shows:\n\\[\nSprint Speed = 10.2 + 0.08 × Reaction Time\n\\]\nHow should the slope be interpreted?\n\n A 1-millisecond increase in reaction time is associated with a 0.08-second decrease in sprint speed. A 1-millisecond increase in reaction time is associated with a 0.08-second increase in sprint speed. A 1-millisecond increase in reaction time is associated with a 10.2-second decrease in sprint speed. A 1-millisecond increase in reaction time is associated with a 10.2-second increase in sprint speed.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe slope (0.08), not the intercept (10.2), tells us the expected change in the outcome variable (sprint speed) for a one-unit increase in the predictor (reaction time). Since the coefficient is positive, it indicates that slower reaction times (higher values) are associated with slower sprint speeds (higher times).\n\n\n\n\n\nQuestion 4\nA simple regression analysis finds an \\(R^2_{Adjusted} = 0.62\\) when predicting sprint speed from reaction time. What does this mean?\n\n The predictor fully explains the outcome. The model does not fit well because the adjusted \\(R^2\\) is too high. 62% of the variance in reaction time is explained by sprint speed. 62% of the variance in sprint speed is explained by reaction time.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nAdjusted \\(R^2\\) represents the proportion of variance in the dependent variable (sprint speed) that is explained by the independent variable (reaction time). A value of 0.62 means that 62% of the differences in sprint speed can be accounted for by reaction time, indicating a strong predictive relationship.\nThe other options are incorrect:\n\nOne of the options reverses the outcome variable and the predictor. Since the DV is sprint speed, we cannot say that 62% of reaction time is explained by sprint speed.\nA high \\(R^2\\) adjusted does not mean the predictor fully explains the outcome. Some variability (\\(1 - R^2_{Adjusted} = 38\\%\\)) remains unexplained, meaning other factors beyond reaction time contribute to sprint speed. A perfect model would have (\\(R^2 = 1.00\\)), which is almost never the case in real data.\nA high \\(R^2\\) adjusted does not mean the model is bad. In fact, 0.62 is quite strong, meaning the model fits the data well. A high can sometimes be concerning if it’s unexpectedly large (e.g., above 0.90 in social sciences), but here it may simply indicate a strong relationship.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Simple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html",
    "href": "11-multiple-regression.html",
    "title": "11  Multiple regression",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:\nIn the previous chapter, we have looked at simple regressions - predicting an outcome variable using one predictor variable. In this chapter, we will expand on that and look at scenarios where we predict an outcome using more than one predictor in the model - hence, multiple regression.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#intended-learning-outcomes",
    "href": "11-multiple-regression.html#intended-learning-outcomes",
    "title": "11  Multiple regression",
    "section": "",
    "text": "Apply and interpret multiple linear regression models.\nInterpret coefficients from individual predictors and interactions.\nVisualise interactions as model predictions to understand and communicate your findings.\nCalculate statistical power for a multiple regression model.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#individual-walkthrough",
    "href": "11-multiple-regression.html#individual-walkthrough",
    "title": "11  Multiple regression",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-1-setup-download-the-data",
    "href": "11-multiple-regression.html#activity-1-setup-download-the-data",
    "title": "11  Multiple regression",
    "section": "11.1 Activity 1: Setup & download the data",
    "text": "11.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2B_chapter11”, or “11_multiple_regression”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you need help.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the new dataset here: data_ch11.zip. The zip folder includes:\n\nthe demographics data file (Przybylski_2017_demographics.csv)\nthe screentime data file (Przybylski_2017_screentime.csv)\nthe wellbeing data file (Przybylski_2017_wellbeing.csv), and the\nthe codebook (Przybylski_2017_Codebook.xlsx).\n\nExtract the data file from the zip folder and place it in your project folder. If you need help, see Section 1.4.\n\nCitation\n\nPrzybylski, A. K., & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis: Quantifying the Relations Between Digital-Screen Use and the Mental Well-Being of Adolescents. Psychological Science, 28(2), 204-215. https://doi.org/10.1177/0956797616678438\n\nAbstract\n\nAlthough the time adolescents spend with digital technologies has sparked widespread concerns that their use might be negatively associated with mental well-being, these potential deleterious influences have not been rigorously studied. Using a preregistered plan for analyzing data collected from a representative sample of English adolescents (n = 120,115), we obtained evidence that the links between digital-screen time and mental well-being are described by quadratic functions. Further, our results showed that these links vary as a function of when digital technologies are used (i.e., weekday vs. weekend), suggesting that a full understanding of the impact of these recreational activities will require examining their functionality among other daily pursuits. Overall, the evidence indicated that moderate use of digital technology is not intrinsically harmful and may be advantageous in a connected world. The findings inform recommendations for limiting adolescents’ technology use and provide a template for conducting rigorous investigations into the relations between digital technology and children’s and adolescents’ health.\n\nThe data is available on OSF: https://osf.io/bk7vw/\nChanges made to the dataset\n\nThe original SPSS file was converted into a CSV format. Although a CSV file was available in the OSF folder, it lacked labels and value explanations, so we opted to work from the SPSS file, which contained more information.\nWe reduced the dataset by selecting some of the variables relating to demographics, screentime and wellbeing.\nThe data was split into three separate files: demographics, screentime, and wellbeing.\nScreen time values were recoded to reflect hours according to the codebook.\nRows with missing values were removed from screentime.csv and wellbeing.csv.\nA codebook was created for the selected variables.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "href": "11-multiple-regression.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "title": "11  Multiple regression",
    "section": "11.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data",
    "text": "11.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data\nToday, we will use the following packages tidyverse, sjPlot, performance, and pwr, along with the three data files from the Przybylski and Weinstein (2017) study.\n\n???\n\ndemo &lt;- ???\nscreentime &lt;- ???\nwellbeing &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(performance)\nlibrary(pwr)\n\ndemo &lt;- read_csv(\"Przybylski_2017_demographics.csv\")\nscreentime &lt;- read_csv(\"Przybylski_2017_screentime.csv\")\nwellbeing &lt;- read_csv(\"Przybylski_2017_wellbeing.csv\")\n\n\n\n\nAs always, take a moment to familiarise yourself with the data before starting your analysis.\nOnce you have explored the data objects and the codebook, try and answer the following questions:\n\nThe variable Gender is located in the object named demowellbeingscreentime.\nThe wellbeing data is in longwide format and contains observations from  participants.\nThe wellbeing questionnaire has  items.\nIndividual participants in this dataset are identified by the variable , which allows us to link information across the three tables.\nAre there any missing data points? YesNo\n\n\nPotential Research Question & Hypthesis\nThere is ongoing debate about how smartphones affect well-being, particularly among children and teenagers. Therefore, we will examine whether smartphone use predicts mental well-being and whether this relationship varies by gender among adolescents.\n\nPotential research question: “Does smartphone use predict mental well-being, and does this relationship differ between male and female adolescents?”\nNull Hypothesis (H0): “Smartphone use does not predict mental well-being, and there is no difference in this relationship between male and female adolescents.”\nAlternative Hypothesis (H1): “Smartphone use is a significant predictor of mental well-being, and the effect of smartphone use on well-being differs between male and female adolescents.”\n\nNote that in this analysis, we have:\n\nA continuous dependent variable (DV)/Outcome: well-being\nA continuous independent variable (IV)/Predictor: screen time\nA categorical independent variable (IV)/Predictor: gender\n\n* these variables are only quasi-continuous, inasmuch as only discrete values are possible. However, there are a sufficient number of discrete categories that we can treat them as effectively continuous.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-3-compute-descriptives",
    "href": "11-multiple-regression.html#activity-3-compute-descriptives",
    "title": "11  Multiple regression",
    "section": "11.3 Activity 3: Compute descriptives",
    "text": "11.3 Activity 3: Compute descriptives\nToday, most of the data wrangling will be done in the upcoming activities. To streamline the process, we will move “Computing descriptives” forward.\n\n11.3.1 Well-being\nWe need to do some initial data wrangling on wellbeing.\nFor each participant, compute the total score for the mental health questionnaire. Store the output in a new data object called wemwbs.\nThe new dataset should have two variables:\n\nSerial - the participant ID.\nWEMWBS_sum - the total WEMWBS score.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nwemwbs &lt;- wellbeing %&gt;%\n  pivot_longer(cols = starts_with(\"WB\"), # -Serial or WBOptimf:WBCheer also work\n               names_to = \"Qs\", \n               values_to = \"Score\") %&gt;%\n  group_by(Serial) %&gt;%\n  summarise(WEMWBS_sum = sum(Score)) %&gt;% \n  ungroup()\n\n\n\n\nIn the original paper, Przybylski and Weinstein (2017) reported: “Scores ranged from 14 to 70 (M = 47.52, SD = 9.55)”. Can you reproduce these values?\n\n\n\n\n\n\nHint\n\n\n\n\n\nMeans and standard deviations should not be an issue at this stage, but how would you calculate the minimum and the maximum?\nWe briefly covered this in Chapter 2, and the solution is more intuitive than you might think…\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYes, that’s right! The functions min() and max() are used to calculate the minimum and maximum values, respectively.\n\nwemwbs %&gt;% \n  summarise(mean = mean(WEMWBS_sum),\n            sd = sd(WEMWBS_sum),\n            min = min(WEMWBS_sum),\n            max = max(WEMWBS_sum))\n\n\n\n\n\nmean\nsd\nmin\nmax\n\n\n\n\n47.52189\n9.546374\n14\n70\n\n\n\n\n\n\n\n\n\n\n\n11.3.2 Screentime\nWe need to calculate the means and standard deviations for smartphone use (in hours) during the week and on the weekend.\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAt this stage, we are simply computing the values rather than storing them. However, if you’d like to save the output as an object in your Global Environment, feel free to do so.\n\nscreentime %&gt;% \n  summarise(smart_weekday_mean = mean(Smart_wk),\n            smart_weekday_sd = sd(Smart_wk),\n            smart_weekend_mean = mean(Smart_we),\n            smart_weekend_sd = sd(Smart_we))\n\n\n\n\n\n\n\n\n\n\n\nsmart_weekday_mean\nsmart_weekday_sd\nsmart_weekend_mean\nsmart_weekend_sd\n\n\n\n\n2.910655\n2.33917\n3.517003\n2.497139",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-4-recreating-the-plot-from-the-paper",
    "href": "11-multiple-regression.html#activity-4-recreating-the-plot-from-the-paper",
    "title": "11  Multiple regression",
    "section": "11.4 Activity 4: Recreating the plot from the paper",
    "text": "11.4 Activity 4: Recreating the plot from the paper\nIf there’s a challenge in this session, this is it! Our task is to wrangle the data and recreate the plot from the original article (shown below).\n\n\n\nFig. 1. Mental well-being as a function of daily digital-screen time on weekdays and weekends. Results are shown separately for time spent (a) watching TV and movies, (b) playing video games, (c) using computers, and (d) using smartphones. Error bars denote the 95% confidence intervals for the observed means. (Przybylski & Weinstein, 2017)\n\n\nThe graph shows that smartphone use of more than 1 hour per day is associated with increasingly negative well-being.\nWe can plot the relationship between well-being and hours of technology use, split into four categories of technology (video games, computers, smartphones, TV).\nThis plot involves faceting, and some of the required functions may be new to you. Don’t worry—we’ll guide you through the process!\n\n\n\n\n\n\nObservations\n\n\n\nLet’s start with some observations:\n\nWe need data on screen time (x-axis) and mental well-being (y-axis), which are currently stored in screentime and wellbeing, respectively. This means we will need to join the two datasets at some point.\nThe data needs to be restructured into long format so we can use the function facet_wrap().\nSince the plot includes separate lines for weekday and weekend screen time, we need to create a variable with two levels (weekday, weekend) rather than storing this information in separate columns.\nWe also need to compute the average well-being scores for each screen time level, separately for weekdays and weekends.\nThe visualization requires both a line plot (geom_line()) and a scatterplot (geom_point()) to create a “line with dots”.\nFor clarity, it would be best to label the different technology categories directly in the plot rather than listing them in the figure caption.\n\n\n\nNow it’s just figuring out which sequence we need them to be in. There are steps to do (or that easier to do) in the dataframe and then there is plotting.\nSooo, let’s start with any changes we can apply to the dataframe screentime. We should store the new output in an object called screen_long.\nStep 1: Pivot screentime into long format.\nStep 2: Extracting technology type and time period To access information on weekday/weekend and the four categories of technology, we need to separate information currently stored in column names. Anything before the separator _ represents the technology type. Anything after the separator _ indicates whether the data is from weekdays (wk) or weekends (we). (e.g., Watch_we, Smart_wk). Restructuring is easier when the data is in long format.\nStep 3: The current labels Watch, Smart, we or wk are not really informative. Since these labels will be displayed in the facets and legends of the final plot, we should rename them here to improve readability. Although legend labels can be adjusted later in the plot, facet labels are more difficult to modify, so it’s better to clean them now.\n\n“Watch” \\(\\rightarrow\\) “Watching TV”,\n“Comp” \\(\\rightarrow\\) “Playing Video Games”,\n“Comph” \\(\\rightarrow\\) “Using Computers”,\n“Smart” \\(\\rightarrow\\) “Using Smartphone”,\n“wk” \\(\\rightarrow\\) “Weekdays”, and\n“we” \\(\\rightarrow\\) “Weekends”.\n\nStep 4: To ensure all necessary information is in one place, join screen_long and wemwbs so that each participant has corresponding values from both dataframes.\nStep 5: For each technology type and screen time level, compute the average well-being scores separately for weekdays and weekends.\nSince steps 4 and 5 contribute to creating a summary dataset rather than modifying individual records, it might be best to store the output in a new object called dat_means.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nStep 1: uses pivot_longer()\nStep 2: remember the separate() function. It will come in handy here. And the separator needs to be “_“.\nStep 3: requires a simple recoding of the values, no conditional statements necessary\nStep 4: inner_join()\nStep 5: think about what column you need to group_by() before you can summarise()\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are just computing the information rather than storing it. If you want to save it as an object to your Global Environment, feel free to do so.\n\nscreen_long &lt;- screentime %&gt;%\n  # Step 1: Pivot into long format\n  pivot_longer(cols = -Serial, names_to = \"headings\", values_to = \"hours\") %&gt;%\n  # Step 2: `separate()`\n  separate(col = headings, into = c(\"technology_type\", \"day\"), sep = \"_\") %&gt;% \n  # Step 3: Recode the values\n  mutate(technology_type = case_match(technology_type,\n                                      \"Watch\" ~ \"Watching TV\",\n                                      \"Comp\" ~ \"Playing Video Games\",\n                                      \"Comph\" ~ \"Using Computers\",\n                                      \"Smart\" ~ \"Using Smartphone\"),\n         day = case_match(day,\n                          \"wk\" ~ \"Weekdays\",\n                          \"we\" ~ \"Weekends\"))\n\ndat_means &lt;- inner_join(wemwbs, screen_long, by = \"Serial\") %&gt;% # Step 4: joining\n  # Step 5: group_by & summarise\n  group_by(technology_type, day, hours) %&gt;%\n  summarise(mean_wellbeing = mean(WEMWBS_sum))\n\n`summarise()` has grouped output by 'technology_type', 'day'. You can override\nusing the `.groups` argument.\n\n\n\n\n\nNow we are ready to create the plot! This visualization includes a few new features related to line plots and point shapes. Take a moment to explore them.\n\nggplot(dat_means, aes(x = hours, y = mean_wellbeing, linetype = day, shape = day)) +\n  geom_line() +\n  geom_point() +\n  scale_shape_manual(values=c(15, 16)) +\n  facet_wrap(~ technology_type) + \n  theme_classic() + \n  labs(x = \"Hours of Technology Use\",\n       y = \"Mean Well-Being Score\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMore info on plot parameters\n\n\n\n\n\n\nThe aes(linetype = …) argument controls the type of line (e.g., solid or dotted). Here, we used it to differentiate between weekdays and weekends. More on line types can be found here: https://sape.inf.usi.ch/quick-reference/ggplot2/linetype.html\nTo change the shape of the points, we set shape inside aes(), linking it to the day type. However, by default, the shapes appeared as dots and triangles, whereas the original plot suggests dots and squares. We corrected this using scale_shape_manual(). More on point shapes can be found here: https://www.sthda.com/english/wiki/ggplot2-point-shapes\n\nIf you are looking really closely, you will notice that the order of the categories is slightly different, and that the x- and y-axis ranges extend a bit further. Feel free to fix that yourself.\nHmm. Actually, it seems the original authors created four separate plots and then combined them using a package like patchwork. Here, we used facets rather than creating those individual plots. That also means that the axis labels span across all plots rather than being repeated for each. Plus, the legend appears on the side instead of within each plot.\nAh well! Let’s call it a conceptual replication, then, shall we?",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-5-dataframe-for-the-regression-model",
    "href": "11-multiple-regression.html#activity-5-dataframe-for-the-regression-model",
    "title": "11  Multiple regression",
    "section": "11.5 Activity 5: Dataframe for the regression model",
    "text": "11.5 Activity 5: Dataframe for the regression model\nNow, we shift our focus to our hypothetical research question:\n\n“Does smartphone use predict mental well-being, and does this relationship differ between male and female adolescents?”\n\n\n11.5.1 Final data wrangling steps\nCreate a new data object that contains the average daily smartphone use per participant, averaged across weekdays and weekends.\nSince Przybylski and Weinstein’s findings suggest that smartphone use exceeding one hour per day is associated with increasingly negative well-being, we will filter the data to include only participants who use a smartphone for more than one hour per day.\nWe have already structured much of the data when creating screen_long, so we have two options:\n\nStart from screen_long to simplify the process, or\nReturn to the original screentime dataset, where smartphone use was recorded separately for weekdays and weekends.\n\nNext, we need to merge the wrangled data with well-being scores (as we did earlier) and also join it with the participant information, since we need the Gender variable for our analysis.\nFinally, store the cleaned dataset in an object called data_smartphone.\n\n\n\n\n\n\nHints: Option 1 (using screen_long)\n\n\n\n\n\n\nStep 1: Only include smartphone use and exclude other technologies.\nStep 2: Calculate the average smartphone use for each participant.\nStep 3: Only include participants who use a smartphone for more than 1 hour per day.\nStep 4: Join the filtered output with wemwbs, and demo, ensuring only participants with values in all three datasets are retained.\nStep 5: Select all variables of interest (i.e., Participant ID, the well-being score, the average smartphone use, and gender information)\n\n\n\n\n\n\n\n\n\n\nSolution Option 1\n\n\n\n\n\n\ndata_smartphone &lt;- screen_long %&gt;% \n  # Step 1\n  filter(technology_type == \"Using Smartphone\") %&gt;% \n  # Step 2\n  group_by(Serial) %&gt;% \n  summarise(average_hours = mean(hours)) %&gt;% \n  # Step 3\n  filter(average_hours &gt; 1) %&gt;% \n  # Step 4\n  inner_join(wemwbs) %&gt;% \n  inner_join(demo) %&gt;% \n  # Step 5\n  select(Serial, WEMWBS_sum, average_hours, Gender)\n\nJoining with `by = join_by(Serial)`\nJoining with `by = join_by(Serial)`\n\n\n\n\n\n\n\n\n\n\n\nHints Option 2 (using screentime)\n\n\n\n\n\n\nStep 1: Select all relevant variables from screentime.\nStep 2: Calculate the average smartphone use for each participant. This can be done by pivoting, grouping, and summarising (as we typically do), or simply by computing the mean as (col1 + col2) / 2.\nStep 3: Only include participants who use a smartphone for more than 1 hour per day.\nStep 4: Join the filtered output with wemwbs, and demo, ensuring only participants with values in all three datasets are retained.\nStep 5: Select all variables of interest (i.e., Participant ID, the well-being score, the average smartphone use, and gender information)\n\n\n\n\n\n\n\n\n\n\nSolution Option 2\n\n\n\n\n\n\ndata_smartphone &lt;- screentime %&gt;% \n  # Step 1\n  select(Serial, Smart_wk, Smart_we) %&gt;% \n  # Step 2 - different approach to computing averages\n  mutate(average_hours = (Smart_wk + Smart_we)/2) %&gt;% \n  # Step 3\n  filter(average_hours &gt; 1) %&gt;% \n  # Step 4\n  inner_join(wemwbs) %&gt;% \n  inner_join(demo) %&gt;% \n  # Step 5\n  select(Serial, WEMWBS_sum, average_hours, Gender)\n\nJoining with `by = join_by(Serial)`\nJoining with `by = join_by(Serial)`\n\n\n\n\n\n\n\n11.5.2 Mean-centering variables\nAs you have seen in the lectures, when you have continuous variables in a regression model, it is often sensible to transform them by mean centering. You mean center a predictor X by subtracting the mean of the predictor (X_centered = X - mean(X)) or you can use the scale() function. This has two useful consequences:\n\nThe model intercept represents the predicted value of \\(Y\\) when the predictor variable is at its mean, rather than at zero in the unscaled version.\nWhen interactions are included in the model, significant effects can be interpreted as the overall effect of a predictor on the outcome (i.e., a main effect) rather than its effect at a specific level of another predictor (i.e., a simple effect).\n\nFor categorical predictors with two levels, these become coded as -.5 and .5 (because the mean of these two values is 0). This is also known as deviation coding.\nIf we used dummy coding (i.e., leaving the categorical predictor as “Male” and “Female or unknown; default for R) instead of deviation coding, the interpretation would change slightly:\n\nDummy-coding interpretation: The intercept represents the predicted outcome for the reference group (coded as 0), and the coefficient for the categorical predictor represents the difference in the outcome between the two groups.\nDeviation-coding interpretation: The intercept represents the overall mean outcome across both groups, and the coefficient for the categorical predictor represents the average difference between the two groups, centered around zero.\n\nUse mutate() to add two new variables to data_smartphone:\n\naverage_hours_centered: calculated as a mean-centered version of the total_hours predictor\ngender_recoded: recode Gender .5 for “Male” and -.5 for “Female or unknown”.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndata_smartphone &lt;- data_smartphone %&gt;%\n  mutate(average_hours_centered = average_hours - mean(average_hours),\n         #alternative with the scale function: \n         #average_hours_centered = scale(average_hours, scale = FALSE),\n         gender_recoded = case_match(Gender,\n                                     \"Male\"  ~ 0.5,\n                                     \"Female or unknown\" ~ -0.5),\n         gender_recoded = factor(gender_recoded),\n         Gender = factor(Gender))",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-6-compute-the-regression-confidence-intervals-and-effect-size",
    "href": "11-multiple-regression.html#activity-6-compute-the-regression-confidence-intervals-and-effect-size",
    "title": "11  Multiple regression",
    "section": "11.6 Activity 6: Compute the regression, confidence intervals, and effect size",
    "text": "11.6 Activity 6: Compute the regression, confidence intervals, and effect size\nFor the data in data_smartphone, use the lm() function to calculate the multiple regression model:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i}  + \\beta_2 X_{2i}  + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\\(Y_i\\) is the well-being score for participant \\(i\\);\n\\(X_{1i}\\) is the mean-centered smartphone use for participant \\(i\\);\n\\(X_{2i}\\) is gender (coded as -0.5 = female, 0.5 = male);\n\\(X_{3i}\\) is the interaction between smartphone use and gender (\\(= X_{1i} \\times X_{2i}\\))\n\nIn R, this model is specified as:\n\nlm(Outcome ~ Predictor1 + Predictor2 + Interaction, data)\n\n\n\n\n\n\n\nTip\n\n\n\nThe formula lm(Outcome ~ Predictor1 + Predictor2, data) includes both predictors in the model, allowing you to examine their individual contributions (i.e., main effects) in explaining the outcome variable.\nHowever, if you are also interested in their interaction, you have two options:\n\nUsing the shorthand * operator: lm(Outcome ~ Predictor1 * Predictor2, data) automatically includes both main effects and their interaction. OR\nManually specifying the interaction term by using the : operator: lm(Outcome ~ Predictor1 + Predictor2 + Predictor1:Predictor2, data). Note: The colon (:) specifies an interaction term without including the main effects, so both predictors must also be listed separately to ensure a full model.\n\nBoth approaches yield the same results, but the * shorthand is often preferred for readability.\n\n\n\n\n\n\n\n\nYour Turn\n\n\n\n\nSave your model in an object mod.\nRun summary(mod) to see the output of the regression.\nCompute confidence intervals for the model coefficients.\nCalculate the effect size (\\(f^2\\)).\n\nThe functions you’ll use are the same as last time, except that this model includes multiple predictors and an interaction term.\nAnswer the following questions:\n\nThe interaction between smartphone use and gender is shown by the variable average_hours_centeredgender_recoded0.5average_hours_centered:gender_recoded0.5, and this interaction was significantnon-significant at the \\(\\alpha = .05\\) level.\nTo 2 decimal places, adjusted \\(R^2\\) suggests the overall model explains what percentage of the variance in well-being scores? \nThe p-value for the overall model fit is &lt;2e-16. Is this statistically significant? YesNo. How would you note that p-value in APA style when writing up the results? \nWhat is the observed effect size (in \\(f^2\\)) for the study to 3 decimal places? \n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## model\nmod &lt;- lm(formula = WEMWBS_sum ~ average_hours_centered * gender_recoded, \n               data = data_smartphone)\n\n## regression output\nsummary(mod)\n\n\nCall:\nlm(formula = WEMWBS_sum ~ average_hours_centered * gender_recoded, \n    data = data_smartphone)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                                         Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)                              44.86740    0.04478 1001.87   &lt;2e-16\naverage_hours_centered                   -0.77121    0.02340  -32.96   &lt;2e-16\ngender_recoded0.5                         5.13968    0.07113   72.25   &lt;2e-16\naverage_hours_centered:gender_recoded0.5  0.45205    0.03693   12.24   &lt;2e-16\n                                            \n(Intercept)                              ***\naverage_hours_centered                   ***\ngender_recoded0.5                        ***\naverage_hours_centered:gender_recoded0.5 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,   Adjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: &lt; 2.2e-16\n\n\n\n## confidence intervals\nconfint(mod)\n\n                                              2.5 %     97.5 %\n(Intercept)                              44.7796275 44.9551788\naverage_hours_centered                   -0.8170719 -0.7253385\ngender_recoded0.5                         5.0002576  5.2791028\naverage_hours_centered:gender_recoded0.5  0.3796615  0.5244376\n\n\n\n## effect size\nr_sq_adj &lt;- summary(mod)$adj.r.squared\nf_2 &lt;- r_sq_adj/(1-r_sq_adj)\nf_2\n\n[1] 0.1034697",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#ch11_act_7",
    "href": "11-multiple-regression.html#ch11_act_7",
    "title": "11  Multiple regression",
    "section": "11.7 Activity 7: Visualising interactions",
    "text": "11.7 Activity 7: Visualising interactions\nIt is very difficult to understand an interaction from the coefficient alone, so your best bet is visualising the interaction to help you understand the results and communicate your results to your readers.\nThere is a great package called sjPlot which takes regression models and helps you plot them in different ways. We will demonstrate plotting interactions, but for further information and options, see the online documentation.\nTo plot the interaction, you need the model object (not the summary), specify “pred” as the type as we want to plot predictions, and add the terms you want to plot.\n\nplot_model(mod, \n           type = \"pred\", \n           terms = c(\"average_hours_centered\", \"gender_recoded\"))\n\n\n\n\n\n\n\n\nWhat is the most reasonable interpretation of the interaction?\n\n smartphone use harms girls more than boys smartphone use was more negatively associated with wellbeing for girls than for boys smartphone use harms boys more than girls there is no evidence for gender differences in the relationship between smartphone use and well-being\n\n\n\n\n\n\n\nNote\n\n\n\nplot_model() uses ggplot2 in the background. You can add further customisation by adding layers after the initial function. You can also use ggsave() to save your plots and insert them into your work.\n\n\n\n\n\n\nExample of a more tidy plot\n\n\n\n\n\nFor example, we can tidy up the axis labels and remove the title, and set a theme.\n\nplot_model(mod, \n           type = \"pred\", \n           terms = c(\"average_hours_centered\", \"gender_recoded\")) + \n  labs(x = \"Total Hours Smartphone Use\",\n       y = \"Total Well-Being Score\",\n       title = \"\") + \n  theme_classic()",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-8-check-assumptions",
    "href": "11-multiple-regression.html#activity-8-check-assumptions",
    "title": "11  Multiple regression",
    "section": "11.8 Activity 8: Check assumptions",
    "text": "11.8 Activity 8: Check assumptions\nNow it’s time to test those pesky assumptions. The assumptions for multiple regression are the same as simple regression but there is one additional assumption, that of multicollinearity. This is the idea that predictor variables should not be too highly correlated.\nAssumptions are:\n\nThe outcome/DV is a interval/ratio level data, and the predictor variable is interval/ratio or categorical (with two levels).\nAll values of the outcome variable are independent (i.e., each score should come from a different participant).\nThe predictors have non-zero variance.\nThe relationship between outcome and predictor is linear.\nThe residuals should be normally distributed.\nThere should be homoscedasticity (homogeneity of variance, but for the residuals).\nMulticollinearity: predictor variables should not be too highly correlated.\n\nWe can use the plot() function for diagnostic plots or the check_model() from the performance package.\nOne difference from when we used check_model() previously is that rather than just letting it run all the tests it wants, we are going to specify which tests to stop it throwing an error.\n\n\n\n\n\n\nImportant\n\n\n\nA word of warning - these assumption tests will take longer than usual to run because it’s such a big data set.\n\n\n\ncheck_model(mod, \n            check = c(\"vif\", \n                      \"qq\", \n                      \"normality\", \n                      \"linearity\", \n                      \"homogeneity\"))\n\n\n\n\n\n\n\n\n\nAssumptions 1-3\nFrom the work we have done so far, we know that we meet assumptions 1-3.\n\n\nAssumption 4: Linearity\nWe already know from looking at the scatterplot that the relationship is linear, but the residual plot also confirms this.\n\n\nAssumption 5: Normality of residuals\nThe residuals look good in both plots and this provides an excellent example of why it’s often better to visualise than rely on statistics. With a sample size this large, any statistical diagnostic tests will be highly significant as they are sensitive to sample size.\n\n\nAssumption 6: Homoscedasticity\nThe plot is missing the reference line. Fun fact, this took us several days of our lives and asking for help on social media to figure out. The reason the line is not there is because the data set is so large that is creates a memory issue. However, if you use the plot() version, it does show the reference line.\n\nplot(mod, which = 3)\n\n\n\n\n\n\n\n\nIt is not perfect, but the reference line is roughly flat to suggest there are no serious issues with homoscedasticity.\n\n\nAssumption 7: Multicollinearity\nFrom the collinearity plot, we can see that both main effects and the interaction term are in the “green zone” which is great. Howeverm we can also test this statistically using check_collinearity() to produce VIF (variance inflation factor) and tolerance values.\nEssentially, this function estimates how much the variance of a coefficient is “inflated” because of linear dependence with other predictors, i.e., that a predictor is not actually adding any unique variance to the model, it’s just really strongly related to other predictors. You can read more about this online. Thankfully, VIF is not affected by large samples like other statistical diagnostic tests.\nThere are various rules of thumb, but most converge on a VIF of above 2 - 2.5 for any one predictor to be problematic. Here we are well under 2 for all 3 terms of the model.\n\ncheck_collinearity(mod)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\n\naverage_hours_centered\n1.721968\n1.704219\n1.740165\n1.312238\n0.5807308\n0.5746582\n0.5867789\n\n\ngender_recoded\n1.035552\n1.028488\n1.044369\n1.017621\n0.9656682\n0.9575159\n0.9723014\n\n\naverage_hours_centered:gender_recoded\n1.716349\n1.698683\n1.734463\n1.310095\n0.5826319\n0.5765474\n0.5886915",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-9-sensitivity-power-analysis",
    "href": "11-multiple-regression.html#activity-9-sensitivity-power-analysis",
    "title": "11  Multiple regression",
    "section": "11.9 Activity 9: Sensitivity power analysis",
    "text": "11.9 Activity 9: Sensitivity power analysis\nAs usual, we want to calculate the smallest effect size that our study was able to detect, given our design and sample size.\nTo do this, we use the pwr.f2.test() function from the pwr package. This is the same as in chapter 10 for simple linear regression. Remember the arguments for this function:\n\nu = Numerator degrees of freedom. This the number of coefficients you have in your model (minus the intercept)\nv = Denominator degrees of freedom. This is calculated as \\(v=n-u-1\\), where \\(n\\) is the number of participants.\nf2 = The effect size. Here we are solving the effect size, so this parameter is left out\nsig.level = The significance level of your study. This is usually set to 0.05\npower = The power level of your study. This is usually set to 0.8, but let’s go for 0.99 this time (just because we have such a large number of participants)\n\nRun the sensitivity power analysis and then answer the following questions:\n\nTo 4 decimal places, what is the smallest effect size that this study could reliably detect? \n\nSince the observed effect size from our inferential statistics was smallerlarger than the effect you could reliably detect with this design, the test was sufficiently poweredunderpowered to detect the observed effect.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npwr.f2.test(u = 3, v = 71029, sig.level = 0.05, power = 0.99)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n\n\nThe study was incredibly sensitive, where they would detect effects of \\(f^2 = .0004\\) with 99% power. Needless to say, this study was sufficiently powered.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#activity-10-the-write-up",
    "href": "11-multiple-regression.html#activity-10-the-write-up",
    "title": "11  Multiple regression",
    "section": "11.10 Activity 10: The write-up",
    "text": "11.10 Activity 10: The write-up\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted wellbeing \\((F(3, 71029) = 2451, p &lt; .001, R^2_{Adjusted} = .094, f^2 = 0.103)\\), accounting for 9.4% of the variance. Total screen time was a significant negative predictor of wellbeing scores \\((\\beta = -0.77, 95\\% CI = [-0.82, -0.73], p &lt; .001\\)), as was gender \\((\\beta = 5.14, p &lt; .001\\)), with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screen time and gender \\((\\beta = 0.45, 95\\% CI = [0.38, 0.52], p &lt; .001\\)), meaning that smartphone use was more negatively associated with well-being for girls than for boys. Therefore, we reject the null hypothesis in favour of H1, as smartphone use significantly predicted wellbeing and this relationship differed between boys and girls. The analysis was sufficiently powered to detect this effect.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "11-multiple-regression.html#test-your-knowledge",
    "href": "11-multiple-regression.html#test-your-knowledge",
    "title": "11  Multiple regression",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nWhat is the main purpose of a multiple regression analysis?\n\n To predict or explain changes in an outcome variable based on multiple predictor variables. To compare means between two groups and determine if they are significantly different. To determine whether there is an association between two variables, without assuming causality. To test whether one predictor variable explains the outcome variable while ignoring other potential influences.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nMultiple regression extends simple regression by including multiple predictors to explain variance in the outcome variable. This allows researchers to assess the unique contribution of each predictor while controlling for others.\n\nOne incorrect option describes correlation rather than regression.\nAnother option describes a t-test, which compares means rather than predicting an outcome.\nThe final incorrect option incorrectly implies that multiple regression ignores other predictors, when in fact it accounts for them.\n\n\n\n\n\n\nQuestion 2\nA researcher investigates whether a student’s exam performance can be predicted by their hours of study and test anxiety levels.\nWhich of the following correctly specifies the multiple regression model in R?\n\n lm(Test_Anxiety ~ Study_Hours + Exam_Score, data = student_data) lm(Exam_Score ~ Study_Hours + Test_Anxiety, data = student_data) lm(Study_Hours ~ Exam_Score + Test_Anxiety, data = student_data) lm(Exam_Score ~ Study_Hours * Test_Anxiety, data = student_data)\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIn multiple regression, the dependent variable (outcome) is placed first, followed by the predictor variables (independent variables) after the tilde (~). Since we are predicting exam scores, this must be the first variable in the formula.\n\nOne incorrect option includes an interaction term (*), which was not specified in the task. A basic multiple regression only includes main effects (+).\nAnother incorrect option swaps the predictor and outcome, which would lead to an incorrect model specification.\nThe last incorrect option incorrectly treats test anxiety as the outcome, when it is actually a predictor in the model.\n\n\n\n\n\n\nQuestion 3\nA multiple regression model is used to predict life satisfaction based on sleep quality and daily screen time. The output includes the following regression equation:\n\\(Life Satisfaction = 50.2 + 1.8 * Sleep Quality − 0.9 * ScreenTime\\)\nHow should the coefficient for Sleep Quality (1.8) be interpreted??\n\n For each one-unit increase in sleep quality, life satisfaction is expected to increase by 1.8, regardless of screen time. For each one-unit increase in sleep quality, life satisfaction is expected to increase by 1.8, holding screen time constant. A one-unit increase in sleep quality may lead to a decrease in life satisfaction, depending on screen time. A one-unit increase in sleep quality always leads to a 1.8-point increase in life satisfaction.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nIn multiple regression, the coefficient represents the expected change in the outcome variable (life satisfaction) for a one-unit increase in the predictor (sleep quality), holding all other predictors constant.\nWhy are the other options incorrect?\n\nOne option ignores the need to hold other predictors constant, which is a key feature of multiple regression.\nAnother option implies a deterministic relationship, incorrectly stating that the increase always occurs.\nThe final incorrect option incorrectly suggests that sleep quality could have a negative effect on life satisfaction, when the model shows a clear positive relationship.\n\n\n\n\n\n\nQuestion 4\nA multiple regression model predicts self-esteem based on social support and stress levels. The output includes an interaction term for social support and stress with a p-value of .007. What does this suggest?\n\n Social support directly improves self-esteem, so the interaction term is unnecessary. The relationship between stress and self-esteem depends on social support. The interaction term suggests that social support and stress are highly correlated and should be removed from the model. Social support and stress both influence self-esteem, but they do not interact.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nA significant interaction term \\((p = .007)\\) means that the effect of stress on self-esteem is different at different levels of social support.\nWhy are the other options incorrect?\n\nOne option ignores the interaction effect, treating the predictors as independent influences.\nAnother incorrectly assumes that social support’s direct effect makes the interaction term unnecessary, when in reality, interactions test whether one predictor alters another’s effect.\nThe last incorrect option confuses interaction effects with multicollinearity. High correlation between predictors does not automatically mean an interaction term should be removed.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Multiple regression</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html",
    "href": "12-one-way-anova.html",
    "title": "12  One-way ANOVA",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#intended-learning-outcomes",
    "href": "12-one-way-anova.html#intended-learning-outcomes",
    "title": "12  One-way ANOVA",
    "section": "",
    "text": "Apply and interpret a one-way ANOVA.\nBreak down the results of a one-way ANOVA using post-hocs tests and apply a correction for multiple comparisons.\nConduct a power analysis for a one-way ANOVA.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#individual-walkthrough",
    "href": "12-one-way-anova.html#individual-walkthrough",
    "title": "12  One-way ANOVA",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-1-setup-download-the-data",
    "href": "12-one-way-anova.html#activity-1-setup-download-the-data",
    "title": "12  One-way ANOVA",
    "section": "12.1 Activity 1: Setup & download the data",
    "text": "12.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset. Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2B_chapter12”, or “12_anova”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you need help.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the new dataset here: data_ch12.zip. The zip folder includes:\n\nthe data file for Experiment 2 (James_2015_Expt_2.csv), and the\nthe codebook for Experiment 2 (James Holmes Experiment 2 Data Code Book.doc).\n\nExtract the data file from the zip folder and place it in your project folder. If you need help, see Section 1.4.\n\nCitation\n\nJames, E. L., Bonsall, M. B., Hoppitt, L., Tunbridge, E. M., Geddes, J. R., Milton, A. L., & Holmes, E. A. (2015). Computer Game Play Reduces Intrusive Memories of Experimental Trauma via Reconsolidation-Update Mechanisms. Psychological Science, 26(8), 1201-1215. https://doi.org/10.1177/0956797615583071\n\nAbstract\n\nMemory of a traumatic event becomes consolidated within hours. Intrusive memories can then flash back repeatedly into the mind’s eye and cause distress. We investigated whether reconsolidation—the process during which memories become malleable when recalled—can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions. We predicted that reconsolidation of a reactivated visual memory of experimental trauma could be disrupted by engaging in a visuospatial task that would compete for visual working memory resources. We showed that intrusive memories were virtually abolished by playing the computer game Tetris following a memory-reactivation task 24 hr after initial exposure to experimental trauma. Furthermore, both memory reactivation and playing Tetris were required to reduce subsequent intrusions (Experiment 2), consistent with reconsolidation-update mechanisms. A simple, noninvasive cognitive-task procedure administered after emotional memory has already consolidated (i.e., &gt; 24 hours after exposure to experimental trauma) may prevent the recurrence of intrusive memories of those emotional events.\n\nThe data is available on OSF: https://osf.io/ij7ea/\nChanges made to the dataset\n\nThe original SPSS file was converted to CSV format. This time, we downloaded the numeric version of the data, allowing you to practice recoding values.\nMissing values were coded as 9999.000 in the original data file; however, we replaced them with NA.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "href": "12-one-way-anova.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "title": "12  One-way ANOVA",
    "section": "12.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data",
    "text": "12.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data\nToday, we will use several packages: effectsize, rstatix, tidyverse, qqplotr, car, emmeans, and pwr, and, of course, the dataset James_2015_Expt_2.csv. The order in which the packages are loaded matters today. I believe we have used all of these packages before, but if you need help installing them, see Section 1.5.1 for more details.\n\n???\n\ndata_james &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(effectsize)\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(qqplotr)\nlibrary(car)\nlibrary(emmeans)\nlibrary(pwr)\n\ndata_james &lt;- read_csv(\"James_2015_Expt_2.csv\")\n\n\n\n\nAs always, take a moment to familiarise yourself with the data before starting your analysis.\nOnce you have explored the data objects and the codebook, try answering the following questions:\n\nHow many conditions were included in the experiment? \nHow many participants were allocated to each condition? \nHow many of participants were allowed to play Tetris during the experiment? \nHow many visual analogue mood scales did participants complete before the experiment? \nName one of them:  (Hint: Match the spelling exactly.)\nName the column that stores the main outcome variable:  (Hint: You can find the information in the codebook.)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-3-preparing-the-dataframe",
    "href": "12-one-way-anova.html#activity-3-preparing-the-dataframe",
    "title": "12  One-way ANOVA",
    "section": "12.3 Activity 3: Preparing the dataframe",
    "text": "12.3 Activity 3: Preparing the dataframe\nLet’s start by wrangling the data we need for today’s analysis:\n\nConvert the Condition column into a factor and replace its values with descriptive labels.\nAdd a column called Participant_ID. This requires using a new function row_number() within mutate().\nRename Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to Intrusions.\nSelect only the columns Participant_ID, Condition, and Intrusions\nStore the cleaned dataset as james_data.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\njames_data &lt;- data_james %&gt;% \n  mutate(Participant_ID = row_number(),\n         Condition = factor(Condition,\n                            labels = c(\"No-Task Control\", \"Reactivation+Tetris\", \"Tetris Only\", \"Reactivation Only\"))) %&gt;% \n  select(Participant_ID, Condition, Intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary)",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-4-compute-descriptives",
    "href": "12-one-way-anova.html#activity-4-compute-descriptives",
    "title": "12  One-way ANOVA",
    "section": "12.4 Activity 4: Compute descriptives",
    "text": "12.4 Activity 4: Compute descriptives\nNow, we can calculate the means and standard deviations for each experimental group.\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nSummarise the data to display the mean and standard deviation of intrusive memories, grouped by Condition.\nYour table should contain three columns: Condition, mean, and sd.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe are simply computing the values again rather than storing them. However, if you prefer, you can save the output as an object in your Global Environment.\n\njames_data %&gt;%\n  group_by(Condition) %&gt;%\n  summarise(mean = mean(Intrusions), \n            sd = sd(Intrusions))\n\n\n\n\n\nCondition\nmean\nsd\n\n\n\n\nNo-Task Control\n5.111111\n4.227207\n\n\nReactivation+Tetris\n1.888889\n1.745208\n\n\nTetris Only\n3.888889\n2.887883\n\n\nReactivation Only\n4.833333\n3.329900",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-5-create-an-appropriate-plot",
    "href": "12-one-way-anova.html#activity-5-create-an-appropriate-plot",
    "title": "12  One-way ANOVA",
    "section": "12.5 Activity 5: Create an appropriate plot",
    "text": "12.5 Activity 5: Create an appropriate plot\nNow, let’s visualise the data. The original paper uses a bar plot, but we’ll create a more informative plot instead.\n\nGenerate a violin-boxplot with the number of intrusive memories on the y-axis and experimental group on the x-axis.\nRename the y-axis title to Number of Intrusions.\nFeel free to add any additional layers in your own time.\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHere is one possible solution. The axis title could also have been modified using the scale_y_continuous() function.\n\nggplot(james_data, aes(x = Condition, y = Intrusions))+\n  geom_violin()+\n  geom_boxplot(width = 0.2) +\n  labs(y = \"Number of Intrusions\")\n\n\n\n\n\n\n\n\nThis plot reveals a few potential outliers in each group. This information would be missing in a bar plot. This is why bar plots are not ideal for visualising this type of data.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-6-store-the-anova-model-and-check-assumptions",
    "href": "12-one-way-anova.html#activity-6-store-the-anova-model-and-check-assumptions",
    "title": "12  One-way ANOVA",
    "section": "12.6 Activity 6: Store the ANOVA model and check assumptions",
    "text": "12.6 Activity 6: Store the ANOVA model and check assumptions\n\n12.6.1 The ANOVA model\nBefore testing assumptions, we first need to store the ANOVA model.\nFor designs with equal group sizes, we could use the aov() function from the stats package, which is part of Base R. The formula for aov() is:\n\naov(DV ~ IV, data)\n\nHowever, there is a catch. aov only supports between-subjects designs. Additionally, it assumes balanced designs (i.e., equal sample sizes in each group; Type I sum of squares). It should not be used for unbalanced designs where group sizes differ.\nIn our current design, this is not a concern since we have equal sample sizes and no within-subject variable. However, you may encounter different designs in the future, so we recommend a more flexible approach.\nLast week, we saw that the lm() function can handle categorical variables. We can apply it here.\nThe structure of lm() is identical to aov():\n\nlm(DV ~ IV, data)\n\nLet’s use this approach with our variables and store the model in a separate object called mod:\n\nmod &lt;- lm(Intrusions ~ Condition, data = james_data)\n\n\n\n12.6.2 Assumption checks\nNow that we have stored the model, we can proceed with the assumption checks. For a one-way independent ANOVA, the assumptions are the same as those for an independent t-test.\n\nAssumption 1: Continuous DV\nThe dependent variable must be measured at interval or ratio level. We can confirm that by looking at Intrusions.\n\n\nAssumption 2: Data are independent\nThere should be no relationship between the observations. Scores in one condition or observation should not influence scores in another. We assume this assumption holds for our data.\n\n\nAssumption 3: The residuals of the DV should be normally distributed\nAgain, this assumption applies to each group.\nThere are several ways to test normality, and here we will use QQ plots from the qqplotr package.\n\nggplot(james_data, aes(sample = Intrusions, fill = Condition)) +\n  stat_qq_band(alpha = 0.5) +\n  stat_qq_line() +\n  stat_qq_point() +\n  facet_wrap(~Condition) +\n  theme_bw() +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nOverall, the assumption of normality appears to hold.\n\n\nAssumption 4: Homoscedasticity (homogeneity of variance)\nThis assumption requires the variances across the four groups to be similar (i.e., homoscedasticity). If the variances differ significantly between groups, this is known as heteroscedasticity.\nWe can test this using Levene’s Test for Equality of Variance, available in the car package. The leveneTest() function takes the formula DV ~ IV and the data object as arguments. Here’s how to apply it:\n\nleveneTest(Intrusions ~ Condition, data = james_data)\n\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n3\n1.692984\n0.1767091\n\n\n\n68\nNA\nNA\n\n\n\n\n\n\nThe test output shows a p-value greater than .05, indicating that we do not have enough evidence to reject the null hypothesis. Therefore, we can assume that the variances across the four groups are equal.\nIf reporting Levene’s Test in a report, you would need to follow APA style: A Levene’s test of homogeneity of variances was conducted to compare the variances across the groups. The test indicated that the variances were homogeneous, \\(F(3,67) = 1.69, p = .177\\).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-7-compute-a-one-way-anova",
    "href": "12-one-way-anova.html#activity-7-compute-a-one-way-anova",
    "title": "12  One-way ANOVA",
    "section": "12.7 Activity 7: Compute a one-way ANOVA",
    "text": "12.7 Activity 7: Compute a one-way ANOVA\nWe can compute the ANOVA output using the anova_test() function from the rstatix package. This function supports both model and formula input and allows additional arguments, such as specifying the type of ANOVA, calculating effect sizes, or manually defining within- or between-subject factors.\nMore information can be found on the rdocumentation support page\nIn this example, we will use anova_test() on the model mod. Since mod already contains the data and formula, we only need to specify a few additional arguments:\n\ntype specifies the type of sums of squares for ANOVA. The default is type = 2, which produces identical results to type = 1 when data are balanced, but type = 2 will additionally yield various assumption tests where appropriate.\neffect.size specifies the effect size. Here, we set it to “pes” (partial eta squared). Note that for one-way between-subjects designs, partial eta squared is equivalent to eta squared.\n\n\nanova_test(mod, type = 2, effect.size = \"pes\")\n\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\npes\n\n\n\n\nCondition\n3\n68\n3.795\n0.014\n*\n0.143\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nLet’s explore alternative ways to use the anova_test() function. As you will see, these approaches produce exactly the same output as the one above.\n\nOption 1: Formula approach without a pre-defined modelOption 2: Specifying arguments individually\n\n\nIf you prefer not to store the model separately, you can directly specify the formula and data within the anova_test() function:\n\nanova_test(data = james_data, \n           formula = Intrusions ~ Condition, \n           type = 2, \n           effect.size = \"pes\")\n\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\npes\n\n\n\n\nCondition\n3\n68\n3.795\n0.014\n*\n0.143\n\n\n\n\n\n\n\n\nIf the formula approach isn’t for you, you can specify the arguments individually.\n\nanova_test(data, dv, wid, between, type, effect.size)\n\n\ndata = The data object.\ndv = The dependent variable (DV; numeric).\nwid = The column name of the participant identifier (factor).\nbetween = The optional between-subjects factor variables.\ntype = The type of sums of squares for ANOVA.\neffect.size = The effect size to compute and to show in the ANOVA results.\n\n\nanova_test(data = james_data, \n           dv = Intrusions,\n           wid = Participant_ID, \n           between = Condition, \n           type = 2, \n           effect.size = \"pes\")\n\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\npes\n\n\n\n\nCondition\n3\n68\n3.795\n0.014\n*\n0.143\n\n\n\n\n\n\n\n\n\n\n\nThe output may be displayed slightly differently from what you saw in the lecture, but all the necessary numbers are there.\n\n\n\n\n\n\nYour Turn\n\n\n\nAnswer the following questions:\n\nIs the overall effect of Condition significant? YesNo\nWhat is the F-statistic rounded to 2 decimal places? \nAccording to the rules of thumb, the effect size is SmallMediumLarge\n\n\n\n\n\n\n\n\n\nWhat do I do if my One-way ANOVA uses a within-subject design???\n\n\n\nYou can still use the anova_test() function as shown in Option 2. However, instead of the between argument, you would use the within argument to specify the within-subjects factor. The rest of the arguments remain the same as in Option 2.\n\nanova_test(data, dv, wid, within, type, effect.size)\n\nObviously, we cannot run this for a within-subjects design, as today’s dataset follows a between-subjects design.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-8-compute-post-hoc-tests-and-effect-sizes",
    "href": "12-one-way-anova.html#activity-8-compute-post-hoc-tests-and-effect-sizes",
    "title": "12  One-way ANOVA",
    "section": "12.8 Activity 8: Compute post-hoc tests and effect sizes",
    "text": "12.8 Activity 8: Compute post-hoc tests and effect sizes\n\n12.8.1 Post-hoc comparisons\nSo far, we know that the model is significant, meaning there are differences between groups. However, we do not yet know which groups differ from one another.\nOne approach would be to run independent Welch t-tests for each pairwise comparison between the four groups (1 vs 2, 1 vs 3, 1 vs 4, etc.). This would involve some data wrangling (e.g., filtering and dropping factor levels) which is quite time-consuming. Furthermore, we would need to apply corrections for multiple comparisons manually. (Even though, note that the original authors did not mention whether or not they corrected for multiple comparisons.)\nA quicker and more efficient way to perform these comparisons is by using the emmeans() function from the emmeans package. This function computes all possible pairwise t-tests and automatically applies a correction for multiple comparisons to the p-values.\nIn this case, we will use the Bonferroni adjustment method.\n\nemmeans(mod, \n        pairwise ~ Condition, \n        adjust = \"bonferroni\")\n\n$emmeans\n Condition           emmean    SE df lower.CL upper.CL\n No-Task Control       5.11 0.749 68    3.617     6.60\n Reactivation+Tetris   1.89 0.749 68    0.395     3.38\n Tetris Only           3.89 0.749 68    2.395     5.38\n Reactivation Only     4.83 0.749 68    3.340     6.33\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                  estimate   SE df t.ratio p.value\n (No-Task Control) - (Reactivation+Tetris)    3.222 1.06 68   3.044  0.0199\n (No-Task Control) - Tetris Only              1.222 1.06 68   1.155  1.0000\n (No-Task Control) - Reactivation Only        0.278 1.06 68   0.262  1.0000\n (Reactivation+Tetris) - Tetris Only         -2.000 1.06 68  -1.889  0.3787\n (Reactivation+Tetris) - Reactivation Only   -2.944 1.06 68  -2.781  0.0420\n Tetris Only - Reactivation Only             -0.944 1.06 68  -0.892  1.0000\n\nP value adjustment: bonferroni method for 6 tests \n\n\nThe output consists of two tables:\n\nThe first one ($emmeans) displays the means, standard errors, degrees of freedom, and confidence intervals (referred to as Confidence Limits here).\nThe second ($contrasts) contains the pairwise comparisons between all groups. The estimate represents the difference between groups, t.ratio is the t-value, and p.value provides the Bonferroni-corrected p-value. Note that there are no asterisks indicating significance - you will need to compare the p-values against the .05 cutoff manually.\n\n\n\n12.8.2 Effect sizes for each comparison\nTo compute effect sizes, we can use the cohens_d function from the rstatix package.\n\ncohens_d(data = james_data, \n         formula = Intrusions ~ Condition)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n.y.\ngroup1\ngroup2\neffsize\nn1\nn2\nmagnitude\n\n\n\n\nIntrusions\nNo-Task Control\nReactivation+Tetris\n0.9964172\n18\n18\nlarge\n\n\nIntrusions\nNo-Task Control\nTetris Only\n0.3376282\n18\n18\nsmall\n\n\nIntrusions\nNo-Task Control\nReactivation Only\n0.0730015\n18\n18\nnegligible\n\n\nIntrusions\nReactivation+Tetris\nTetris Only\n-0.8382366\n18\n18\nlarge\n\n\nIntrusions\nReactivation+Tetris\nReactivation Only\n-1.1076078\n18\n18\nlarge\n\n\nIntrusions\nTetris Only\nReactivation Only\n-0.3030234\n18\n18\nsmall",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-9-sensitivity-power-analysis",
    "href": "12-one-way-anova.html#activity-9-sensitivity-power-analysis",
    "title": "12  One-way ANOVA",
    "section": "12.9 Activity 9: Sensitivity power analysis",
    "text": "12.9 Activity 9: Sensitivity power analysis\nAs always, we want to determine the smallest effect size that this study could detect, given its design and sample size.\nTo do this, we use the pwr.anova.test() function from the pwr package. The key arguments for this function are:\n\nk = The number of groups.\nn = The number of participants in each group.\nsig.level = The significance level of the study (usually set to 0.05).\npower = The power level of the study (usually set to 0.8).\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npwr.anova.test(k = 4, n = 18, sig.level = .05, power = 0.8)\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18\n              f = 0.4005038\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\n\n\n\nSince the power analysis computes Cohen’s f, but the model output provides partial eta squared, we need to convert the eta squared value into f to be able to compare the two. We can achieve this using the eta2_to_f() function from the effectsize package. The partial eta squared value from the model was 0.143.\n\neta2_to_f(0.143)\n\n[1] 0.4084864\n\n\nThe smallest effect size (Cohen’s \\(f\\)) that can be detected with four groups, 18 participants in each group, a significance level of 0.05, and 80% power was \\(f = .40\\). This was smaller than the effect size determined by the ANOVA (\\(\\eta_p^2 = 0.143; f = 0.41)\\). Therefore, the study was sufficiently powered.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#activity-10-the-write-up",
    "href": "12-one-way-anova.html#activity-10-the-write-up",
    "title": "12  One-way ANOVA",
    "section": "12.10 Activity 10: The write-up",
    "text": "12.10 Activity 10: The write-up\nA one-way between-subjects ANOVA was conducted on the 7-day diary post-intervention to examine the effect of cognitive task on overall intrusion scores. The analysis revealed a statistically significant effect, \\(F(3, 68) = 3.79, p = .014, \\eta_p^2 = 0.143\\).\nSince the ANOVA result was significant, post-hoc pairwise comparisons were conducted with Bonferroni corrections for multiple comparisons to identify which groups differed significantly.\nComparisons demonstrated that the reactivation-plus-Tetris group \\((M = 1.89, SD = 1.75)\\) experienced significantly fewer intrusive memories compared to the no-task control group \\((M = 5.11, SD = 4.23)\\), \\(t(68) = 3.04, p_{adj} = .020, d = 1.00\\). This effect is considered large.\nFurthermore, the reactivation-plus-Tetris group \\((M = 1.89, SD = 1.75)\\) experienced significantly fewer intrusive memories compared to the reactivation-only group \\((M = 4.83, SD = 3.33)\\), \\(t(68) = 2.78, p_{adj} = .042, d = 1.11\\). This effect is also considered large.\nThere were no significant differences between the no-task control group and the Tetris-only group \\((t(68) = 1.15, p_{adj} = 1, d = 0.34)\\), the no-task control group and the reactivation-only group \\((t(68) = 0.26, p_{adj} = 1, d = 0.07)\\), the reactivation-plus-Tetris group and the Tetris-only group \\((t(68) = 1.89, p_{adj} = .379, d = 0.84)\\), or the Tetris-only group and the reactivation-only group \\((t(68) = 0.89, p_{adj} = 1, d = 0.30)\\).",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "12-one-way-anova.html#test-your-knowledge",
    "href": "12-one-way-anova.html#test-your-knowledge",
    "title": "12  One-way ANOVA",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nWhy do we use a one-way ANOVA instead of multiple independent t-tests when comparing three or more groups?\n\n ANOVA is the only test that works when sample sizes are unequal. ANOVA does not require the dependent variable to be normally distributed. ANOVA reduces the risk of Type I errors caused by multiple comparisons. ANOVA can test for interactions between independent variables.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCorrect Answer:\nANOVA reduces the risk of Type I errors caused by multiple comparisons is correct because performing multiple comparisons increases the risk of Type I errors (false positives).\nIncorrect Answers:\n\n“ANOVA can test for interactions between independent variables” is incorrect because testing for interactions requires a factorial ANOVA, not a one-way ANOVA.\n“ANOVA is the only test that works when sample sizes are unequal” is incorrect because unequal sample sizes can be handled in both ANOVA and t-tests.\n“ANOVA does not require the dependent variable to be normally distributed” is incorrect because normality of the dependent variable is still an assumption for ANOVA.\n\n\n\n\n\n\nQuestion 2\nWhich assumption must be met for an ANOVA to be valid?\n\n The groups must have different sample sizes. The independent variable must be measured on an interval scale. Each group must have an equal mean before running ANOVA. The residuals of the dependent variable should be normally distributed in each group.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe correct answer: ANOVA assumes that the residuals of the dependent variable are normally distributed within each group to ensure valid results.\nThe other options are incorrect:\n\nThe independent variable in ANOVA is categorical, not interval or ratio.\nWhile equal sample sizes can be beneficial, ANOVA does not require them to be different (or equal for that matter).\nThe groups are not required to have equal means before running the ANOVA. ANOVA is used to test for mean differences.\nOne incorrect option includes an interaction term (*), which was not specified in the task. A basic multiple regression only includes main effects (+).\nAnother incorrect option swaps the predictor and outcome, which would lead to an incorrect model specification.\nThe last incorrect option incorrectly treats test anxiety as the outcome, when it is actually a predictor in the model.\n\n\n\n\n\n\nQuestion 3\nAfter finding a significant ANOVA result, which of the following statements about post-hoc tests is true?\n\n Post-hoc tests are unnecessary unless more than five groups are being compared. Post-hoc tests help identify which specific groups differ after a significant ANOVA result. Post-hoc tests should only be conducted if Levene’s test is significant. A significant ANOVA result automatically tells us which groups are different without further tests.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCorrect Answer:\nANOVA tells us that at least one group differs significantly from another, but post-hoc tests (e.g., Tukey, Bonferroni) are needed to determine which specific groups are different.\nWhy are the other options incorrect?\n\nPost-hoc tests are used after a significant ANOVA result, regardless of Levene’s test outcome.\nANOVA does not automatically tell us which groups differ. It only detects an overall effect. That’s why we have to run a post-hoc test.\nPost-hoc tests are necessary whenever there are more than two groups, not just when there are more than five.\n\n\n\n\n\n\nQuestion 4\nA researcher reports an effect size of ηₚ² = 0.02 after conducting a one-way ANOVA. How should this effect size be interpreted?\n\n Moderate effect Small effect Large effect Cannot determine without the F-ratio\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nAccording to Cohen’s guidelines, ηₚ² = 0.01 is small, ηₚ² = 0.06 is medium, and ηₚ² = 0.14 is large. Since 0.02 is closer to 0.01, it represents a small effect.\nThe effect size is independent of the F-ratio. You do not need the F-ratio to interpret ηₚ².",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>One-way ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html",
    "href": "13-factorial-anova.html",
    "title": "13  Factorial ANOVA",
    "section": "",
    "text": "Intended Learning Outcomes\nBy the end of this chapter you should be able to:",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#intended-learning-outcomes",
    "href": "13-factorial-anova.html#intended-learning-outcomes",
    "title": "13  Factorial ANOVA",
    "section": "",
    "text": "Apply and interpret a factorial ANOVA.\nBreak down the results of a factorial ANOVA using post hoc tests and apply a correction for multiple comparisons.\nCheck statistical assumptions for factorial ANOVA through your understanding of the design and diagnostic plots.\nVisualise the results of a factorial ANOVA through an interaction plot.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#individual-walkthrough",
    "href": "13-factorial-anova.html#individual-walkthrough",
    "title": "13  Factorial ANOVA",
    "section": "Individual Walkthrough",
    "text": "Individual Walkthrough",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-1-setup-download-the-data",
    "href": "13-factorial-anova.html#activity-1-setup-download-the-data",
    "title": "13  Factorial ANOVA",
    "section": "13.1 Activity 1: Setup & download the data",
    "text": "13.1 Activity 1: Setup & download the data\nThis week, we will be working with a new dataset - Experiment 3 in Zhang et al. (2014). Follow the steps below to set up your project:\n\nCreate a new project and name it something meaningful (e.g., “2B_chapter13”, or “13_anova”). See Section 1.2 if you need some guidance.\nCreate a new .Rmd file and save it to your project folder. See Section 1.3 if you need help.\nDelete everything after the setup code chunk (e.g., line 12 and below)\nDownload the new dataset here: data_ch13.zip. The zip folder includes:\n\nthe data file for Study 3 (Zhang_2014_Study3.csv)\nthe codebook for Study (Zhang_2014_Study3_codebook.xlsx), and the\na document explaining the Materials and Methods of Study 3 (Materials_and_methods_Study3.docx).\n\nExtract the data file from the zip folder and place it in your project folder. If you need help, see Section 1.4.\n\nCitation\n\nZhang, T., Kim, T., Brooks, A. W., Gino, F., & Norton, M. I. (2014). A “Present” for the Future: The Unexpected Value of Rediscovery. Psychological Science, 25(10), 1851-1860. https://doi.org/10.1177/0956797614542274\n\nAbstract\n\nAlthough documenting everyday activities may seem trivial, four studies reveal that creating records of the present generates unexpected benefits by allowing future rediscoveries. In Study 1, we used a time-capsule paradigm to show that individuals underestimate the extent to which rediscovering experiences from the past will be curiosity provoking and interesting in the future. In Studies 2 and 3, we found that people are particularly likely to underestimate the pleasure of rediscovering ordinary, mundane experiences, as opposed to extraordinary experiences. Finally, Study 4 demonstrates that underestimating the pleasure of rediscovery leads to time-inconsistent choices: Individuals forgo opportunities to document the present but then prefer rediscovering those moments in the future to engaging in an alternative fun activity. Underestimating the value of rediscovery is linked to people’s erroneous faith in their memory of everyday events. By documenting the present, people provide themselves with the opportunity to rediscover mundane moments that may otherwise have been forgotten.\n\nThe data is available on OSF: https://osf.io/t2wby/\nIn summary, the researchers were interested in whether people could accurately predict how interested they would be in revisiting past experiences. They referred to this as the “time capsule” effect, where individuals store photos or messages to remind themselves of past events in the future. The researchers predicted that participants in the ordinary condition would underestimate their future feelings (i.e., show a greater difference between time 1 and time 2 ratings) compared to those in the extraordinary condition.\nChanges made to the dataset\n\nThe original SPSS file was converted to CSV format. Columns are already tidied.\nNo other changes were made.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "href": "13-factorial-anova.html#activity-2-load-in-the-library-read-in-the-data-and-familiarise-yourself-with-the-data",
    "title": "13  Factorial ANOVA",
    "section": "13.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data",
    "text": "13.2 Activity 2: Load in the library, read in the data, and familiarise yourself with the data\nToday, we will use several packages: afex, tidyverse, performance, emmeans, and effectsize.\nWe also need to read in the dataset Zhang_2014_Study3.csv\n\n???\n\ndata_zhang &lt;- ???\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(afex)\nlibrary(tidyverse)\nlibrary(performance)\nlibrary(emmeans)\nlibrary(effectsize)\n\ndata_zhang &lt;- read_csv(\"Zhang_2014_Study3.csv\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-3-preparing-the-dataframe",
    "href": "13-factorial-anova.html#activity-3-preparing-the-dataframe",
    "title": "13  Factorial ANOVA",
    "section": "13.3 Activity 3: Preparing the dataframe",
    "text": "13.3 Activity 3: Preparing the dataframe\nThis is a 2 x 2 mixed factorial ANOVA, with one within-subjects factor (time: time 1 vs. time 2) and one between-subjects factor (type of event: ordinary vs. extraordinary).\nSo let’s start by wrangling the data we need for today’s analysis:\n\nOnly include participants who completed the questionnaire at both time point 1 and time point 2.\nAdd a column called Participant_ID. We did that last week.\nConvert the column Condition into a factor.\nSelect the following columns\n\nParticipant_ID\nGender\nAge\nCondition\nThe predicted interest composite score at time point 1 T1_Pred_Interest_Comp and relabel it as Time 1\nThe actual interest composite score at time point 2 T2_Interest_Comp and relabel it as Time 2\n\nStore the cleaned dataset as zhang_data.\n\nWe should also create a long format version zhang_long that stores the interest composite scores for time points 1 and 2 in a single column (see excerpt below). Obviously zhang_long should have data from all 130 participants, not just the first 3.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParticipant_ID\nGender\nAge\nCondition\nTime_Point\nInterest_Composite_Score\n\n\n\n\n1\nFemale\n22\nOrdinary\nTime 1\n3.25\n\n\n1\nFemale\n22\nOrdinary\nTime 2\n4.50\n\n\n2\nMale\n23\nOrdinary\nTime 1\n2.00\n\n\n2\nMale\n23\nOrdinary\nTime 2\n1.50\n\n\n3\nFemale\n26\nOrdinary\nTime 1\n5.00\n\n\n3\nFemale\n26\nOrdinary\nTime 2\n6.50\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nzhang_data &lt;- data_zhang %&gt;% \n  filter(T2_Finished == \"Yes\") %&gt;% \n  mutate(Participant_ID = row_number(),\n         Condition = factor(Condition)) %&gt;% \n  select(Participant_ID, Gender, Age, Condition, `Time 1` = T1_Pred_Interest_Comp, `Time 2` = T2_Interest_Comp)\n\nzhang_long &lt;- zhang_data %&gt;% \n  pivot_longer(cols = `Time 1`:`Time 2`,\n               names_to = \"Time_Point\",\n               values_to = \"Interest_Composite_Score\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-4-compute-descriptives",
    "href": "13-factorial-anova.html#activity-4-compute-descriptives",
    "title": "13  Factorial ANOVA",
    "section": "13.4 Activity 4: Compute descriptives",
    "text": "13.4 Activity 4: Compute descriptives\nNow, we can calculate the number of participants in each group, as well as means, and standard deviations for each level of IV, and for both IVs overall.\nBonus: round the numbers to 2 decimal places\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nYou cannot do this all in one go. One option is to compute all required variables for Time, Condition, and grouped by Time and Condition separately, and then combine all dataframes.\nThe final output should contain 8 observations and 5 variables.\nTo round the values, use the round() function by wrapping it around the mean() and sd() functions.\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## grouped output\ndescriptives &lt;- zhang_long %&gt;%\n  group_by(Condition, Time_Point) %&gt;%\n  summarise(n = n(),\n            mean = round(mean(Interest_Composite_Score), 2), \n            sd = round(sd(Interest_Composite_Score), 2)) %&gt;% \n  ungroup()\n\n`summarise()` has grouped output by 'Condition'. You can override using the\n`.groups` argument.\n\ndescriptives_T &lt;- zhang_long %&gt;%\n  group_by(Time_Point) %&gt;%\n  summarise(n = n(),\n            mean = round(mean(Interest_Composite_Score), 2), \n            sd = round(sd(Interest_Composite_Score), 2)) %&gt;% \n  ungroup() %&gt;% \n  mutate(Condition = \"all\")\n\ndescriptives_C &lt;- zhang_long %&gt;%\n  group_by(Condition) %&gt;%\n  summarise(n = n(),\n            mean = round(mean(Interest_Composite_Score), 2), \n            sd = round(sd(Interest_Composite_Score), 2)) %&gt;% \n  ungroup() %&gt;% \n  mutate(Time_Point = \"all\")\n\ndescriptives &lt;- descriptives %&gt;% \n  full_join(descriptives_T) %&gt;% \n  full_join(descriptives_C)\n\nJoining with `by = join_by(Condition, Time_Point, n, mean, sd)`\nJoining with `by = join_by(Condition, Time_Point, n, mean, sd)`",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-5-create-an-appropriate-plot",
    "href": "13-factorial-anova.html#activity-5-create-an-appropriate-plot",
    "title": "13  Factorial ANOVA",
    "section": "13.5 Activity 5: Create an appropriate plot",
    "text": "13.5 Activity 5: Create an appropriate plot\nTry to recreate the following violin-boxplot. See how many features you can replicate before checking the code. The colour palette might be a bit tricky, but the rest should be fairly straightforward.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHint for the colour palette\n\n\n\n\n\nThe colour palette used here is one we haven’t explored yet. It’s called rainbow() and is a built-in palette in BaseR. To apply it, you can define it as the values argument within the scale_fill_manual() function.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(zhang_long, aes(x = Condition, y = Interest_Composite_Score, fill = Condition)) +\n  geom_violin(alpha = 0.4) + \n  geom_boxplot(width = 0.5, alpha = 0.8) +\n  facet_wrap(~ Time_Point) +\n  theme_classic() +\n  scale_fill_manual(values=rainbow(2),\n                    guide = \"none\") +\n  labs(y = \"Interest Composite Score\")",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-6-store-the-anova-model-and-check-assumptions",
    "href": "13-factorial-anova.html#activity-6-store-the-anova-model-and-check-assumptions",
    "title": "13  Factorial ANOVA",
    "section": "13.6 Activity 6: Store the ANOVA model and check assumptions",
    "text": "13.6 Activity 6: Store the ANOVA model and check assumptions\n\n13.6.1 The ANOVA model\nThis week, we will use the aov_ez() function from the afex package to run our analysis and save the model. The arguments are very similar to the anova_test() function we used last week, so the switch should feel familiar. However, while anova_test() does run the anova, somehow it doesn’t store the full model object properly when defining the arguments manually. As that makes it difficult to run post-hoc tests or check assumptions, we are switching to aov_ez() to give ourselves more flexibility for assumption checks and follow-up analyses.\nThe aov_ez() function requires the following arguments:\n\naov_ez(id = \"NULL\",\n       data = NULL, \n       between = \"NULL\", \n       within = \"NULL\",\n       dv = \"NULL\", \n       type = 3,\n       anova_table = list(es = \"NULL\"))  \n\n\nid = The column name of the participant identifier (factor).\ndata = The data object.\nbetween = The between-subjects factor variable(s).\nwithin = The within-subjects factor variable(s).\ndv = The dependent variable (DV; numeric).\ntype = The type of sums of squares for ANOVA (here we need Type 3).\nanova_table = list(es = \"NULL\") specifies the effect size to compute (here we set “NULL” to “pes” for partial eta squared).\n\nNow define the parameters for your analysis based on our current dataset. Check the solution when you’re done. Store the model in an object called mod.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nmod &lt;- aov_ez(id = \"Participant_ID\",\n       data = zhang_long, \n       between = \"Condition\", \n       within = \"Time_Point\",\n       dv = \"Interest_Composite_Score\", \n       type = 3,\n       anova_table = list(es = \"pes\"))\n\nContrasts set to contr.sum for the following variables: Condition\n\n\n\n\n\n\n\n13.6.2 Assumption checks\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nAssumption 1: Continuous DV\nThe dependent variable (DV) must be measured at the interval or ratio level. In our case, this assumption is met.\n\n\n\n\n\n\nDeep Dive: Ordinal data\n\n\n\nOrdinal data are commonly found in psychology, especially in the form of Likert scales. The challenge is that ordinal data are not interval or ratio data. They consist of a fixed set of ordered categories (e.g., the points on a Likert scale), but we can’t assume the distances between those points are equal. For example, is the difference between strongly agree and agree really the same as the difference between agree and neutral?\nTechnically, we shouldn’t use ANOVA to analyse ordinal data. But in practice, almost everyone does. A common justification is that when you average multiple Likert-scale items, the resulting composite score can be treated as interval data and may approximate a normal distribution.\nOthers argue that non-parametric tests or more advanced models like ordinal regression are more appropriate for ordinal data. However, this is beyond the scope of what we cover in this course.\nWhichever approach you choose, the key is to understand the data you have and be able to justify your analytical decision.\n\n\n\n\nAssumption 2: Data are independent\nThis assumption holds due to the study design; each participant provided responses independently.\n\n\nAssumption 3: Normality\nThe residuals of the DV should be normally distributed.\nThis assumption can be checked using the check_model() function from the performance package.\n\ncheck_model(mod)\n\n\n\n\n\n\n\n\nAs we can see here, the assumption is met. The residuals are approximately normally distributed. In both normality plots displayed, you can see they fall close to the horizontal reference line, and the density plot shows a roughly bell-shaped distribution.\n\n\nAssumption 4: Homoscedasticity\nThe variances across groups should be approximately equal.\nWe can test this using the check_homogeneity() function from the performance package. Simply run it on your model object mod. This function uses Levene’s Test to assess whether the variances across all four groups (i.e., the cells of our 2 × 2 design) are roughly equal:\n\ncheck_homogeneity(mod, method = \"levene\")\n\nOK: There is not clear evidence for different variances across groups (Levene's Test, p = 0.893).\n\n\nYou can also visualise the results:\n\nplot(check_homogeneity(mod, method = \"levene\"))\n\n\n\n\n\n\n\n\nIn this case, the non-significant p-value suggests that the variances across the four groups are roughly equal. The assumption is therefore met. This is also evident from the plot, which shows relatively similar spread across groups.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-7-compute-a-mixed-factorial-anova",
    "href": "13-factorial-anova.html#activity-7-compute-a-mixed-factorial-anova",
    "title": "13  Factorial ANOVA",
    "section": "13.7 Activity 7: Compute a mixed factorial ANOVA",
    "text": "13.7 Activity 7: Compute a mixed factorial ANOVA\nSince we already stored the model above, all that’s left is to run the output. To view the ANOVA results, simply call the model object:\n\nmod\n\nAnova Table (Type 3 tests)\n\nResponse: Interest_Composite_Score\n                Effect     df  MSE         F  pes p.value\n1            Condition 1, 128 2.05      0.46 .004    .498\n2           Time_Point 1, 128 0.61 25.88 *** .168   &lt;.001\n3 Condition:Time_Point 1, 128 0.61    4.44 * .034    .037\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\n\nLook at the results, and answer the following questions:\n\nIs the main effect of Condition significant? YesNo\nIs the main effect of Time significant? YesNo\nIs the two-way interaction significant? YesNo",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-8-compute-post-hoc-tests-an-interaction-plot-and-effect-sizes",
    "href": "13-factorial-anova.html#activity-8-compute-post-hoc-tests-an-interaction-plot-and-effect-sizes",
    "title": "13  Factorial ANOVA",
    "section": "13.8 Activity 8: Compute post-hoc tests, an interaction plot, and effect sizes",
    "text": "13.8 Activity 8: Compute post-hoc tests, an interaction plot, and effect sizes\n\n13.8.1 Post-hoc comparisons\n\n13.8.1.1 Main effect of Time Point\nWe do not need to run emmeans() for a post hoc comparison, because Time_Point only has 2 levels.\nHowever, seeing that Zhang et al. report Confidence Intervals in their final write-up and we didn’t calculate them earlier, we could use emmeans() to achieve that quickly.\n\nemmeans(mod, ~ Time_Point)\n\n Time_Point emmean     SE  df lower.CL upper.CL\n Time.1       4.20 0.0977 128     4.01     4.39\n Time.2       4.69 0.1040 128     4.49     4.90\n\nResults are averaged over the levels of: Condition \nConfidence level used: 0.95 \n\n\n\n\n13.8.1.2 Interaction of Time Point and Condition\nBecause the interaction is significant, we should follow up with post hoc tests using the emmeans() function to determine which specific group comparisons are driving the effect. If the interaction is not significant, there is no justification for conducting these post hoc tests.\nThe emmeans() function requires you to specify the model object, and then the factors you want to contrast, here our interaction term (Time_Point*Condition).\n\nemmeans(mod, ~ Time_Point*Condition)\n\n Time_Point Condition     emmean    SE  df lower.CL upper.CL\n Time.1     Extraordinary   4.36 0.137 128     4.09     4.63\n Time.2     Extraordinary   4.65 0.147 128     4.36     4.94\n Time.1     Ordinary        4.04 0.139 128     3.76     4.31\n Time.2     Ordinary        4.73 0.149 128     4.44     5.03\n\nConfidence level used: 0.95 \n\n\nThis gives us the estimated marginal means for each combination of the two independent variables. As you can see, these values match the descriptives we computed earlier. However, we still need to compute the contrasts to determine which comparisons are statistically significant.\nWe can use the contrast() function, piped onto the output of emmeans() do get the constrast comparisons. Here’s how it works:\n\ninteraction = \"pairwise\" specifies that we want to test pairwise contrasts within the interaction, i.e., comparisons at each level of the other variable.\nsimple = \"each\" tells R to test each factor separately across the levels of the other factor. If we leave this out, it will test the difference between time points and event types as a single contrast, which isn’t meaningful in this context.\ncombine = FALSE ensures that p-value adjustments are applied separately at each level of the other variable. If set to TRUE, all comparisons would be pooled and corrected together. You might choose combine = FALSE when you’re interested in simple effects (e.g., differences within each condition separately), and combine = TRUE when you’re making a larger number of comparisons across the full interaction and want a more conservative correction.\nadjust = \"bonferroni\" specifies the method for correcting multiple comparisons. However, in a 2 × 2 design, if combine = FALSE, there is only one comparison per level of the other factor. So no correction is actually applied, as there’s nothing to adjust for.\n\n\nemmeans(mod, ~ Time_Point*Condition) %&gt;% \n  contrast(interaction = \"pairwise\", \n           simple = \"each\", \n           combine = FALSE, \n           adjust = \"bonferroni\")\n\n$`simple contrasts for Time_Point`\nCondition = Extraordinary:\n Time_Point_pairwise estimate    SE  df t.ratio p.value\n Time.1 - Time.2       -0.288 0.136 128  -2.123  0.0357\n\nCondition = Ordinary:\n Time_Point_pairwise estimate    SE  df t.ratio p.value\n Time.1 - Time.2       -0.695 0.138 128  -5.049  &lt;.0001\n\n\n$`simple contrasts for Condition`\nTime_Point = Time.1:\n Condition_pairwise       estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary   0.3246 0.195 128   1.661  0.0992\n\nTime_Point = Time.2:\n Condition_pairwise       estimate    SE  df t.ratio p.value\n Extraordinary - Ordinary  -0.0829 0.209 128  -0.397  0.6923\n\n\n\n\n\n13.8.2 Creating an interaction plot\nWhen you have a factorial design, one powerful way of visualising the data is through an interaction plot. This is essentially a line graph where the x-axis has one IV and separate lines for a second IV. However, once you have the factorial ANOVA model, you can add confidence intervals to the plot to visualise uncertainty. The afex package has its own function called afex_plot() which you can use with the model object you created.\nIn the code below, there are a few key argument to highlight:\n\nobject is the model you created.\nx is the variable you want on the x-axis.\ntrace is the variable you want to plot as separate lines.\nerror controls whether the error bars show confidence intervals for between-subjects or within-subjects. In a mixed design, these have different properties, so you must think about which you want to plot and highlight to the reader.\nfactor_levels lets you edit the levels of factors you plot, such as renaming or reordering them.\n\nPlus, afex_plot() uses ggplot2 in the background, so you can add layers to the initial function land use ggsave() if you wanted to save your plot\n\nafex_plot(object = mod, \n          x = \"Condition\", \n          trace = \"Time_Point\", \n          error = \"between\",\n          factor_levels = list(Time_Point = c(\"Time 1\", \"Time 2\"))) + \n  theme_classic() + \n  scale_y_continuous(breaks = 1:7)\n\nRenaming/reordering factor levels of 'Time_Point':\n  Time.1 -&gt; Time 1\n  Time.2 -&gt; Time 2\n\n\nWarning: Panel(s) show a mixed within-between-design.\nError bars do not allow comparisons across all means.\nSuppress error bars with: error = \"none\"\n\n\n\n\n\n\n\n\n\n\n\n13.8.3 Effect sizes for each comparison\nTo calculate standardised effect sizes for the pairwise comparisons, we again need to do this individually using the cohens_d() function from the effectsize package. Here is where zhang_data is becoming useful.\nAs we have a mixed design, we must follow a slightly different process for each comparison. Cohen’s d has a different calculation for between-subjects and within-subjects contrasts, so we must express it differently.\nFor the first comparison, we are interested in the difference between time 1 and time 2 for each group, so this represents a within-subjects comparison.\n\n# time 1 vs time 2 for Extraordinary group\ncohens_d(x = \"Time 1\", \n         y = \"Time 2\", \n         paired = TRUE,\n         data = filter(zhang_data, \n                       Condition == \"Extraordinary\"))\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n-0.3086922\n0.95\n-0.554559\n-0.0605597\n\n\n\n\n\n\n\n# time 1 vs time 2 for Ordinary group\ncohens_d(x = \"Time 1\", \n         y = \"Time 2\", \n         paired = TRUE,\n         data = filter(zhang_data,\n                       Condition == \"Ordinary\"))\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n-0.5552045\n0.95\n-0.816696\n-0.2898832\n\n\n\n\n\n\nFor the second comparison, we are interested in the difference between ordinary and extraordinary at each time point, so this represents a between-subjects comparison.\n\n# Extraordinary vs ordinary at time 1\ncohens_d(`Time 1` ~ Condition,\n         data = zhang_data)\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n0.2914024\n0.95\n-0.0548458\n0.6365251\n\n\n\n\n\n\n\n# Extraordinary vs ordinary at time 2\ncohens_d(`Time 2` ~ Condition,\n         data = zhang_data)\n\n\n\n\n\nCohens_d\nCI\nCI_low\nCI_high\n\n\n\n\n-0.0695901\n0.95\n-0.413401\n0.2744922",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#activity-9-the-write-up",
    "href": "13-factorial-anova.html#activity-9-the-write-up",
    "title": "13  Factorial ANOVA",
    "section": "13.9 Activity 9: The write-up",
    "text": "13.9 Activity 9: The write-up\nWe can now replicate the write-up paragraph from the paper. However, note we report t-test for the post hoc comparison (tbh, I have no clue why Zhang et al. decided on ANOVAs reporting when there is only 2 levels to compare):\nWe conducted the same repeated measures ANOVA with interest as the dependent measure and again found a main effect of time, \\(F(1, 128) = 25.88, p &lt; .001, η_p^2 = 0.168\\); anticipated interest at Time 1 \\((M = 4.20, SD = 1.12, 95\\% CI = [4.01, 4.39])\\) was lower than actual interest at Time 2 \\((M = 4.69, SD = 1.19, 95\\% CI = [4.49, 4.90])\\).\nWe also observed an interaction between time and type of experience, \\(F(1, 128) = 4.45, p = .037, η_p^2 = 0.034\\). Pairwise comparisons revealed that for ordinary events, predicted interest at Time 1 \\((M = 4.04, SD = 1.09, 95\\% CI = [3.76, 4.31])\\) was lower than experienced interest at Time 2 \\((M = 4.73, SD = 1.24, 95\\% CI = [4.44, 5.03])\\), \\(t(128) = -5.05, p &lt; .001, d = -0.56\\). Although predicted interest for extraordinary events at Time 1 \\((M = 4.36, SD = 1.13, 95\\% CI = [4.09, 4.63])\\) was lower than experienced interest at Time 2 \\((M = 4.65, SD = 1.14, 95\\% CI = [4.36, 4.94])\\), \\(t(128) = -2.12, p = .036, d = -0.31\\), the magnitude of underestimation was smaller than for ordinary events.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "13-factorial-anova.html#test-your-knowledge",
    "href": "13-factorial-anova.html#test-your-knowledge",
    "title": "13  Factorial ANOVA",
    "section": "Test your knowledge",
    "text": "Test your knowledge\n\nQuestion 1\nA researcher wants to compare memory test scores across three different age groups (young adults, middle-aged adults, and older adults). What type of ANOVA should they use?\n\n One-way repeated-measures ANOVA Mixed factorial ANOVA Factorial ANOVA One-way between-subjects ANOVA\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCorrect Answer:\nA one-way between-subjects ANOVA is appropriate because there is one independent variable (age group) with three levels, and each participant is only tested in one group.\nIncorrect Answers:\n\nA One-way repeated-measures ANOVA is incorrect because it is used when the same participants are measured multiple times. Here, participants can only be allocated to one group.\nA Factorial ANOVA is incorrect because it is used when there are two or more independent variables.\nA mixed factorial ANOVA is incorrect because it is used when there is at least one between-subjects factor and one within-subjects factor.\n\n\n\n\n\n\nQuestion 2\nA researcher investigates how type of social media use (Passive, Active–Personal, Active–Public) and time of day (Morning vs Evening) affect self-esteem. They run a 3 × 2 mixed factorial ANOVA and follow up a significant interaction using emmeans() with pairwise comparisons at each level of the other variable.\nBelow is a partial output of the post hoc tests:\nContrasts of Time_Point at each Condition\n# emmeans(mod, ~ Time_Point * Condition) %&gt;%\n#   contrast(interaction = \"pairwise\", simple = \"each\", combine = FALSE)\n\n\n# === Passive Users ===\ncontrast               estimate   SE    df  t.ratio   p.value\nMorning - Evening        2.00    0.31   48   -6.45     &lt;.001\n\n# === Active–Personal Users ===\ncontrast               estimate   SE    df  t.ratio   p.value\nMorning - Evening       -2.50    0.32   48   -7.81     &lt;.001\n\n# === Active–Public Users ===\ncontrast               estimate   SE    df  t.ratio   p.value\nMorning - Evening       -1.00    0.31   48   -3.23     0.005\nWhich of the following statements best reflects these findings?\n\n Self-esteem increased over the day in all three groups. Passive users showed a drop in self-esteem across the day, while both active user groups showed increases. You cannot see the directionality of the comparison from the output, only that there is a significant difference. Only Active users show significant changes in self-esteem over time.\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCorrect Answer: Passive users showed a drop in self-esteem across the day, while both active user groups showed increases.\nThe contrast is Morning - Evening, so a positive estimate means Morning scores were higher than Evening scores (i.e., a drop across the day). Passive users show a positive value (2.00), while both Active-Personal (−2.50) and Active-Public (−1.00) show negative values, indicating higher self-esteem in the evening (i.e., an increase across the day).\nIncorrect Answers:\n\nSelf-esteem increased over the day in all three groups.: Only the active user groups showed an increase (negative estimates = Evening &gt; Morning). Passive users actually showed a decrease in self-esteem (positive estimate = Morning &gt; Evening).\nOnly Active users show significant changes in self-esteem over time.: All three groups show statistically significant changes (p &lt; .05), including Passive users. The difference lies in the direction of change—not whether a change occurred.\nYou cannot see the directionality of the comparison from the output, only that there is a significant difference.: The direction is clearly shown by the estimate: positive means higher in the Morning, negative means higher in the Evening. This output lets you interpret both the presence and direction of the effect.\n\n\n\n\n\n\nQuestion 3\nWhich of the following is the most appropriate method for checking whether the residuals in a mixed factorial ANOVA are normally distributed?\n\n Use Levene’s Test to compare variance across groups Check whether the independent variable is normally distributed in each condition Visually inspect the spread of data points using a bar chart Generate a Q–Q plot of residuals\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCorrect Answer:\nGenerate a Q–Q plot of residuals is correct because this visual tool helps assess whether the residuals follow a normal distribution.\nIncorrect Answers:\n\nUse Levene’s Test to compare variance across groups is incorrect as this checks for homogeneity of variance, not normality.\nCheck whether the independent variable is normally distributed in each condition is incorrect because ANOVA assumes that the residuals of the dependent variable, not the independent variable, are normally distributed. The IV is usually categorical and doesn’t require normality.\nVisually inspect the spread of data points using a bar chart is incorrect since bar charts show averages, not the distribution of residuals.\n\n\n\n\n\n\nQuestion 4\nYou run a 3 × 4 mixed factorial ANOVA and find a significant interaction. What is the most appropriate next step?\n\n Conduct post hoc comparisons to explore simple effects Rerun the analysis using a one-way ANOVA for each group Ignore the interaction since it complicates the interpretation Interpret only the main effects of each factor\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nCorrect Answer:\nConduct post hoc comparisons to explore simple effects is correct because a significant interaction suggests that the effect of one factor depends on the level of the other. To fully understand this, you need to explore the simple effects, i.e., how one variable behaves at each level of the other.\nIncorrect Answers:\n\nInterpret only the main effects of each factor is incorrect because a significant interaction indicates that the effect of one factor depends on the level of the other. Interpreting main effects alone would be misleading.\nRerun the analysis using a one-way ANOVA for each group is incorrect as this would ignore the factorial structure and inflate the risk of Type I error. The proper approach is to follow up the interaction with simple effects comparisons, not separate one-way ANOVAs.\nIgnore the interaction since it complicates the interpretation is incorrect because the interaction is a meaningful result. Ignoring it would overlook important patterns in the data and lead to an incomplete or inaccurate interpretation.",
    "crumbs": [
      "INDIVIDUAL WALKTHROUGH CHAPTERS",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Factorial ANOVA</span>"
    ]
  },
  {
    "objectID": "pc-A01.html",
    "href": "pc-A01.html",
    "title": "2A Lab 1 Week 2",
    "section": "",
    "text": "Now, let’s get started!!!",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-A01.html#task-1-create-a-project-folder-for-the-lab-activities",
    "href": "pc-A01.html#task-1-create-a-project-folder-for-the-lab-activities",
    "title": "2A Lab 1 Week 2",
    "section": "Task 1: Create a project folder for the lab activities",
    "text": "Task 1: Create a project folder for the lab activities\nSince we will be working with the same data throughout semester 1, create a separate project for the lab data. Name it something useful, like lab_data or dogs_in_the_lab. Make sure you are not placing it within the project you have already created today. If you need guidance, see 1.2 Activity 1: Creating a new project.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-A01.html#task-2-create-a-new-.rmd-file",
    "href": "pc-A01.html#task-2-create-a-new-.rmd-file",
    "title": "2A Lab 1 Week 2",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-A01.html#task-3-download-the-data",
    "href": "pc-A01.html#task-3-download-the-data",
    "title": "2A Lab 1 Week 2",
    "section": "Task 3: Download the data",
    "text": "Task 3: Download the data\nDownload the data here: data_pair_coding. The zip folder contains the raw data file with responses to individual questions, a cleaned version of the same data in long format and wide format, and the codebook describing the variables in the raw data file and the long format.\nUnzip the folder and place the data files in the same folder as your project.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-A01.html#task-4-familiarise-yourself-with-the-data",
    "href": "pc-A01.html#task-4-familiarise-yourself-with-the-data",
    "title": "2A Lab 1 Week 2",
    "section": "Task 4: Familiarise yourself with the data",
    "text": "Task 4: Familiarise yourself with the data\nOpen the data files, look at the codebook, and perhaps skim over the original Binfet article (methods in particular) to see what kind of measures they used.\nRead in the raw data file as dog_data_raw and the cleaned-up data (long format) as dog_data_long. See if you can answer the following questions.\n\nlibrary(tidyverse)\n\ndog_data_raw &lt;- read_csv(\"dog_data_raw.csv\")\ndog_data_long &lt;- read_csv(\"dog_data_clean_long.csv\")\n\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nRows: 284 Columns: 136\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (41): GroupAssignment, L2_1, L2_2, L2_3, L2_4, L2_5, L2_6, L2_7, L2_8, L...\ndbl (95): RID, Age_Yrs, Year_of_Study, Live_Pets, Consumer_BARK, S1_1, HO1_1...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 568 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): GroupAssignment, Year_of_Study, Live_Pets, Stage\ndbl (12): RID, Age_Yrs, Consumer_BARK, Flourishing, PANAS_PA, PANAS_NA, SHS,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-A01.html#task-5-question-time",
    "href": "pc-A01.html#task-5-question-time",
    "title": "2A Lab 1 Week 2",
    "section": "Task 5: Question Time",
    "text": "Task 5: Question Time\nNow that you have familiarised yourself with the data, you can answer the following questions.\n\nQuestion 1\nHow many participants took part in the study? \n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nYou can see this from dog_data_raw. Each participant ID is on a single row meaning the number of observations is the number of participants.\nIf you look at dog_data_long, there are 568 observations. Each participant answered the questionnaires pre and post intervention, resulting in 2 rows per participant ID. This means you’d have to divide the number of observations by 2 to get to the number of participants.\n\n\n\n\n\nQuestion 2\nHow many different questionnaires did the participants answer? \n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe Binfet paper (e.g., Methods section and/or abstract), the codebook, and dog_data_long show it’s 9 questionnaires - Flourishing scale (variable Flourishing), the UCLS Loneliness scale Version 3 (Loneliness), Positive and Negative affect scale (PANAS_PA and PANAS_NA), the Subjective Happiness scale (SHS), the Social connectedness scale (SCS), and 3 scales with 1 question each, i.e., perception of stress levels (Stress), self-reported level of homesickness (Homesick), and integration into the campus community (Engagement).\nHowever, if you thought PANAS_PA and PANAS_NA are a single questionnaire, 8 was also acceptable as an answer here.\n\n\n\n\n\nQuestion 3\ndog_data_raw has  character columns and  that are labeled as double.\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nYou can get information on column specification when reading in the data.\n\n\n\nmessage from read_csv() when reading in the data\n\n\n\n\n\n\n\nQuestion 4\nSelect from the dropdown menu the variable type and their data types for each of the columns.\nIn dog_data_raw:\n\n\n\n\n\n\n\n\nColumn\nVariable type\nData type\n\n\n\n\nRID\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nGroupAssignment\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nAge_Yrs\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nYear_of_Study\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nPN1_1\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nL2_1\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nSC2_1\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\n\nIn dog_data_long:\n\n\n\n\n\n\n\n\nColumn\nVariable type\nData type\n\n\n\n\nYear_of_Study\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nStage\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nLoneliness\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\nSCS\ncontinuousnominalordinal\nnumericcharacterlogicalfactor\n\n\n\n\n\n\n\n\n\nExplain this answer\n\n\n\n\n\nThe column SC2_1 contains both numbers and words. Because R can store numbers as characters but cannot store words as numbers, the whole column is coded as chr.\nMost of the questionnaire items were answered on a Likert scale (e.g., strongly disagree to strongly agree, or never, rarely, sometimes, often). These are ordinal variables because the categories (whether shown as words or numbers) represent an order but not equal distances (see dog_data_raw). However, when you add up or average several items to calculate an overall questionnaire score (like Loneliness or SCS in dog_data_long), that score can be treated as continuous data.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-A02.html",
    "href": "pc-A02.html",
    "title": "2A Lab 2 Week 3",
    "section": "",
    "text": "Task 1: Open the R project you created last week\nIf you haven’t created an R project for the lab yet, please do so now. If you already have one set up, go ahead and open it.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-A02.html#task-2-open-your-.rmd-file-from-last-week",
    "href": "pc-A02.html#task-2-open-your-.rmd-file-from-last-week",
    "title": "2A Lab 2 Week 3",
    "section": "Task 2: Open your .Rmd file from last week",
    "text": "Task 2: Open your .Rmd file from last week\nSince we haven’t used it much yet, feel free to continue using the .Rmd file you created last week in Task 2.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-A02.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-A02.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2A Lab 2 Week 3",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should be in your project folder. If you didn’t download it last week, or if you’d like a fresh copy, you can download the data again here: data_pair_coding.\nWe will be using the tidyverse package today, and the data file we need to read in is dog_data_raw.csv.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n# loading tidyverse into the library\nlibrary(???)\n\n# reading in `dog_data_raw.csv`\ndog_data_raw &lt;- read_csv(\"???\")",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-A02.html#task-4-calculating-the-mean-for-flourishing_pre",
    "href": "pc-A02.html#task-4-calculating-the-mean-for-flourishing_pre",
    "title": "2A Lab 2 Week 3",
    "section": "Task 4: Calculating the mean for Flourishing_pre",
    "text": "Task 4: Calculating the mean for Flourishing_pre\n\nStep 1: Select all relevant columns from dog_data_raw, including participant ID and all items from the Flourishing questionnaire completed before the intervention. Store this data in an object called data_flourishing.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nLook at the codebook. Try to determine:\n\nThe variable name of the column where the participant ID is stored.\nThe items related to the Flourishing scale at the pre-intervention stage.\n\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\nFrom the codebook, we know that:\n\nThe participant ID column is called RID.\nThe Flourishing items at the pre-intervention stage start with F1_.\n\n\ndata_flourishing &lt;- ??? %&gt;% \n  select(???, F1_???:F1_???)\n\n\n\n\n\n\n\n\nStep 2: Pivot the data from wide format to long format so we can calculate the average score more easily (in step 3).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhich pivot function should you use? We have pivot_wider() and pivot_longer() to choose from.\nWe also need 3 arguments in that function:\n\nThe columns you want to select (e.g., all the Flourishing items),\nThe name of the column where the current column headings will be stored (e.g., “Questionnaire”),\nThe name of the column that should store all the values (e.g., “Responses”).\n\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\nWe need pivot_longer(). You already encountered pivot_longer() in first year (or in the individual walkthrough if you have already completed this Chapter). The 3 arguments was also a give-away; pivot_wider() only requires 2 arguments.\n\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\")\n\n\n\n\n\n\n\n\nStep 3: Calculate the average Flourishing score per participant and name this column Flourishing_pre to match the table above.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nBefore summarising the mean, you may need to group the data.\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\nTo compute an average score per participant, we would need to group by participant ID first.\n\n  group_by(???) %&gt;% \n  summarise(Flourishing_pre = mean(???)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# loading tidyverse into the library\nlibrary(tidyverse)\n\n# reading in `dog_data_raw.csv`\ndog_data_raw &lt;- read_csv(\"dog_data_raw.csv\")\n\n# Task 4: Tidying \ndata_flourishing &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, F1_1:F1_8) %&gt;% \n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Questionnaire\", values_to = \"Responses\") %&gt;% \n  # Step 3\n  group_by(RID) %&gt;% \n  summarise(Flourishing_pre = mean(Responses)) %&gt;% \n  ungroup()",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-A03.html",
    "href": "pc-A03.html",
    "title": "2A Lab 3 Week 4",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-A03.html#task-2-open-your-.rmd-file-from-last-week-or-create-a-new-.rmd-file",
    "href": "pc-A03.html#task-2-open-your-.rmd-file-from-last-week-or-create-a-new-.rmd-file",
    "title": "2A Lab 3 Week 4",
    "section": "Task 2: Open your .Rmd file from last week or create a new .Rmd file",
    "text": "Task 2: Open your .Rmd file from last week or create a new .Rmd file\nYou could continue the .Rmd file you used last week, or create a new .Rmd. If you need some guidance, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-A03.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-A03.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2A Lab 3 Week 4",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the package tidyverse today, and the datafile we should read in is dog_data_raw.csv.\n\n\n\n\n\n\nHint\n\n\n\n\n\n\n# loading tidyverse into the library\nlibrary(???)\n\n# reading in `dog_data_raw.csv`\ndog_data_raw &lt;- read_csv(\"???\")",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-A03.html#task-4-calculating-the-mean-for-loneliness_pre",
    "href": "pc-A03.html#task-4-calculating-the-mean-for-loneliness_pre",
    "title": "2A Lab 3 Week 4",
    "section": "Task 4: Calculating the mean for Loneliness_pre",
    "text": "Task 4: Calculating the mean for Loneliness_pre\n\nStep 1: Select all relevant columns, such as the participant ID and all 20 items of the Loneliness questionnaire completed by participants before the intervention. Store this data in an object called data_loneliness.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nLook at the codebook. Try to figure out\n\nthe variable name of the column in which the participant id is stored, and\nwhich items relate to the Loneliness scale at Stage “pre”\n\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\n\nthe participant id column is called RID\nThe Loneliness items at pre-intervention stage start with L1_\n\n\n\n\n\n\n\n\nStep 2: Pivot the data from wide format to long format so we can reverse-score and calculate the average score more easily (in step 3)\n\n\n\n\n\n\n\nHint\n\n\n\n\n\npivot_\nWe also need 3 arguments in that function:\n\nthe columns we want to select (e.g., all the loneliness items),\nthe name of the column in which the current column headings will be stored (e.g., “Qs”), and\nthe name of the column that should store all the values (e.g., “Responses”).\n\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\n\n  pivot_longer(cols = ???, names_to = \"???\", values_to = \"???\")\n\n\n\n\n\n\n\n\nStep 3: Reverse-scoring\n\nIdentify the items on the Loneliness scale that are reverse-coded, and then reverse-score them accordingly.\n\n\n\n\n\n\nHint\n\n\n\n\n\nWe need to figure out:\n\nwhich are the items of the loneliness scale we need to reverse-score\nwhat is the measuring scale of loneliness so we can determine the new values\nwhich function to use to create a new column that has the corrected scores in it\nwhich one of the case_ functions will get us there\n\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\n\nThe items to be reverse-coded items can be found in the codebook: L1_1, L1_5, L1_6, L1_9, L1_10, L1_15, L1_16, L1_19, L1_20\nthe loneliness scale ranges from 1 to 4, so we need to replace 1 with 4, 2 with 3, 3 with 2, and 4 with 1\nthe function to create a new column mutate()\nit’s a conditional statement rather than “just” replacing values, hence we need case_when()\n\n\n  mutate(Score_corrected = case_when(\n    ??? ~ ???,\n    .default = ???\n    ))\n\n\n\n\n\n\n\n\nStep 4: Calculate the average Loneliness score per participant. To match with the table above, we want to call this column Loneliness_pre\n\n\n\n\n\n\n\nHint\n\n\n\n\n\ngrouping and summarising\n\n\n\n\n\n\nMore concrete hint\n\n\n\n\n\n\n  group_by(???) %&gt;% \n  summarise(Loneliness_pre = ???(???)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# loading tidyverse into the library\nlibrary(tidyverse)\n\n# reading in `dog_data_raw.csv`\ndog_data_raw &lt;- read_csv(\"dog_data_raw.csv\")\n\n# Task 4: Tidying \nloneliness_tidy &lt;- dog_data_raw %&gt;% \n  # Step 1\n  select(RID, starts_with(\"L1\")) %&gt;% # select(RID, L1_1:L1_20) also works\n  # Step 2\n  pivot_longer(cols = -RID, names_to = \"Qs\", values_to = \"Response\") %&gt;% \n  # Step 3\n  mutate(Score_corrected = case_when(\n    Qs %in% c(\"L1_1\", \"L1_5\", \"L1_6\", \"L1_9\", \"L1_10\", \"L1_15\", \"L1_16\", \"L1_19\", \"L1_20\") ~ 5-Response,\n    .default = Response\n    )) %&gt;% \n  # Step 4\n  group_by(RID) %&gt;% \n  summarise(Loneliness_pre = mean(Score_corrected, na.rm = TRUE)) %&gt;% \n  ungroup()\n\n\n\n\nIf you’d like to practise your data wrangling skills further, you can try the “Challenge yourself” scenarios at the end of 3  Data wrangling II.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-A04.html",
    "href": "pc-A04.html",
    "title": "2A Lab 4 Week 5",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-A04.html#task-2-create-a-new-.rmd-file",
    "href": "pc-A04.html#task-2-create-a-new-.rmd-file",
    "title": "2A Lab 4 Week 5",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-A04.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-A04.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2A Lab 4 Week 5",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the package tidyverse today, and the datafile we should read in is dog_data_clean_wide.csv.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-A04.html#task-4-create-an-appropriate-plot",
    "href": "pc-A04.html#task-4-create-an-appropriate-plot",
    "title": "2A Lab 4 Week 5",
    "section": "Task 4: Create an appropriate plot",
    "text": "Task 4: Create an appropriate plot\nPick any single or two categorical variables from the Binfet dataset and choose one of the appropriate plot choices. Things to think about:\n\nSelect your categorical variable(s): GroupAssignment, Year_of_Study, Live_Pets, and/or Consumer_BARK\nDecide on the plot you want to display: barchart, stacked barchart, percent stacked barchart, or grouped barchart\nYou may need to convert your variables into factors\nThink about what you want to do with missing data\nPick a colour scheme (manual or pre-defined colour palette)\nTidy the axes labels\nDecide whether you need a legend or not, and if so, where you would want to place it\nRemove the gap between the bottom of the chart and the bars\nPick a theme\n\n\n\n\n\n\n\nPossible solution for a plot with 1 categorical variable\n\n\n\n\n\nConverting some variables into factors\n\ndog_data_wide &lt;- dog_data_wide %&gt;% \n  mutate(Year_of_Study = factor(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")))\n\nNow we can plot\n\nggplot(dog_data_wide, aes(x = Year_of_Study, fill = Year_of_Study)) +\n  geom_bar() + \n  scale_fill_brewer(\n    palette = \"Dark2\",\n    guide = \"none\") + \n  scale_x_discrete(name = \"Year of Study\") + \n  scale_y_continuous(name = \"Count\",\n                     expand = expansion(mult = c(0, 0.05))) + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPossible solution for a plot with 2 categorical variables\n\n\n\n\n\nConverting some variables into factors\n\ndog_data_wide &lt;- dog_data_wide %&gt;% \n  mutate(GroupAssignment = factor(GroupAssignment,\n                                  levels = c(\"Direct\", \"Indirect\", \"Control\")))\n\nNow we can plot\n\nggplot(dog_data_wide, aes(x = GroupAssignment , fill = Live_Pets)) +\n  geom_bar(position = \"fill\") + \n  labs(x = \"Experimental Group\", y = \"Count\", fill = \"Pets at Home\") +\n  scale_fill_manual(values = c('deeppink', 'springgreen2'), na.value = 'orangered',\n                    labels = c(\"Yes\", \"No\")) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +\n  theme_classic() + \n  theme(legend.position = \"bottom\")",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-A05.html",
    "href": "pc-A05.html",
    "title": "2A Lab 5 Week 7",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-A05.html#task-2-create-a-new-.rmd-file",
    "href": "pc-A05.html#task-2-create-a-new-.rmd-file",
    "title": "2A Lab 5 Week 7",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-A05.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-A05.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2A Lab 5 Week 7",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the package tidyverse today, and the data file we need to read in is dog_data_clean_wide.csv. I’ve named my data object dog_data_wide to shorten the name but feel free to use whatever object name sounds intuitive to you.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-A05.html#task-4-re-create-one-of-the-3-plots-below",
    "href": "pc-A05.html#task-4-re-create-one-of-the-3-plots-below",
    "title": "2A Lab 5 Week 7",
    "section": "Task 4: Re-create one of the 3 plots below",
    "text": "Task 4: Re-create one of the 3 plots below\nRe-create one of the 3 plot below:\n\ngrouped barchart (easy)\nviolin-boxplot (medium)\nscatterplot (hard)\n\n\nDifficulty level: easy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nI’ve created a new data object data_bar to select the relevant variables but you could also work straight from dog_data_wide.\nConsider turning the 2 categorical variables into factors before plotting\nPlotting should be relatively straightforward - these are default colours and you would only need to change the axes labels/ legend title.\n\n\n\n\n\n\n\nMore hints\n\n\n\n\n\nWe can change all of the 3 labels in one go. Check out the ## Prettier grouped barchart in 4.5 Activity 5: Stacked, Percent Stacked, and Grouped Barchart, where we did exactly that.\n\n\n\n\n\n\n\n\n\nSolution for data_bar\n\n\n\n\n\n\ndata_bar &lt;- dog_data_wide %&gt;% \n  select(RID, GroupAssignment, Year_of_Study) %&gt;% \n  mutate(GroupAssignment = factor(GroupAssignment,\n                                  levels = c(\"Direct\", \"Indirect\", \"Control\")),\n         Year_of_Study = factor(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")))\n\n\n\n\n\n\n\n\n\n\nSolution for the barchart\n\n\n\n\n\n\nggplot(data_bar, aes(x = GroupAssignment, fill = Year_of_Study)) +\n  geom_bar(position = \"dodge\") +\n  labs(x = \"Experimental Group\", y = \"Count\", fill = \"Year of Study\")\n\n\n\n\n\n\n\n\n\nDifficulty level: medium\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nI’ve created a new data object data_vb to select the relevant variables but you could also work straight from dog_data_wide.\nConsider turning the categorical variable into a factor before plotting\nPlotting tips:\n\nthe colour scale is one of the viridis options\nit’s a bit of trial and error for the opacity of the violin and the box width of the boxes (it is totally fine if it looks approximately right)\nthe tricky part might be adjusting the y-axis ticks. Take inspiration from the histogram in 5.3 Activity 3: Histogram (geom_histogram()) (Tab Axes labels, margins, and breaks)\n\n\n\n\n\n\n\n\nSolution for data_vb\n\n\n\n\n\n\ndata_vb &lt;- dog_data_wide %&gt;% \n  select(RID, Year_of_Study, Loneliness_post) %&gt;% \n  mutate(Year_of_Study = factor(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")))\n\n\n\n\n\n\n\n\n\n\nSolution for the violin-boxplot\n\n\n\n\n\n\nggplot(data_vb, aes(x = Year_of_Study, y = Loneliness_post, fill = Year_of_Study)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.25) +\n  scale_y_continuous(breaks = c(seq(from = 1, to = 4, by = 0.5)),\n                     limits = c(1, 4)) +\n  scale_fill_viridis_d(option = \"magma\",\n                       guide = \"none\") +\n  labs(x = \"Year of Study\", y = \"Loneliness scores post intervention\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nDifficulty level: hard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\nData wrangling: Even though we cleaned the data, it may not be in the shape for the task at hand. Have a look what the data object dog_data_wide looks like and think about how you’d need to restructure it to be able to plot the scatterplot. As always, I would suggest creating a new data object for the scatterplot (e.g., data_scatter).\nOnce you have the data in the right shape, start plotting. Start with a basic scatterplot and then add various layers and change elements you notice.\nRemember, some finetuning might need to be done in data_scatter rather than plot itself.\n\n\n\n\n\n\n\nData structure you have\n\n\n\n\n\n\n\n\n\n\n\nRID\nPANAS_PA_pre\nPANAS_PA_post\nPANAS_NA_pre\nPANAS_NA_post\n\n\n\n\n1\n3.2\n3.8\n1.0\n1.2\n\n\n2\n3.0\n3.2\n1.8\n1.0\n\n\n3\n2.8\n3.0\n1.6\n1.6\n\n\n4\n4.2\n3.8\n1.8\n1.6\n\n\n5\n3.4\n4.0\n2.2\n1.6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData structure you need\n\n\n\n\n\n\n\n\n\n\n\nRID\nSubscale\npre\npost\n\n\n\n\n1\nPositive Affect\n3.2\n3.8\n\n\n1\nNegative Affect\n1.0\n1.2\n\n\n2\nPositive Affect\n3.0\n3.2\n\n\n2\nNegative Affect\n1.8\n1.0\n\n\n3\nPositive Affect\n2.8\n3.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints for data_scatter\n\n\n\n\n\n\nStep 1: select the variables you need from dog_data_wide.\nStep 2: pivot all columns (bar the Participant ID) into long format\nStep 3: think about how to separate information of the subscales and timepoints\nStep 4: pivot from long into wide format. Take some inspiration from the Special case: Variables with subscales scenario above.\n\n\n\n\n\n\n\n\n\n\nHints for the plot\n\n\n\n\n\n\nThe colour scheme is Dark2 from the colour palette brewer\nThe colour of the trendline is #7570b3\nThink about how to make the Negative and Positive Affect points different colours. The solution is in 5.4 Activity 4: Scatterplot (geom_point())\nRenaming the different facets is one of those things that should be fixed in the data object instead\n\n\n\n\n\n\n\n\n\n\nSolution for data_scatter\n\n\n\n\n\n\ndata_scatter &lt;- dog_data_wide %&gt;% \n  select(RID, starts_with(\"PANAS\")) %&gt;% \n  pivot_longer(cols = -RID, names_to = \"Q\", values_to = \"Values\") %&gt;% \n  separate(Q, into = c(NA, \"Subscale\", \"Timepoint\"), sep = \"_\") %&gt;% \n  pivot_wider(names_from = Timepoint, values_from = Values) %&gt;% \n  mutate(Subscale = case_match(Subscale,\n                               \"NA\" ~ \"Negative Affect\",\n                               \"PA\" ~ \"Positive Affect\"),\n         Subscale = factor(Subscale)) %&gt;% \n  drop_na()\n\n\n\n\n\n\n\n\n\n\nSolution for the scatterplot\n\n\n\n\n\n\nggplot(data_scatter, aes(x = pre, y = post, colour = Subscale)) +\n  geom_point() +\n  geom_smooth(method = lm, colour = \"#7570b3\") +\n  facet_wrap(~Subscale) +\n  labs(x = \"Pre-Intervention (Timepoint 1)\",\n       y = \"Post-Intervention (Timepoint 2)\") +\n  scale_colour_brewer(palette = \"Dark2\",\n                      guide = \"none\") +\n  theme_bw()\n\n\n\n\n\n\n\nIf you are extremely fast, challenge yourself and re-create one of the other plots.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-A06.html",
    "href": "pc-A06.html",
    "title": "2A Lab 7 Week 9",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A06.html#task-2-create-a-new-.rmd-file",
    "href": "pc-A06.html#task-2-create-a-new-.rmd-file",
    "title": "2A Lab 7 Week 9",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A06.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-A06.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2A Lab 7 Week 9",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages tidyverse and lsr today, and the data file we need to read in is dog_data_clean_wide.csv. I’ve named my data object dog_data_wide to shorten the name but feel free to use whatever object name sounds intuitive to you.\nIf you have not worked through chapter 6 yet, you may need to install the package lsr before you can load it into the library. Run install.packages(\"lsr\") in your CONSOLE.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A06.html#task-4-tidy-data-for-a-chi-square-t-test",
    "href": "pc-A06.html#task-4-tidy-data-for-a-chi-square-t-test",
    "title": "2A Lab 7 Week 9",
    "section": "Task 4: Tidy data for a Chi-Square t-test",
    "text": "Task 4: Tidy data for a Chi-Square t-test\nLook at dog_data_wide and choose two categorical variables. To guide you through this example, I have selected Year of Study and whether or not the students owned pets as my categorical variable.\n\nStep 1: Select all relevant columns from dog_data_wide. In my case, those would be the participant ID RID, Year_of_Study, and Live_Pets. Store this data in an object called dog_chi.\nStep 2: Check if we have any missing values in the dog_chi. If so remove them with the function drop_na().\nStep 3: Convert Year_of_Study and Live_Pets into factors. Feel free to order the categories meaningfully.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\ndog_chi &lt;- ??? %&gt;% \n  # Step 1\n  select(???, ???, ???) %&gt;% \n  # Step 2\n  drop_na() %&gt;% \n  # Step 3\n  mutate(Year_of_Study = ???(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")),\n         Live_Pets = ???(Live_Pets,\n                            levels = c(\"yes\", \"no\")))\n\n\n\n\n\n\n\n\n\n\nSolution for Tasks 3 and 4\n\n\n\n\n\n\n# loading tidyverse and lsr into the library\nlibrary(tidyverse)\nlibrary(lsr)\n\n# reading in `dog_data_clean_wide.csv`\ndog_data_wide &lt;- read_csv(\"dog_data_clean_wide.csv\")\n\n# Task 4: Tidying \ndog_chi &lt;- dog_data_wide %&gt;% \n  # Step 1\n  select(RID, Year_of_Study, Live_Pets) %&gt;% \n  # Step 2\n  drop_na() %&gt;% \n  # Step 3\n  mutate(Year_of_Study = factor(Year_of_Study,\n                                levels = c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth or above\")),\n         Live_Pets = factor(Live_Pets,\n                            levels = c(\"yes\", \"no\")))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A06.html#task-5-compute-descriptives",
    "href": "pc-A06.html#task-5-compute-descriptives",
    "title": "2A Lab 7 Week 9",
    "section": "Task 5: Compute descriptives",
    "text": "Task 5: Compute descriptives\nCreate a frequency table (or contingency table to be more exact) from dog_chi, i.e., we need counts for each combination of the variables. Store the data in a new data object dog_chi_contingency. dog_chi_contingency should look like this:\n\n\n\n\n\nYear_of_Study\nyes\nno\n\n\n\n\nFirst\n21\n89\n\n\nSecond\n37\n64\n\n\nThird\n12\n22\n\n\nFourth\n12\n18\n\n\nFifth or above\n3\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\ndog_chi_contingency &lt;- dog_chi %&gt;% \n  count(???, ???) %&gt;% \n  pivot_wider(names_from = ???, values_from = n)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Task 5: Frequency table\ndog_chi_contingency &lt;- dog_chi %&gt;% \n  count(Live_Pets, Year_of_Study) %&gt;% \n  pivot_wider(names_from = Live_Pets, values_from = n)",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A06.html#task-6-check-assumptions",
    "href": "pc-A06.html#task-6-check-assumptions",
    "title": "2A Lab 7 Week 9",
    "section": "Task 6: Check assumptions",
    "text": "Task 6: Check assumptions\n\nBoth variables should be categorical, measured at either the ordinal or nominal level. Answer: yesno as Year_of_Study is ordinalnominal, and Live_Pets is ordinalnominal.\nEach observation in the dataset has to be independent, meaning the value of one observation does not affect the value of any other. Answer: yesno\nCells in the contingency table are mutually exclusive. Answer: yesno because each individual can belong to multiple cellsonly one cell in the contingency table.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A06.html#task-7-compute-a-chi-square-test-interpret-the-output",
    "href": "pc-A06.html#task-7-compute-a-chi-square-test-interpret-the-output",
    "title": "2A Lab 7 Week 9",
    "section": "Task 7: Compute a chi-square test & interpret the output",
    "text": "Task 7: Compute a chi-square test & interpret the output\n\nStep 1: Use the function as.data.frame to turn dog_chi into a dataframe. Store this output in a new data object called dog_chi_df.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\n??? &lt;- as.data.frame(???)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndog_chi_df &lt;- as.data.frame(dog_chi)\n\n\n\n\n\n\n\n\nStep 2: Run the associationTest() function from the lsr package to compute the Chi-Square test. The structure of the function is as follows:\n\n\nassociationTest(formula = ~ Variable1 + Variable2, data = your_dataframe)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nassociationTest(formula = ~ Year_of_Study + Live_Pets, data = dog_chi_df)\n\n\n\n\n\nStep 3: Interpreting the output\n\n\n\nWarning in associationTest(formula = ~Year_of_Study + Live_Pets, data =\ndog_chi_df): Expected frequencies too small: chi-squared approximation may be\nincorrect\n\n\n\n     Chi-square test of categorical association\n\nVariables:   Year_of_Study, Live_Pets \n\nHypotheses: \n   null:        variables are independent of one another\n   alternative: some contingency exists between variables\n\nObserved contingency table:\n                Live_Pets\nYear_of_Study    yes no\n  First           21 89\n  Second          37 64\n  Third           12 22\n  Fourth          12 18\n  Fifth or above   3  2\n\nExpected contingency table under the null hypothesis:\n                Live_Pets\nYear_of_Study      yes    no\n  First          33.39 76.61\n  Second         30.66 70.34\n  Third          10.32 23.68\n  Fourth          9.11 20.89\n  Fifth or above  1.52  3.48\n\nTest results: \n   X-squared statistic:  12.276 \n   degrees of freedom:  4 \n   p-value:  0.015 \n\nOther information: \n   estimated effect size (Cramer's v):  0.209 \n   warning: expected frequencies too small, results may be inaccurate\n\n\nThe Chi-Square test revealed that there is a statistically significant associationno statistically significant association between Year of Study and whether students live with pets, \\(\\chi^2\\) () = , p = , V = . The strength of the association between the variables is considered smallmoderatestrong. We therefore fail to reject the null hypothesisreject the null hypothesis.\n\n\n\n\n\n\nI’ve typed in the correct numbers but my fields don’t turn green\n\n\n\n\n\nCheck which numbers need to have 2 or 3 decimal spaces and (don’t) have a leading 0.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 7 Week 9"
    ]
  },
  {
    "objectID": "pc-A07.html",
    "href": "pc-A07.html",
    "title": "2A Lab 8 Week 10",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-A07.html#task-2-create-a-new-.rmd-file",
    "href": "pc-A07.html#task-2-create-a-new-.rmd-file",
    "title": "2A Lab 8 Week 10",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-A07.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-A07.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2A Lab 8 Week 10",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages tidyverse, car, and lsr today, and the data file we need to read in is dog_data_clean_wide.csv. I’ve named my data object dog_data_wide to shorten the name but feel free to use whatever object name sounds intuitive to you.\nIf you have not worked through chapter 7 yet, you may need to install a few packages first before you can load them into the library, for example, if car is missing, run install.packages(\"car\") in your CONSOLE.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-A07.html#task-4-tidy-data-for-a-two-sample-t-test",
    "href": "pc-A07.html#task-4-tidy-data-for-a-two-sample-t-test",
    "title": "2A Lab 8 Week 10",
    "section": "Task 4: Tidy data for a two-sample t-test",
    "text": "Task 4: Tidy data for a two-sample t-test\nFor today’s task, we want to analyse how students’ psychological well-being scores differed at the post_intervention time point. Specifically, we will compare the scores of students who directly interacted with the dogs (Group direct)to those who only talked to the dog handlers (Group control).\nTo achieve that, we need to select all relevant columns from dog_data_wide, and narrow down the dataframe to only include students assigned either to the direct or the control groups.\n\nStep 1: Select all relevant columns from dog_data_wide. For the task at hand, those would be the participant ID RID, GroupAssignment, and Flourishing_post. Store this data in an object called dog_independent.\nStep 2: Narrow down dog_independent to only include GroupAssignment groups direct or the control.\nStep 3: Convert GroupAssignment into a factor.\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\ndog_independent &lt;- ??? %&gt;% \n  # Step 1\n  select(???, ???, ???) %&gt;% \n  # Step 2\n  filter(??? %in% c(???, ???)) %&gt;% \n  # Step 3\n  mutate(GroupAssignment = ???())\n\n\n\n\n\n\n\n\n\n\nSolution for Tasks 3 and 4\n\n\n\n\n\n\n# loading tidyverse and lsr into the library\nlibrary(tidyverse)\nlibrary(car)\nlibrary(lsr)\n\n# reading in `dog_data_clean_wide.csv`\ndog_data_wide &lt;- read_csv(\"dog_data_clean_wide.csv\")\n\n# Task 4: Tidying \ndog_independent &lt;- dog_data_wide %&gt;% \n  # Step 1\n  select(RID, GroupAssignment, Flourishing_post) %&gt;% \n  # Step 2\n  filter(GroupAssignment %in% c(\"Control\", \"Direct\")) %&gt;% \n  # Step 3\n  mutate(GroupAssignment = factor(GroupAssignment))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-A07.html#task-5-compute-descriptives",
    "href": "pc-A07.html#task-5-compute-descriptives",
    "title": "2A Lab 8 Week 10",
    "section": "Task 5: Compute descriptives",
    "text": "Task 5: Compute descriptives\nCalculate the sample size (n), the mean, and the standard deviation of the psychological well-being score for both groups. Save the output in an object called dog_independent_descriptives. The resulting dataframe should look like this:\n\n\n\n\n\nGroupAssignment\nn\nmean_Flourishing\nsd_Flourishing\n\n\n\n\nControl\n94\n5.718085\n0.7709738\n\n\nDirect\n95\n5.776316\n0.8638912\n\n\n\n\n\n\n\n\n\n\n\n\n\nHints\n\n\n\n\n\n\ndog_independent_descriptives &lt;- dog_independent %&gt;% \n  group_by(???) %&gt;% \n  summarise(n = n(),\n            mean_Flourishing = mean(???),\n            sd_Flourishing = sd(???)) %&gt;% \n  ungroup()\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Task 5: Means & SD\ndog_independent_descriptives &lt;- dog_independent %&gt;% \n  group_by(GroupAssignment) %&gt;% \n  summarise(n = n(), \n            mean_Flourishing = mean(Flourishing_post),\n            sd_Flourishing = sd(Flourishing_post)) %&gt;% \n  ungroup()",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-A07.html#task-6-check-assumptions",
    "href": "pc-A07.html#task-6-check-assumptions",
    "title": "2A Lab 8 Week 10",
    "section": "Task 6: Check assumptions",
    "text": "Task 6: Check assumptions\n\nAssumption 1: Continuous DV\nIs the dependent variable (DV) continuous? Answer:\n\n No. The DV is called Flourishing and it is categorical No. The DV is called GroupAssignment and it is categorical Yes. The DV is called Flourishing and it is continuous Yes. The DV is called GroupAssignment and it is continuous\n\n\n\nAssumption 2: Data are independent\nEach observation in the dataset has to be independent, meaning the value of one observation does not affect the value of any other. Answer: yesno\n\n\nAssumption 3: Homoscedasticity (homogeneity of variance)\nI’ve computed Levene’s test below. How do you interpret the output?\n\nleveneTest(Flourishing_post ~ GroupAssignment, data = dog_independent)\n\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n1\n0.7111707\n0.4001329\n\n\n\n187\nNA\nNA\n\n\n\n\n\n\nAnswer:\n\n The p-value of Levene's test is significant, therefore we conclude that there is a difference between the variances in the population. The p-value of Levene's test is non-significant, therefore we conclude that there is a difference between the variances in the population. The p-value of Levene's test is significant, therefore we conclude that the variances in the population are equal. The p-value of Levene's test is non-significant, therefore we conclude that the variances in the population are equal.\n\n\n\nAssumption 4: DV should be approximately normally distributed\nLooking at the violin-boxplot below, are both groups normally distributed?\n\nggplot(dog_independent, aes(x = GroupAssignment, y = Flourishing_post, fill = GroupAssignment)) +\n  geom_violin(alpha = 0.4) +\n  geom_boxplot(width = 0.3, alpha = 0.8) +\n  scale_fill_viridis_d(option = \"cividis\", guide = \"none\") +\n  theme_classic() +\n  labs(x = \"Group\", y = \"Psychological well-being (post-intervention)\")\n\n\n\n\n\n\n\n\nAnswer:\n\n yes, both groups are normally distributed no, both groups are sightly skewed no, both groups are extremely skewed\n\n\n\nConclusion from assumption tests\nWith all assumptions tested, which statistical test would you recommend for this analysis?\nAnswer:\n\n All assumptions held. We will conduct a Student two-sample t-test. The assumption of normality was violated. We will conduct a Welch two-sample t-test because it has been shown to be robust to slight deviations from normality (Delacre et al., 2017). The assumptions of normality and homoscedasticity were violated. Therefore, we will conduct a non-parametric test.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-A07.html#task-7-computing-a-two-sample-t-test-with-effect-size-interpret-the-output",
    "href": "pc-A07.html#task-7-computing-a-two-sample-t-test-with-effect-size-interpret-the-output",
    "title": "2A Lab 8 Week 10",
    "section": "Task 7: Computing a two-sample t-test with effect size & interpret the output",
    "text": "Task 7: Computing a two-sample t-test with effect size & interpret the output\n\nStep 1: Compute the Welch two-sample t-test. The structure of the function is as follows:\n\n\nt.test(DV ~ IV, data = your_dataframe, var.equal = FALSE, alternative = \"two.sided\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nt.test(Flourishing_post ~ GroupAssignment, data = dog_independent, var.equal = FALSE, alternative = \"two.sided\")\n\n\n\n\n\nStep 2: Calculate an effect size\n\nCalculate Cohen’s D. The structure of the function is as follows:\n\ncohensD(DV ~ IV, data = your_dataframe, method = \"unequal\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncohensD(Flourishing_post ~ GroupAssignment, data = dog_independent, method = \"unequal\")\n\n\n\n\n\nStep 3: Interpreting the output\n\nBelow are the outputs for the descriptive statistics (table), Welch t-test (main output), and Cohen’s D (last line starting with [1]). Based on these, write up the results in APA style and provide an interpretation.\n\n\n\n\n\n\nGroupAssignment\nn\nmean_Flourishing\nsd_Flourishing\n\n\n\n\nControl\n94\n5.718085\n0.7709738\n\n\nDirect\n95\n5.776316\n0.8638912\n\n\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  Flourishing_post by GroupAssignment\nt = -0.48902, df = 185.05, p-value = 0.6254\nalternative hypothesis: true difference in means between group Control and group Direct is not equal to 0\n95 percent confidence interval:\n -0.2931533  0.1766920\nsample estimates:\nmean in group Control  mean in group Direct \n             5.718085              5.776316 \n\n\n[1] 0.0711213\n\n\nThe Welch two-sample t-test revealed that there is a statistically significant differenceno statistically significant difference in psychological well-being scores between direct (N = , M = , SD = ) and control group (N = , M = , SD = ), t() = , p = , d = . The strength of the association between the variables is considered smallmediumlarge. We therefore fail to reject the null hypothesisreject the null hypothesis in favour of H1.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2A Lab 8 Week 10"
    ]
  },
  {
    "objectID": "pc-B01.html",
    "href": "pc-B01.html",
    "title": "2B Lab 1 Week 2",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B01.html#task-2-create-a-new-.rmd-file",
    "href": "pc-B01.html#task-2-create-a-new-.rmd-file",
    "title": "2B Lab 1 Week 2",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B01.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-B01.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2B Lab 1 Week 2",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages rstatix, tidyverse, qqplotr, lsr today. Make sure to load rstatix in before tidyverse.\nWe also need to read in dog_data_clean_wide.csv. Again, I’ve named my data object dog_data_wide to shorten the name but feel free to use whatever object name sounds intuitive to you.\nFor the plot, we will need the data in long format. We can either read in dog_data_clean_long.csv to take a shortcut, or wrangle the data from dog_data_wide. I’ve taken the shortcut and named my data object dog_data_long.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B01.html#task-4-tidy-data-for-a-paired-t-test",
    "href": "pc-B01.html#task-4-tidy-data-for-a-paired-t-test",
    "title": "2B Lab 1 Week 2",
    "section": "Task 4: Tidy data for a paired t-test",
    "text": "Task 4: Tidy data for a paired t-test\nNot much tidying to do for today.\nPick a variable of interest and select the pre- and post-scores, and calculate the difference score. Store them in a separate data object with a meaningful name.\nI will use Loneliness as an example and call my data object dog_lonely. Regardless of your chosen variable, your data object should look like/ similar to the table below.\n\n\n\n\n\n\nRID\nLoneliness_pre\nLoneliness_post\nLoneliness_diff\n\n\n\n\n1\n2.25\n1.70\n-0.55\n\n\n2\n1.90\n1.60\n-0.30\n\n\n3\n2.25\n2.25\n0.00\n\n\n4\n1.75\n2.05\n0.30\n\n\n5\n2.85\n2.70\n-0.15\n\n\n\n\n\n\nIn dog_data_long, we want to turn Stage into a factor so we can re-order the labels (i.e., “pre” before “post”).\n\n\n\n\n\n\nSolution for Tasks 3 and 4\n\n\n\n\n\n\n## Task 3\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(lsr)\n\ndog_data_wide &lt;- read_csv(\"data/dog_data_clean_wide.csv\")\n\nRows: 284 Columns: 24\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): GroupAssignment, Year_of_Study, Live_Pets\ndbl (21): RID, Age_Yrs, Consumer_BARK, Flourishing_pre, Flourishing_post, PA...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndog_data_long &lt;- read_csv(\"data/dog_data_clean_long.csv\")\n\nRows: 568 Columns: 16\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): GroupAssignment, Year_of_Study, Live_Pets, Stage\ndbl (12): RID, Age_Yrs, Consumer_BARK, Flourishing, PANAS_PA, PANAS_NA, SHS,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n## Task 4\ndog_lonely &lt;- dog_data_wide %&gt;% \n  select(RID, Loneliness_pre, Loneliness_post) %&gt;% \n  mutate(Loneliness_diff = Loneliness_post - Loneliness_pre)\n\ndog_data_long &lt;- dog_data_long %&gt;% \n  mutate(Stage = factor(Stage,\n                        levels = c(\"pre\", \"post\")))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B01.html#task-5-compute-descriptives",
    "href": "pc-B01.html#task-5-compute-descriptives",
    "title": "2B Lab 1 Week 2",
    "section": "Task 5: Compute descriptives",
    "text": "Task 5: Compute descriptives\nWe want to determine the mean and sd of:\n\nthe pre-scores\nthe post-scores, and\nthe difference scores\n\nStore them in a data object called descriptives.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndescriptives &lt;- dog_lonely %&gt;% \n  summarise(mean_pre = mean(Loneliness_pre),\n            sd_pre = sd(Loneliness_pre),\n            mean_post = mean(Loneliness_post),\n            sd_post = sd(Loneliness_post),\n            diff = mean(Loneliness_diff),\n            sd_diff = sd(Loneliness_diff))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B01.html#task-6-check-assumptions",
    "href": "pc-B01.html#task-6-check-assumptions",
    "title": "2B Lab 1 Week 2",
    "section": "Task 6: Check assumptions",
    "text": "Task 6: Check assumptions\n\nAssumption 1: Continuous DV\nIs the dependent variable (DV) continuous? Answer:\n\n No. The DV is the pre- and post-stages and it is categorical Yes. The DV is the difference in loneliness scores and it is continuous No. The DV is the difference in loneliness scores but it is categorical\n\n\n\nAssumption 2: Data are independent\nEach pair of values in the dataset has to be independent, meaning each pair of values needs to be from a separate participant. Answer: yesno\n\n\nAssumption 3: Normality\nLooking at the violin-boxplots below, do you think the assumption of normality holds?\n\n\n\n\n\n\nNote\n\n\n\nThe axis label of Plot 2 turned out to be quite long here. I’ve used the escape character \\n to break it up across 2 lines.\n\n\n\n## Plot 1\nggplot(dog_data_long, aes(x = Stage, y = Loneliness, fill = Stage)) +\n  geom_violin(alpha = 0.5) +\n  geom_boxplot(width = 0.4, alpha = 0.8) +\n  scale_fill_viridis_d(guide = \"none\") +\n  theme_classic() +\n  labs(x = \"Time point\", y = \"mean Loneliness Scores\")\n\n## Plot 2\nggplot(dog_lonely, aes(x = \"\", y = Loneliness_diff)) +\n  geom_violin(fill = \"#21908C\", alpha = 0.5) +\n  geom_boxplot(fill = \"#21908C\", width = 0.4) +\n  theme_classic() +\n  labs(x = \"\",\n       y = \"Difference in mean Loneliness scores \\nbetween pre- and post- intervention\") # \\n forces a manual line break in the axis label\n\n\n\n\n\n\nPlots displayed to assess normality assumption\n\n\n\n\nAnswer:\n\n yes, because both pre- and post-scores in Plot 1 are approximately normally distributed yes, because the difference scores in Plot 2 are approximately normally distributed no, because both pre- and post-scores in Plot 1 are extremely skewed no, because the difference scores in Plot 2 are extremely skewed\n\n\n\nConclusion from assumption tests\nWith all assumptions tested, which statistical test would you recommend for this analysis?\nAnswer:\n\n All assumptions held. We will conduct a paired-samples t-test. The assumption of normality was violated. We will conduct a Wilcoxon signed-rank test.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B01.html#task-7-computing-a-paired-sample-t-test-with-effect-size-interpret-the-output",
    "href": "pc-B01.html#task-7-computing-a-paired-sample-t-test-with-effect-size-interpret-the-output",
    "title": "2B Lab 1 Week 2",
    "section": "Task 7: Computing a paired-sample t-test with effect size & interpret the output",
    "text": "Task 7: Computing a paired-sample t-test with effect size & interpret the output\n\nStep 1: Compute the paired-sample t-test. The structure of the function is as follows:\n\n\nt.test(your_data$var1, your_data$var2, paired = TRUE)\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nt.test(dog_lonely$Loneliness_pre, dog_lonely$Loneliness_post, paired = TRUE)\n\n\n\n\n\nStep 2: Calculate an effect size\n\nCalculate Cohen’s D. The structure of the function is as follows:\n\ncohensD(your_data$var1, your_data$var2, method = \"paired\")\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncohensD(dog_lonely$Loneliness_pre, dog_lonely$Loneliness_post, method = \"paired\")\n\n\n\n\n\nStep 3: Interpreting the output\n\nBelow are the outputs for the descriptive statistics (table), paired-samples t-test (main output), and Cohen’s D (last line starting with [1]). Based on these, write up the results in APA style and provide an interpretation.\n\n\n\n\n\n\nmean_pre\nsd_pre\nmean_post\nsd_post\ndiff\nsd_diff\n\n\n\n\n2.040187\n0.5304488\n1.914298\n0.5344914\n-0.1258895\n0.2290269\n\n\n\n\n\n\n\n    Paired t-test\n\ndata:  dog_lonely$Loneliness_pre and dog_lonely$Loneliness_post\nt = 9.2632, df = 283, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.09913876 0.15264034\nsample estimates:\nmean difference \n      0.1258895 \n\n\n[1] 0.5496716\n\n\nWe hypothesised that there would be a significant difference between Loneliness measured before (M = , SD = ) and after (M = , SD = ) the dog intervention. On average, participants felt less lonely after the intervention (Mdiff = , SDdiff = ). Using a paired-samples t-test, the effect was found to be significantnon-significant and of a smallmediumlarge magnitude, t() = , p , d = . We therefore fail to reject the null hypothesisreject the null hypothesis in favour of H1.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 1 Week 2"
    ]
  },
  {
    "objectID": "pc-B02.html",
    "href": "pc-B02.html",
    "title": "2B Lab 2 Week 3",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B02.html#task-2-create-a-new-.rmd-file",
    "href": "pc-B02.html#task-2-create-a-new-.rmd-file",
    "title": "2B Lab 2 Week 3",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B02.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-B02.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2B Lab 2 Week 3",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages tidyverse and correlation today. If you have already worked through this chapter, you will have all the packages installed. If you have yet to complete 9  Correlations, you will need to install the package correlation (see 1.5.1 Installing packages for guidance if needed).\nWe also need to read in dog_data_clean_wide.csv. Again, I’ve named my data object dog_data_wide to shorten the name but feel free to use whatever object name sounds intuitive to you.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B02.html#task-4-tidy-data-selecting-variables-of-interest",
    "href": "pc-B02.html#task-4-tidy-data-selecting-variables-of-interest",
    "title": "2B Lab 2 Week 3",
    "section": "Task 4: Tidy data & Selecting variables of interest",
    "text": "Task 4: Tidy data & Selecting variables of interest\nStep 1: Select the variables of interest. We need 2 continuous variables today, so any of the pre- vs post-test comparison will do. I would suggest happiness ratings (i.e., SHS_pre, SHS_post). Also keep the participant id RID. Store them in a new data object called dog_happy.\nStep 2: Check for missing values and remove participants with missing in either pre- or post-ratings.\nStep 3: Convert participant ID into a factor\n\n\n\n\n\n\nSolution for Tasks 3 and 4\n\n\n\n\n\n\n## Task 3\nlibrary(tidyverse)\nlibrary(correlation)\n\ndog_data_wide &lt;- read_csv(\"dog_data_clean_wide.csv\")\n\n\n## Task 4\ndog_happy &lt;- dog_data_wide %&gt;%\n  # Step 1\n  select(RID, SHS_pre, SHS_post) %&gt;% \n  # Step 2\n  drop_na() %&gt;% \n  # Step 3\n  mutate(RID = factor(RID))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B02.html#task-5-re-create-the-scatterplot-below",
    "href": "pc-B02.html#task-5-re-create-the-scatterplot-below",
    "title": "2B Lab 2 Week 3",
    "section": "Task 5: Re-create the scatterplot below",
    "text": "Task 5: Re-create the scatterplot below\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nggplot(dog_happy, aes(x = SHS_pre, y = SHS_post)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B02.html#task-6-assumptions-check",
    "href": "pc-B02.html#task-6-assumptions-check",
    "title": "2B Lab 2 Week 3",
    "section": "Task 6: Assumptions check",
    "text": "Task 6: Assumptions check\nWe can either do the assumption check by looking at the scatterplot above or we can run the code plot(lm(SHS_pre~SHS_post, data = dog_happy)) and assess the assumptions there. Either way, it should give you similar responses.\n\nLinearity: a non-linearlinear relationship\nNormality: residuals are approximately normally distributednot normally distributed\nHomoscedasticity: There is\n\n homoscedasticity as there is no distinct pattern in the residuals heteroscedasticity as the residuals show a distinct pattern\n\nOutliers: the data has some outliersthe data does not have any clear outliers\n\nWhat is your conclusion from the assumptions check?\n\n All assumptions hold. Therefore, we are conducting a parametric test, specifically Pearson’s correlation. Some assumptions are violated. Therefore, we are conducting a non-parametric test, specifically Spearman’s correlation. All assumptions are violated. Therefore, we are conducting a non-parametric test, specifically Spearman’s correlation.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B02.html#task-7-compute-a-pearson-correlation-interpret-the-output",
    "href": "pc-B02.html#task-7-compute-a-pearson-correlation-interpret-the-output",
    "title": "2B Lab 2 Week 3",
    "section": "Task 7: Compute a Pearson correlation & interpret the output",
    "text": "Task 7: Compute a Pearson correlation & interpret the output\n\nStep 1: Compute the Pearson correlation. The structure of the function is as follows:\n\n\ncorrelation(data = your_dataframe,\n            select = \"variable1\",\n            select2 = \"variable2\",\n            method = \"Pearson\",\n            alternative = \"two.sided\")\n\nThe default method argument is Pearson, but if you thought any of the assumptions were violated and conduct a Spearman correlation instead, change the method argument to”Spearman”.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ncorrelation(data = dog_happy,\n            select = \"SHS_pre\",\n            select2 = \"SHS_post\",\n            method = \"Pearson\",\n            alternative = \"two.sided\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter1\nParameter2\nr\nCI\nCI_low\nCI_high\nt\ndf_error\np\nMethod\nn_Obs\n\n\n\n\nSHS_pre\nSHS_post\n0.8842169\n0.95\n0.855856\n0.9072765\n31.73394\n281\n0\nPearson correlation\n283\n\n\n\n\n\n\n\n# alternative because there are only 2 numeric columns in `dog_happy`\ncorrelation(dog_happy)\n\n\n\n\n\nStep 2: Interpret the output\n\nA Pearson correlation revealed a strongmoderately strongweak, positivenegative, and statistically significantnon-significant relationship between happiness before and after the dog intervention, r() = , p , 95% CI = [, ]. We therefore fail to reject the null hypothesisreject the null hypothesis in favour of H1.\n\n\n\n\n\n\nImportant\n\n\n\nIn the write-up paragraph above, the open fields accepted answers with 2 or 3 decimal places as correct. However, in your reports, ensure that correlation values are reported with 3 decimal places.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 2 Week 3"
    ]
  },
  {
    "objectID": "pc-B03.html",
    "href": "pc-B03.html",
    "title": "2B Lab 3 Week 4",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B03.html#task-2-create-a-new-.rmd-file",
    "href": "pc-B03.html#task-2-create-a-new-.rmd-file",
    "title": "2B Lab 3 Week 4",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file\n… and name it something useful. If you need help, have a look at 1.3 Activity 2: Create a new R Markdown file.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B03.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-B03.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2B Lab 3 Week 4",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages tidyverse and performance today. If you have already worked through this chapter, you will have all the packages installed. If you have yet to complete 10  Simple regression, you will need to install the package performance (see 1.5.1 Installing packages for guidance if needed).\nWe also need to read in dog_data_clean_wide.csv. Again, I’ve named my data object dog_data_wide to shorten the name but feel free to use whatever object name sounds intuitive to you.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B03.html#task-4-tidy-data-selecting-variables-of-interest",
    "href": "pc-B03.html#task-4-tidy-data-selecting-variables-of-interest",
    "title": "2B Lab 3 Week 4",
    "section": "Task 4: Tidy data & Selecting variables of interest",
    "text": "Task 4: Tidy data & Selecting variables of interest\nLet’s try to answer the question whether pre-intervention social connectedness (SCS_pre) predicts post-intervention loneliness (Loneliness_post)?\nNot much tidying to do today.\nStep 1: Select the variables of interest. Store them in a new data object called dog_reg.\nStep 2: Check for missing values and remove participants with missing in either variable.\n\n\n\n\n\n\nHints\n\n\n\n\n\nStep 1: Variables of interest are pre-intervention social connectedness (SCS_pre), post-intervention loneliness (Loneliness_post), and of course the participant ID (RID).\nStep 2: The function drop_na() is your friend.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\ndog_reg &lt;- dog_data_wide %&gt;%\n  # Step 1\n  select(RID, Loneliness_post, SCS_pre) %&gt;% \n  # Step 2\n  drop_na()",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B03.html#task-5-visualise-the-relationship",
    "href": "pc-B03.html#task-5-visualise-the-relationship",
    "title": "2B Lab 3 Week 4",
    "section": "Task 5: Visualise the relationship",
    "text": "Task 5: Visualise the relationship\nI’ve used the following code to create a scatterplot to explore the relationship between social connectedness (pre-test) and loneliness (post-test). Can you check I did it correctly?\n\nggplot(dog_reg, aes(x = Loneliness_post, y = SCS_pre)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nDid I do it right? yesno\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe scatterplot is incorrect. Since we are predicting loneliness from social connectedness, the axes should be reversed.\nIn a correlation, the order of x and y does not matter, but in a regression, the predictor variable must be on the x-axis, and the outcome variable must be on the y-axis.\nHere is the corrected scatterplot:\n\nggplot(dog_reg, aes(x = SCS_pre, y = Loneliness_post)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B03.html#task-6-model-creating-assumption-checks",
    "href": "pc-B03.html#task-6-model-creating-assumption-checks",
    "title": "2B Lab 3 Week 4",
    "section": "Task 6: Model creating & Assumption checks",
    "text": "Task 6: Model creating & Assumption checks\nLet’s store our linear model as mod and then use the check_model() function from the performance package to check assumptions.\nRemember, the structure of the linear model is:\n\nlm(Outcome~Predictor, data)\n\nOnce the model is stored as mod, we can check its assumptions using check_model(mod).\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n## creating the linear model\nmod &lt;- lm(Loneliness_post~SCS_pre, data = dog_reg)\n\n## checking model assumptions\ncheck_model(mod)\n\n\n\n\n\n\n\n\n\n\n\nAssumptions 1-3 hold due to the study design, but let’s take a closer look at the following output:\n\n\n\n\n\n\n\n\n\n\nLinearity: The relationship appears to be linearnon-linear.\nNormality: The residuals are not normally distributedapproximately normally distributed.\nHomoscedasticity: There is homoscedasticity as there is no distinct pattern in the residualsheteroscedasticity as the residuals show a distinct pattern.\n\n\n\n\n\n\n\nI don’t understand - can you explain more?\n\n\n\n\n\n\nLinearity: The reference line is mostly flat and horizontal. There’s a slight curve at the end, but when checking the scatterplot, it’s not a major concern.\nNormality: Looking pretty good. The dots fall onto the line, indicating the residuals are approximately normally distributed. A Q-Q plot would show the same outcome, but with the reference line diagonal instead of horizontal.\nHomoscedasticity (or Homogeneity of Variance): Yeah, the reference line could be a bit more horizontal, but there’s no clear funnel shape. The points appear to have a fairly random pattern, so we can consider the assumption met.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B03.html#task-7-computing-a-simple-regression-interpret-the-output",
    "href": "pc-B03.html#task-7-computing-a-simple-regression-interpret-the-output",
    "title": "2B Lab 3 Week 4",
    "section": "Task 7: Computing a Simple Regression & interpret the output",
    "text": "Task 7: Computing a Simple Regression & interpret the output\nTo compute the simple regression, we need to use the summary() on our linear model mod.\n\nsummary(mod)\n\nHow do you interpret the output?\n\nThe estimate of the y-intercept for the model, rounded to two decimal places, is \nThe relationship is positivenegative\nThe model indicated that Social Connectedness significantly predicts Loneliness post intervention.Social Connectedness does not significantly predicts Loneliness post intervention.\nHow much the variance is explained by the model (rounded to two decimal places)? %.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 3 Week 4"
    ]
  },
  {
    "objectID": "pc-B04.html",
    "href": "pc-B04.html",
    "title": "2B Lab 4 Week 5",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-B04.html#task-2-create-a-new-.rmd-file",
    "href": "pc-B04.html#task-2-create-a-new-.rmd-file",
    "title": "2B Lab 4 Week 5",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-B04.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-B04.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2B Lab 4 Week 5",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages tidyverse, sjPlot, and performance today.\nJust like last week, we also need to read in dog_data_clean_wide.csv.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-B04.html#task-4-tidy-data-selecting-variables-of-interest",
    "href": "pc-B04.html#task-4-tidy-data-selecting-variables-of-interest",
    "title": "2B Lab 4 Week 5",
    "section": "Task 4: Tidy data & Selecting variables of interest",
    "text": "Task 4: Tidy data & Selecting variables of interest\nLet’s define a potential research question:\nTo what extent do pre-intervention loneliness and pre-intervention flourishing predict post-intervention loneliness, and is there an interaction between these predictors?\nTo get the data into shape, we should select our variables of interest from dog_data_wide and remove any missing values .\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(sjPlot)\nlibrary(performance)\n\ndog_data_wide &lt;- read_csv(\"dog_data_clean_wide.csv\")\n\ndog_mult_reg &lt;- dog_data_wide %&gt;%\n  select(RID, Loneliness_post, Loneliness_pre, Flourishing_pre) %&gt;% \n  drop_na() \n\n\n\n\nFurthermore, we need to mean-center our two continuous predictors. Since this is a new concept, simply run the code below.\n\ndog_mult_reg &lt;- dog_mult_reg %&gt;% \n  mutate(Flourishing_pre_centered = Flourishing_pre - mean(Flourishing_pre),\n         Loneliness_pre_centered = Loneliness_pre - mean(Loneliness_pre))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-B04.html#task-5-model-creating-assumption-checks",
    "href": "pc-B04.html#task-5-model-creating-assumption-checks",
    "title": "2B Lab 4 Week 5",
    "section": "Task 5: Model creating & Assumption checks",
    "text": "Task 5: Model creating & Assumption checks\nNow, let’s create our regression model. This follows the same approach as 10  Simple regression, but with additional predictors.\nAccording to our research question, we have the following model variables:\n\nDependent Variable (DV)/Outcome: Loneliness post intervention\nIndependent Variable (IV1)/Predictor1: Flouring before the intervention\nIndependent Variable (IV2)/Predictor2: Loneliness before the intervention\nDoes our model require an interaction term? YesNo\n\nAs a reminder, the multiple linear regression model has the following structure:\n\nlm(Outcome ~ Predictor1 * Predictor2, data)\n\nThe asterisk (*) means that the model includes main effects for both predictors (i.e., Pre-intervention flourishing & Pre-intervention loneliness) as well as their interaction term (which tests whether the effect of one predictor depends on the other).\n\n\n\n\n\n\nYour Turn\n\n\n\nStep 1: Create the model\nCompute the linear regression model using the formula above. Store the model in an object called mod, ensuring that you use the mean-centered predictors rather than the unstandardised values.\nStep 2: Run the regression\nJust like last week, use the summary() function on mod to display the regression output.\nStep 3: Check assumption\nUse the check_model() function from the performance package to test whether the model meets its assumptions.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Step 1\nmod &lt;- lm(Loneliness_post~Loneliness_pre_centered*Flourishing_pre_centered, data = dog_mult_reg)\n\n# Step 2\nsummary(mod)\n\n# Step 3\ncheck_model(mod)\n\n\n\n\nNow, answer the following questions:\n\nAre all of the assumptions met? YesNo\nHow much of the variance is explained by the model? Enter the percentage value with 2 decimal places. %\nIs the interaction term statistically significant? YesNo\nWhat is the p-value for the interaction term? Enter the value with 3 decimal places. \nWhat is \\(\\beta\\) coefficient for pre-intervention loneliness? Enter the value rounded to two decimal places.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 4 Week 5"
    ]
  },
  {
    "objectID": "pc-B05.html",
    "href": "pc-B05.html",
    "title": "2B Lab 5 Week 7",
    "section": "",
    "text": "Task 1: Open the R project for the lab",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-B05.html#task-2-create-a-new-.rmd-file",
    "href": "pc-B05.html#task-2-create-a-new-.rmd-file",
    "title": "2B Lab 5 Week 7",
    "section": "Task 2: Create a new .Rmd file",
    "text": "Task 2: Create a new .Rmd file",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-B05.html#task-3-load-in-the-library-and-read-in-the-data",
    "href": "pc-B05.html#task-3-load-in-the-library-and-read-in-the-data",
    "title": "2B Lab 5 Week 7",
    "section": "Task 3: Load in the library and read in the data",
    "text": "Task 3: Load in the library and read in the data\nThe data should already be in your project folder. If you want a fresh copy, you can download the data again here: data_pair_coding.\nWe are using the packages rstatix, tidyverse, qqplotr, and car today.\nJust like last week, we also need to read in dog_data_clean_wide.csv.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-B05.html#task-4-tidy-data-selecting-variables-of-interest",
    "href": "pc-B05.html#task-4-tidy-data-selecting-variables-of-interest",
    "title": "2B Lab 5 Week 7",
    "section": "Task 4: Tidy data & Selecting variables of interest",
    "text": "Task 4: Tidy data & Selecting variables of interest\nLet’s define a potential research question:\nHow does the type of interaction with dogs (control, indirect contact, direct contact) affect Positive Affect (PA) scores on the PANAS?\nTo get the data into shape, we should select our variables of interest from dog_data_wide and convert the intervention group into a factor . Store this reduced dataset in an object called dog_anova.\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nlibrary(rstatix)\nlibrary(tidyverse)\nlibrary(qqplotr)\nlibrary(car)\n\ndog_data_wide &lt;- read_csv(\"dog_data_clean_wide.csv\")\n\ndog_anova &lt;- dog_data_wide %&gt;%\n  select(RID, GroupAssignment, PANAS_PA_post) %&gt;% \n  mutate(GroupAssignment = factor(GroupAssignment))",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-B05.html#task-5-model-creating-assumption-checks",
    "href": "pc-B05.html#task-5-model-creating-assumption-checks",
    "title": "2B Lab 5 Week 7",
    "section": "Task 5: Model creating & Assumption checks",
    "text": "Task 5: Model creating & Assumption checks\nNow, let’s create our ANOVA model.\nAccording to our research question, we have the following model variables:\n\nDependent Variable (DV): levels of positive emotions, as assessed by the PANAS, at post intervention\nIndependent Variable (IV): Intervention Group (control, indirect contact, direct contact)\n\nAs a reminder, the ANOVA model has the following structure:\n\nlm(DV ~ IV, data)\n\nLet’s use this approach with our variables and store the model in a separate object called mod:\n\nmod &lt;- lm(PANAS_PA_post ~ GroupAssignment, data = dog_anova)\n\nLets check some assumptions:\nYou see the following output.\n\nggplot(dog_anova, aes(sample = PANAS_PA_post, fill = GroupAssignment)) +\n  stat_qq_band(alpha = 0.5) +\n  stat_qq_line() +\n  stat_qq_point() +\n  facet_wrap(~GroupAssignment) +\n  theme_bw() +\n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\nWhich assumption was checked in the plot above? \nDoes the assumption hold? YesNo\n\n\nleveneTest(PANAS_PA_post ~ GroupAssignment, data = dog_anova)\n\nYou run the line of code above and the outcome of the Levene’s test is reported as \\(F(2,277) = 0.68, p = .507\\). What does that mean?\n\n The p-value is non-significant, and the assumption of homogeneity of variance is met. The p-value is significant, and the assumption of homogeneity of variance is met. The p-value is significant, and the assumption of homogeneity of variance is violated. The p-value is non-significant, and the assumption of homogeneity of variance is violated.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-B05.html#task-6-interpreting-the-output",
    "href": "pc-B05.html#task-6-interpreting-the-output",
    "title": "2B Lab 5 Week 7",
    "section": "Task 6: Interpreting the output",
    "text": "Task 6: Interpreting the output\n\nanova_test(mod, type = 2, effect.size = \"pes\")\n\n\n\n\n\nEffect\nDFn\nDFd\nF\np\np&lt;.05\npes\n\n\n\n\nGroupAssignment\n2\n277\n0.687\n0.504\n\n0.005\n\n\n\n\n\n\nHow do you interpret the results?\n\n The effect of GroupAssignment is significant, meaning at least one group differs from the others. The effect size (ηₚ² = 0.504) suggests a large effect of GroupAssignment on the outcome variable. The F-value (F = 0.687) suggests a moderate effect, but more comparisons are needed. The effect of GroupAssignment is not significant, indicating no meaningful difference between groups.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 5 Week 7"
    ]
  },
  {
    "objectID": "pc-B06.html",
    "href": "pc-B06.html",
    "title": "2B Lab 7 Week 9",
    "section": "",
    "text": "This is the pair coding activity related to 13  Factorial ANOVA.",
    "crumbs": [
      "IN-LAB: PAIR-CODING",
      "2B Lab 7 Week 9"
    ]
  },
  {
    "objectID": "appendix-a-installing-r.html",
    "href": "appendix-a-installing-r.html",
    "title": "Appendix A — Installing R",
    "section": "",
    "text": "How to install R and RStudio\nThe RSetGo book provides detailed instructions on how to install R and RStudio on your computer. It also includes links to walkthroughs for installing R on different types of computers and operating systems.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing R</span>"
    ]
  },
  {
    "objectID": "appendix-b-updating-packages.html",
    "href": "appendix-b-updating-packages.html",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "",
    "text": "B.1 Updating RStudio\nRStudio is the easiest component to update. Typically, updates to RStudio won’t affect your code, instead they add in new features, like spell-check or upgrades to what RStudio can do. There’s usually very little downside to updating RStudio and it’s easy to do.\nClick Help &gt; Check for updates\nUpdating RStudio\nIf an update is available, it will prompt you to download it and you can install it as usual.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Updating R, RStudio, and packages</span>"
    ]
  },
  {
    "objectID": "appendix-b-updating-packages.html#updating-r",
    "href": "appendix-b-updating-packages.html#updating-r",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "B.2 Updating R",
    "text": "B.2 Updating R\nFinally, you may also wish to update R itself. The key thing to be aware of is that when you update R, if you just download the latest version from the website, you will lose all your packages.\n\nB.2.1 Windows\nThe easiest way to update R on Windows and not cause yourself a huge headache is to use the installr package. When you use the updateR() function, a series of dialogue boxes will appear. These should be fairly self-explanatory but there is a full step-by-step guide available for how to use installr, the important bit is to select “Yes” when it asked if you would like to copy your packages from the older version of R.\n\n# Install the installr package\ninstall.packages(\"installr\")\n\n# Run the update function\ninstallR::updateR()\n\n\n\nB.2.2 Mac\nFor a Mac, you can use the updateR package. You’ll need to install this from GitHub. You will be asked to type your system password (that you use to log into your computer) in the console pane. If relevant, it will ask you if you want to restore your packages for a new major version.\n\n# install from github\ndevtools::install_github(\"AndreaCirilloAC/updateR\")\n\n# update your R version, you will need your system password\nupdateR::updateR()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Updating R, RStudio, and packages</span>"
    ]
  },
  {
    "objectID": "appendix-b-updating-packages.html#updating-packages",
    "href": "appendix-b-updating-packages.html#updating-packages",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "B.3 Updating packages",
    "text": "B.3 Updating packages\nPackage developers will occasionally release updates to their packages. This is typically to add in new functions to the package, or to fix or amend existing functions. Be aware that some package updates may cause your previous code to stop working. This does not tend to happen with minor updates to packages, but occasionally with major updates, you can have serious issues if the developer has made fundamental changes to how the code works. For this reason, we recommend updating all your packages once at the beginning of each academic year (or semester) - don’t do it before an assessment or deadline just in case!\nTo update an individual package, the easiest way is to use the install.packages() function, as this always installs the most recent version of the package.\n\ninstall.packages(\"tidyverse\")\n\nTo update multiple packages, or indeed all packages, RStudio provides helpful tools. Click Tools &gt; Check for Package Updates. A dialogue box will appear and you can select the packages you wish to update. Be aware that if you select all packages, this may take some time and you will be unable to use R whilst the process completes.\n\n\n\n\n\nUpdating packages with RStudio",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Updating R, RStudio, and packages</span>"
    ]
  },
  {
    "objectID": "appendix-b-updating-packages.html#sec-package-install-troubleshooting",
    "href": "appendix-b-updating-packages.html#sec-package-install-troubleshooting",
    "title": "Appendix B — Updating R, RStudio, and packages",
    "section": "B.4 Troubleshooting",
    "text": "B.4 Troubleshooting\nOccasionally, you might have a few problem packages that seemingly refuse to update. For me, rlang and vctrs cause me no end of trouble. These aren’t packages that you will likely every explicitly load, but they’re required beneath the surface for R to do things like knit your Markdown files etc.\n\nB.4.1 Non-zero exit status\nIf you try to update a package and get an error message that says something like Warning in install.packages : installation of package ‘vctrs’ had non-zero exit status or perhaps Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :  namespace 'rlang' 0.4.9 is being loaded, but &gt;= 0.4.10 is required one solution I have found is to manually uninstall the package, restart R, and then install the package new, rather than trying to update an existing version. The installr package also has a useful function for uninstalling packages.\n\n# Load installr\nlibrary(installr)\n\n# Uninstall the problem package\nuninstall.packages(\"package_name\")\n\n# Then restart R using session - restart R\n# Then install the package fresh\n\ninstall.packages(\"package\")\n\n\n\nB.4.2 Cannot open file\nYou may get the following error after trying to install any packages at all:\n\nError in install packages : Cannot open file ‘C:/…..’: Permission denied\n\nThis usually indicates a permissions problem with writing to the default library (the folder that packages are kept in). Sometimes this means that you need to install R and RStudio as administrator or run it as administrator.\nOne other fix may be to change the library location using the following code (check in “C:/Program Files/R” for what version you should have instead of “R-3.5.2”):\n\n# change the library path\n.libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))\n\nIf that works and you can install packages, set this library path permanently:\n\nInstall the usethis package\nRun usethis::edit_r_profile() in the console; it will open up a blank file\nPaste into the file (your version of): .libPaths(c(\"C:/Program Files/R/R-3.5.2/library\"))\nSave and close the file\nRestart R for changes to take effect\n\nThe code in your .Rprofile will now run every time you start up R.\nAs always, if you’re having issues, please ask on Teams or come to office hours.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Updating R, RStudio, and packages</span>"
    ]
  },
  {
    "objectID": "appendix-d-symbols.html",
    "href": "appendix-d-symbols.html",
    "title": "Appendix C — Symbols",
    "section": "",
    "text": "Symbol\npsyTeachR Term\nAlso Known As\n\n\n\n\n()\n(round) brackets\nparentheses\n\n\n[]\nsquare brackets\nbrackets\n\n\n{}\ncurly brackets\nsquiggly brackets\n\n\n&lt;&gt;\nchevrons\nangled brackets / guillemets\n\n\n&lt;\nless than\n\n\n\n&gt;\ngreater than\n\n\n\n&\nampersand\n“and” symbol\n\n\n#\nhash\npound / octothorpe\n\n\n/\nslash\nforward slash\n\n\n\\\nbackslash\n\n\n\n-\ndash\nhyphen / minus\n\n\n_\nunderscore\n\n\n\n*\nasterisk\nstar\n\n\n^\ncaret\npower symbol\n\n\n~\ntilde\ntwiddle / squiggle\n\n\n=\nequal sign\n\n\n\n==\ndouble equal sign\n\n\n\n.\nfull stop\nperiod / point\n\n\n!\nexclamation mark\nbang / not\n\n\n?\nquestion mark\n\n\n\n’\nsingle quote\nquote / apostrophe\n\n\n”\ndouble quote\nquote\n\n\n%&gt;%\npipe\nmagrittr pipe\n\n\n|\nvertical bar\npipe\n\n\n,\ncomma\n\n\n\n;\nsemi-colon\n\n\n\n:\ncolon\n\n\n\n@\n“at” symbol\nvarious hilarious regional terms\n\n\n…\nglossary(\"ellipsis\")\ndots\n\n\n\n\n\n\n\n\nImage by James Chapman/Soundimals",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Symbols</span>"
    ]
  },
  {
    "objectID": "appendix-x-How-to-cite-R.html",
    "href": "appendix-x-How-to-cite-R.html",
    "title": "Appendix D — Citing R and RStudio",
    "section": "",
    "text": "How to cite R and RStudio\nYou may be some way off writing a scientific report where you have to cite and reference R, however, when the time comes it is important to do so to give the people who built it (most of them for free!) credit. You should provide separate citations for R, RStudio, and the packages you use.\nTo get the citation for the version of R you are using, simply run the citation() function which will always provide you with the most recent citation.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2025). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2025},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo extract the version of R you are using, run R.version.string\n\nR.version.string\n\n[1] \"R version 4.5.1 (2025-06-13 ucrt)\"\n\n\nTo generate the citation for any packages you are using, you can also use the citation() function with the name of the package you wish to cite.\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\nSome citations will already display the version, but if they don’t, use packageVersion() and add the package.\n\npackageVersion(\"tidyverse\")\n\n[1] '2.0.0'\n\n\nTo generate the citation for the version of RStudio you are using, you can use the RStudio.Vesion() function:\n\nRStudio.Version()\n\nFinally, here’s an example of how that might look in the write-up of your report:\n\nAnalysis was conducted using R (Version 4.5.1; R Core Team, 2025), RStudio (Version 2024.12.1+563; Posit Team, 2025), and the tidyverse package (Version 2.0.0; Wickham et al., 2019).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Citing R and RStudio</span>"
    ]
  },
  {
    "objectID": "appendix-y-license.html",
    "href": "appendix-y-license.html",
    "title": "License",
    "section": "",
    "text": "This book is licensed under Creative Commons Attribution-ShareAlike 4.0 International License (CC-BY-SA 4.0). You are free to share and adapt this book. You must give appropriate credit, provide a link to the license, and indicate if changes were made. If you adapt the material, you must distribute your contributions under the same license as the original.",
    "crumbs": [
      "Appendices",
      "License"
    ]
  }
]